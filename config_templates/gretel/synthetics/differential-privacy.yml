# This is a default configuration for enabling differential privacy during
# model training via DP-SGD.
#
# Differential privacy helps prevent unintended memorization of secrets in 
# the training data, by limiting the amount that any training example, or 
# small set of training examples can affect the model.
#
# Even though the analytical epsilon upper bound does not offer strong
# privacy guarantees, the benefits of differentially private training
# can be clearly observed by examining the trained model. 

schema_version: "1.0"
name: "differential-privacy"
models:
  - synthetics:
      data_source: __tmp__
      params:
        epochs: auto
        vocab_size: auto
        learning_rate: auto
        rnn_units: auto
        batch_size: auto
        predict_batch_size: 1
        dp: True
        dp_noise_multiplier: 0.001
        dp_l2_norm_clip: 5.0
        dp_microbatches: 1
      privacy_filters:
        similarity: auto
        outliers: auto
