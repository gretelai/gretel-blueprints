# deprecated: This configuration will be deprecated soon. We recommend using the Tabular DP model with the "synthetics/tabular-differential-privacy" config to generate synthetic data with strong differential privacy guarantees.

# Alternatively, you can also use the "synthetics/tabular-lstm" config and set
# the param dp: True to continue using the experimental differential privacy
# mode for the Gretel LSTM model.

# This is a configuration for enabling differential privacy during
# model training via DP-SGD.
#
# Differential privacy helps prevent unintended memorization of secrets in 
# the training data, by limiting the amount that any training example, or 
# small set of training examples can affect the model.
#
# Even though the analytical epsilon upper bound does not offer strong
# privacy guarantees, the benefits of differentially private training
# can be clearly observed by examining the trained model. 

schema_version: "1.0"
name: "differential-privacy"
models:
  - synthetics:
      data_source: __tmp__
      params:
        epochs: auto
        vocab_size: auto
        learning_rate: auto
        rnn_units: auto
        batch_size: auto
        predict_batch_size: 1
        dp: True
        dp_noise_multiplier: 0.001
        dp_l2_norm_clip: 5.0
        dp_microbatches: 1
      generate:
        num_records: 5000
      privacy_filters:
        similarity: auto
        outliers: auto
