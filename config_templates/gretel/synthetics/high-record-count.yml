# Data with a extremely high record count
#
# With the potential for highly varied data we lower the learning
# rate to cause the model to learn less at each training step.
#
# We use a higher RNN unit count in each layer to learn
# more complexities within the data.
#
# There is not a single optimal setting for learning rate, we
# recommend experimenting with the following values:
#
# 0.01, 0.001, 0.0005, 0.0001, 0.00005

schema_version: 1.0

models:
  - synthetics:
      data_source: "__tmp__"
      params:
        epochs: 100
        batch_size: 64
        vocab_size: 20000
        learning_rate: 0.0005
        rnn_units: 1024
