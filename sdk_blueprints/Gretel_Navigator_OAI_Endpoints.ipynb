{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigator OAI Endpoints with the Gretel SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blueprint, we'll be able to make requests to a OpenAI compliant Navigator hosted on AWS or Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gretel-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from gretel_client import Gretel\n",
    "\n",
    "PROMPT = \"\"\"Generate a mock dataset for users from the Foo company based in France.\n",
    "Each user should have the following columns:\n",
    "* first_name: traditional French first names.\n",
    "* last_name: traditional French surnames. \n",
    "* email: formatted as the first letter of their first name followed by their last name @foo.io (e.g., jdupont@foo.io)\n",
    "* gender: Male/Female\n",
    "* city: a city in France\n",
    "* country: always 'France'.\n",
    "\"\"\"\n",
    "\n",
    "EDIT_PROMPT = \"\"\"Edit the table and add the following columns:\n",
    "* occupation: a random occupation\n",
    "* education level: make it relevant to the occupation\n",
    "\"\"\"\n",
    "\n",
    "table_headers = [\"first_name\", \"last_name\", \"email\", \"gender\", \"city\", \"country\"]\n",
    "table_data = [\n",
    "    {\n",
    "        \"first_name\": \"Lea\",\n",
    "        \"last_name\": \"Martin\",\n",
    "        \"email\": \"lmartin@foo.io\",\n",
    "        \"gender\": \"Female\",\n",
    "        \"city\": \"Lyon\",\n",
    "        \"country\": \"France\",\n",
    "    }\n",
    "]\n",
    "\n",
    "SAMPLE_DATA = pd.DataFrame(table_data, columns=table_headers)\n",
    "\n",
    "STREAM = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, you'll need to update your OpenAI endpoint and API key as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "endpoint = \"my-domain.com\"\n",
    "api_key = \"abc\"\n",
    "# This is used for local testing since the AzureOpenAI class requires an actual deployed Azure OpenAI endpoint\n",
    "client = OpenAI(\n",
    "    base_url=f\"https://{endpoint}/v1/inference/oai/v1\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "MODEL = \"gretelai-azure/gpt-3.5-turbo\"\n",
    "\n",
    "azure_open_ai = Gretel.create_navigator_azure_oai_adapter(client)\n",
    "\n",
    "usage, generated_df = azure_open_ai.generate(\n",
    "    MODEL,\n",
    "    PROMPT,\n",
    "    num_records=10,\n",
    "    sample_data=SAMPLE_DATA,\n",
    "    stream=STREAM,\n",
    ")\n",
    "\n",
    "print(generated_df)\n",
    "print(\"*****\")\n",
    "print(usage)\n",
    "\n",
    "# Let's edit this now\n",
    "\n",
    "EDIT_PROMPT = \"\"\"Edit the table and add the following columns:\n",
    "* Occupation: a random occupation\n",
    "* Education level: make it relevant to the occupation\n",
    "\"\"\"\n",
    "\n",
    "usage, edited_df = azure_open_ai.edit(\n",
    "    MODEL,\n",
    "    EDIT_PROMPT,\n",
    "    seed_data=generated_df,\n",
    "    stream=STREAM\n",
    ")\n",
    "print(edited_df)\n",
    "print(\"*****\")\n",
    "print(usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the same thing again, but now we're gonna use streaming mode. In order to have streaming mode \n",
    "# utilize a Python generator, we have to disable DataFrame mode.\n",
    "\n",
    "# In this mode, we only get back a single Python generator. Because of how the OAI API spec is designed, \n",
    "# usage information will only come back after the entire stream has been exhausted.\n",
    "data_stream = azure_open_ai.generate(\n",
    "    MODEL,\n",
    "    PROMPT,\n",
    "    num_records=20,\n",
    "    sample_data=SAMPLE_DATA,\n",
    "    as_dataframe=False,\n",
    ")\n",
    "\n",
    "generated_records = []\n",
    "\n",
    "for record in data_stream:\n",
    "    print(record)\n",
    "    generated_records.append(record)\n",
    "    \n",
    "# Once the stream is exhausted, we capture our usage/metadata and make it\n",
    "# available as an attribute on our data stream\n",
    "print(\"*****\")\n",
    "print(data_stream.metadata)\n",
    "\n",
    "# Let's edit this now\n",
    "\n",
    "data_stream = azure_open_ai.edit(\n",
    "    MODEL,\n",
    "    EDIT_PROMPT,\n",
    "    seed_data=generated_records,\n",
    "    as_dataframe=False\n",
    ")\n",
    "\n",
    "for record in data_stream:\n",
    "    print(record)\n",
    "\n",
    "print(\"*****\")\n",
    "print(data_stream.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started here, you'll need to update your \n",
    "* profile name\n",
    "* sagemaker endpoint name\n",
    "* aws region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "profile_name = \"my-profile-name\"\n",
    "sagemaker_endpoint = \"my-sagemaker-endpoint\"\n",
    "aws_region = \"us-east-1\"\n",
    "\n",
    "boto3.setup_default_session(profile_name=profile_name)\n",
    "\n",
    "sagemaker_client = boto3.client(\"sagemaker-runtime\", region_name=aws_region)\n",
    "\n",
    "sagemaker = Gretel.create_navigator_sagemaker_adapter(sagemaker_client, sagemaker_endpoint)\n",
    "\n",
    "MODEL = \"gretelai/auto\"\n",
    "\n",
    "usage, generated_df = sagemaker.generate(\n",
    "    MODEL,\n",
    "    PROMPT,\n",
    "    num_records=10,\n",
    "    sample_data=SAMPLE_DATA,\n",
    "    stream=STREAM,\n",
    ")\n",
    "\n",
    "print(generated_df)\n",
    "print(\"*****\")\n",
    "print(usage)\n",
    "\n",
    "# Edit!\n",
    "\n",
    "usage, edited_df = sagemaker.edit(\n",
    "    MODEL,\n",
    "    EDIT_PROMPT,\n",
    "    seed_data=generated_df,\n",
    "    stream=STREAM\n",
    ")\n",
    "print(edited_df)\n",
    "print(\"*****\")\n",
    "print(usage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
