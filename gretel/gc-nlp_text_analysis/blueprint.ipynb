{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq spacy gretel-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Safely with Sensitive Free Text Using Gretel Cloud and NLP\n",
    "\n",
    "Using Gretel.ai's [NER and NLP features](https://gretel.ai/platform/data-cataloghttps://gretel.ai/platform/data-catalog), we analyze and label chat logs looking for PII and other potentially sensitive information. After labeling the dataset, we build a transformation pipeline that will redact and replace any sensitive strings from chat messages.\n",
    "\n",
    "At the end of the notebook we'll have a dataset that is safe to share without compromising a user's personal information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gretel_client import get_cloud_client\n",
    "\n",
    "client = get_cloud_client(prefix=\"api\", api_key=\"prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.install_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "For this blueprint, we use a modified dataset from the Ubuntu Chat Corpus. It represents an archived set of IRC logs from Ubuntu's technical support channel. This data primarily contains free form text that we will pass through a NER pipeline for labeling and PII discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = pd.read_csv(\"https://gretel-public-website.s3.us-west-2.amazonaws.com/blueprints/nlp_text_analysis/chat_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>dialogueID</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>71195.tsv</td>\n",
       "      <td>2010-08-27T11:31:00.000Z</td>\n",
       "      <td>KB1JWQ</td>\n",
       "      <td>mjwalker</td>\n",
       "      <td>phone number 123.453.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>126125.tsv</td>\n",
       "      <td>2008-04-23T14:55:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>location San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126125.tsv</td>\n",
       "      <td>2008-04-23T14:56:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my name is Linus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>126125.tsv</td>\n",
       "      <td>2008-04-23T14:57:00.000Z</td>\n",
       "      <td>lordleemo</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>location United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>64545.tsv</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>city is San Diego email address is test@exampl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder  dialogueID                      date       from         to  \\\n",
       "0       3   71195.tsv  2010-08-27T11:31:00.000Z     KB1JWQ   mjwalker   \n",
       "1       3  126125.tsv  2008-04-23T14:55:00.000Z  bad_image        NaN   \n",
       "2       3  126125.tsv  2008-04-23T14:56:00.000Z  bad_image        NaN   \n",
       "3       3  126125.tsv  2008-04-23T14:57:00.000Z  lordleemo  bad_image   \n",
       "4       3   64545.tsv  2009-08-01T06:22:00.000Z   mechtech        NaN   \n",
       "\n",
       "                                                text  \n",
       "0                          phone number 123.453.8920  \n",
       "1                                 location San Diego  \n",
       "2                                   my name is Linus  \n",
       "3                             location United States  \n",
       "4  city is San Diego email address is test@exampl...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label the source text\n",
    "\n",
    "With the data loaded into the notebook, we now create a Gretel Project, and upload the records to the project for labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = client.get_project(create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`detection_mode` configures the NER pipeline that is responsible for labeling the data. Using `detection_mode=all` we configure the records to be labeled using all of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6 records [00:00, 15.01 records/s]         \n"
     ]
    }
   ],
   "source": [
    "project.send_dataframe(source_df, detection_mode=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For extra credit, you can navigate to the project's console view to better inspect and visualize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://console.gretel.cloud/drew-0a1c3'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.get_console_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect labeled data\n",
    "\n",
    "In this next cell, we download the labeled records and inspect each chat message to see what entities were detected. Gretel uses a combination of NLP models, regex, and custom heuristics to detect named entities in structured and unstructured data.\n",
    "\n",
    "For a list of entities that Gretel can detect, [click here](https://gretel.ai/gretel-cloud-faqs/what-types-of-entities-can-gretel-identify)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_helpers.spacy import display_entities\n",
    "\n",
    "TEXT_FIELD = \"text\"\n",
    "\n",
    "for record in project.iter_records(direction=\"backward\"):\n",
    "    display_entities(record, text_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a transformation pipeline\n",
    "\n",
    "After labeling the dataset, we've identified messages that contain PII, such as names and emails. The final step in this blueprint is to build a transformation pipeline that will replace names and other identifying information with fake representations of the data.\n",
    "\n",
    "We make a point to replace rather than redact sensitive information. This preservation ensures the dataset remains valuable for downstream use cases such as machine learning, where the structure and contents of the data are essential.\n",
    "\n",
    "To learn more about data transformation pipelines with Gretel, check our [website](https://gretel.ai/platform/transform) or [SDK documentation](https://gretel-client.readthedocs.io/en/stable/transformers/api_ref.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from gretel_client.transformers import DataPath, DataTransformPipeline\n",
    "from gretel_client.transformers import FakeConstantConfig\n",
    "\n",
    "SEED = uuid.uuid1().int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the pipeline. `FakeConstantConfig` will replace any entities configured under `labels` with a fake version of the entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_xf = FakeConstantConfig(seed=SEED, labels=[\"person_name\", \"email_address\", \"phone_number\"])\n",
    "\n",
    "paths = [\n",
    "    DataPath(input=TEXT_FIELD, xforms=[fake_xf]),\n",
    "    DataPath(input=\"*\"),\n",
    "]\n",
    "\n",
    "pipeline = DataTransformPipeline(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the pipeline to redact any sensitive strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf_records = [\n",
    "    pipeline.transform_record(record)[\"record\"]\n",
    "    for record in \n",
    "    project.iter_records(direction=\"backward\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the transformed version of the dataset. Notice that entities such as names and emails have been replace with fake instances of the entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>location United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my name is Darrell Long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city is San Diego email address is garciajim@y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phone number 532-677-7284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                             location United States\n",
       "1                            my name is Darrell Long\n",
       "2  city is San Diego email address is garciajim@y...\n",
       "3                                 location San Diego\n",
       "4                          phone number 532-677-7284"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xf_df = pd.DataFrame(xf_records)\n",
    "\n",
    "xf_df[[TEXT_FIELD]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've completed this notebook, you've seen how it's possible to take a corpus of free text, label it using Gretel's NER pipeline, and safely anonymize the dataset while retaining its utility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
