{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "39b52602",
      "metadata": {
        "id": "39b52602"
      },
      "source": [
        "# Getting Started: Transforming Data with Gretel Transform v2 ðŸš€\n",
        "\n",
        "Welcome to this hands-on guide for leveraging [Gretel Transform v2](https://docs.gretel.ai/create-synthetic-data/models/transform/v2), a powerful tool for detecting and transforming entities in both structured and unstructured datasets. This notebook will walk you through the process step-by-step, helping you:\n",
        "\n",
        "* Configure and run a model to detect and process sensitive entities.\n",
        "* Replace detected entities with synthetic data, including faking, hashing, or custom transformations.\n",
        "\n",
        "Letâ€™s get started! ðŸŽ‰"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "668a19e1",
      "metadata": {
        "id": "668a19e1"
      },
      "source": [
        "## Step 1: Install Dependencies\n",
        "First, let's install the `gretel_client` package to interact with Gretel's API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86834a14",
      "metadata": {
        "id": "86834a14"
      },
      "outputs": [],
      "source": [
        "!pip install -Uqq gretel_client"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218bb96d",
      "metadata": {
        "id": "218bb96d"
      },
      "source": [
        "## Step 2: Set Up Gretel Client\n",
        "Login to Gretel and create or load a project. Get a free API key at https://console.gretel.ai/users/me/key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb643fea",
      "metadata": {
        "id": "cb643fea"
      },
      "outputs": [],
      "source": [
        "from gretel_client import Gretel\n",
        "\n",
        "gretel = Gretel(\n",
        "    project_name=\"redact-pii\",\n",
        "    api_key=\"prompt\",\n",
        "    validate=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac866da2",
      "metadata": {
        "id": "ac866da2"
      },
      "source": [
        "## Step 3: Load the Dataset\n",
        "We'll load a sample dataset containing personal identifiable information (PII). Update the link to load your dataset of choice.\n",
        "\n",
        "Let's review the first few rows of the dataset below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e42eb3d",
      "metadata": {
        "id": "7e42eb3d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://gretel-public-website.s3.us-west-2.amazonaws.com/datasets/gretel_generated_table_simpsons_pii.csv')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcfd19f",
      "metadata": {
        "id": "5bcfd19f"
      },
      "source": [
        "## Step 4: Configure and Run the Model\n",
        "\n",
        "Letâ€™s set up a **Transform v2** model to detect and anonymize entities in the dataset by either faking or hashing them, depending on the entity type and available Faker functions. The configuration is done in YAML format, and weâ€™ll choose or create a Gretel project to store the model and its outputs.\n",
        "\n",
        "Learn more in the docs at: https://docs.gretel.ai/create-synthetic-data/models/transform/v2/reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c66a4d65",
      "metadata": {
        "id": "c66a4d65"
      },
      "outputs": [],
      "source": [
        "# De-identification configuration\n",
        "config = \"\"\"\n",
        "schema_version: \"1.0\"\n",
        "name: \"Replace PII\"\n",
        "models:\n",
        "  - transform_v2:\n",
        "      globals:\n",
        "        classify:\n",
        "          enable: true\n",
        "          entities:\n",
        "            - first_name\n",
        "            - last_name\n",
        "            - email\n",
        "            - phone_number\n",
        "            - street_address\n",
        "          num_samples: 100\n",
        "      steps:\n",
        "        - rows:\n",
        "            update:\n",
        "              # Detect and replace values in PII columns, hash if no Faker available\n",
        "              - condition: column.entity is in globals.classify.entities\n",
        "                value: column.entity | fake\n",
        "                fallback_value: this | hash | truncate(9,true,\"\")\n",
        "\n",
        "              # Detect and replace entities within free text columns\n",
        "              - type: text\n",
        "                value: this | fake_entities(on_error=\"hash\")\n",
        "\n",
        "              # Replace email addresses with first + last name to retain correlations\n",
        "              - name: email_address\n",
        "                value: 'row.first_name + \".\" + row.last_name + \"@\" + fake.free_email_domain()'\n",
        "\"\"\"\n",
        "\n",
        "transform_result = gretel.submit_transform(\n",
        "    config=config,\n",
        "    data_source=df,\n",
        "    job_label=\"Transform PII data\"\n",
        ")\n",
        "\n",
        "transformed_df = transform_result.transformed_df\n",
        "transformed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3293fa26",
      "metadata": {
        "id": "3293fa26"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def highlight_detected_entities(report_dict):\n",
        "    \"\"\"\n",
        "    Process the report dictionary, extract columns with detected entities,\n",
        "    and highlight cells with non-empty entity labels.\n",
        "\n",
        "    Args:\n",
        "        report_dict (dict): The report dictionary from transform_result.report.as_dict.\n",
        "\n",
        "    Returns:\n",
        "        pd.io.formats.style.Styler: Highlighted DataFrame.\n",
        "    \"\"\"\n",
        "    # Parse the columns and extract 'Detected Entities'\n",
        "    columns_data = report_dict['columns']\n",
        "    df = pd.DataFrame([\n",
        "        {\n",
        "            'Column Name': col['name'],\n",
        "            'Detected Entities': ', '.join(\n",
        "                entity['label'] for entity in col['entities'] if entity['label']\n",
        "            )\n",
        "        }\n",
        "        for col in columns_data\n",
        "    ])\n",
        "\n",
        "    # Highlighting logic\n",
        "    def highlight_entities(s):\n",
        "        return ['background-color: lightgreen' if len(val) > 0 else '' for val in s]\n",
        "\n",
        "    # Apply highlighting\n",
        "    return df.style.apply(highlight_entities, subset=['Detected Entities'], axis=1)\n",
        "\n",
        "\n",
        "highlight_detected_entities(pd.DataFrame(transform_result.report.as_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! We successfully de-identified both column-level PII entities and PII entities within unstructured free text using this default configuration."
      ],
      "metadata": {
        "id": "82wNgNAw8caT"
      },
      "id": "82wNgNAw8caT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "Finally, we'll do a side-by-side comparison of the first row of data before and after transformation. We'll also print out relevant job statistics."
      ],
      "metadata": {
        "id": "0bN-BM7IYwRP"
      },
      "id": "0bN-BM7IYwRP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebc2505",
      "metadata": {
        "id": "0ebc2505"
      },
      "outputs": [],
      "source": [
        "# Preview the differences of the first row of real vs transformed data\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "first_row_df1 = df.iloc[0].to_frame('Original')\n",
        "first_row_df2 = transformed_df.iloc[0].to_frame('Transformed')\n",
        "\n",
        "# Join the transposed rows\n",
        "comparison_df = first_row_df1.join(first_row_df2)\n",
        "\n",
        "def highlight_differences(row):\n",
        "    is_different = row['Original'] != row['Transformed']\n",
        "    color = 'background-color: lightgreen' if is_different else ''\n",
        "    return ['', f'{color}; min-width: 500px']\n",
        "\n",
        "styled_df = comparison_df.style.apply(highlight_differences, axis=1).format(escape=\"html\")\n",
        "styled_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}