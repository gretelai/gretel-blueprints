{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801298b3",
   "metadata": {},
   "source": [
    "<a target=\"_parent\" href=\"https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/demo/navigator/getting-started/data-designer-101.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¨ Data Designer 101: A Comprehensive Guide\n",
    "\n",
    "Welcome to this comprehensive introduction to Gretel's Data Designer! This notebook will walk you through the essential concepts and techniques you need to generate high-quality synthetic data for your projects.\n",
    "\n",
    "## What is Data Designer?\n",
    "\n",
    "Data Designer is a powerful tool in Gretel's ecosystem that allows you to programmatically define and generate synthetic data with precise control over structure, relationships, and statistical properties. Whether you need test data for development, synthetic data for privacy protection, or training data for AI models, Data Designer provides a flexible and powerful solution.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this tutorial, you'll be able to:\n",
    "- Create synthetic datasets with various column types\n",
    "- Define relationships between columns using expressions\n",
    "- Generate realistic person data with demographic information\n",
    "- Use statistical distributions to create realistic numeric data\n",
    "- Leverage LLMs to generate contextual text data\n",
    "- Add constraints to ensure data validity\n",
    "- Preview and generate your final dataset\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "First, let's install the necessary packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install the latest version of Gretel client and dependencies\n",
    "%pip install -U gretel_client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached Gretel credentials\n",
      "Logged in as kirit.thadaka@gretel.ai âœ…\n",
      "Gretel client configured to use project: proj_2uY0cfM0kjiegpyEZvCHNKZYxGf\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from gretel_client.navigator_client import Gretel\n",
    "from gretel_client.data_designer import columns as C\n",
    "from gretel_client.data_designer import params as P\n",
    "\n",
    "# Initialize the Gretel client\n",
    "gretel = Gretel(\n",
    "    api_key=\"prompt\",  # This will prompt for your API key\n",
    "    endpoint=\"https://api.dev.gretel.ai\"  # Update with your endpoint if different\n",
    ")\n",
    "\n",
    "# Create a new Data Designer object\n",
    "model_suite = \"apache-2.0\"  # This specifies the model suite to use\n",
    "dd = gretel.data_designer.new(model_suite=model_suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Column Types\n",
    "\n",
    "Data Designer offers several types of columns to generate different kinds of data. Let's explore each of these types:\n",
    "\n",
    "1. **Sampler Columns** - Generate data from predefined distributions or categories\n",
    "2. **Expression Columns** - Create data using Jinja expressions that can reference other columns\n",
    "3. **LLM-Generated Columns** - Use large language models to create contextual text\n",
    "\n",
    "### Sampler Columns\n",
    "\n",
    "Let's start with some basic sampler columns. These are useful for generating structured data from predefined sources or distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:23:33] [INFO] Validation passed âœ…\n",
      "[14:23:33] [INFO] ðŸš€ Generating preview\n",
      "[14:23:35] [INFO] ðŸ¦œ Step 1: Generate columns using samplers\n",
      "[14:23:37] [INFO] ðŸŽ‰ Your dataset preview is ready!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['product_subcategory'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     62\u001b[39m dd.validate()\n\u001b[32m     63\u001b[39m preview = dd.preview()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43mpreview\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproduct_category\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproduct_subcategory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Playground/base_env/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Playground/base_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Playground/base_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['product_subcategory'] not in index\""
     ]
    }
   ],
   "source": [
    "# Category sampler - useful for discrete categories like product types, statuses, etc.\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"product_category\",\n",
    "        type=P.SamplingSourceType.CATEGORY,\n",
    "        params=P.CategorySamplerParams(\n",
    "            values=[\"Electronics\", \"Clothing\", \"Home & Kitchen\", \"Books\", \"Toys\"],\n",
    "            weights=[0.3, 0.25, 0.2, 0.15, 0.1]  # Optional: control the distribution\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Numerical samplers - for generating numbers from statistical distributions\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"price\",\n",
    "        type=P.SamplingSourceType.GAUSSIAN,  # Normal distribution\n",
    "        params=P.GaussianSamplerParams(\n",
    "            mean=100.0,\n",
    "            stddev=30.0,\n",
    "            min=10.0,  # Ensure no negative prices\n",
    "            max=500.0  # Cap the maximum price\n",
    "        ),\n",
    "        convert_to=\"float\"  # Specify the output type\n",
    "    )\n",
    ")\n",
    "\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"quantity_in_stock\",\n",
    "        type=P.SamplingSourceType.POISSON,  # Good for count data\n",
    "        params=P.PoissonSamplerParams(mean=50)\n",
    "    )\n",
    ")\n",
    "\n",
    "# DateTime samplers - for generating dates and times\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"listed_date\",\n",
    "        type=P.SamplingSourceType.DATETIME,\n",
    "        params=P.DatetimeSamplerParams(\n",
    "            start=\"2023-01-01\",\n",
    "            end=\"2023-12-31\"\n",
    "        ),\n",
    "        convert_to=\"%Y-%m-%d\"  # Format as YYYY-MM-DD\n",
    "    )\n",
    ")\n",
    "\n",
    "# UUID sampler - for generating unique identifiers\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"product_id\",\n",
    "        type=P.SamplingSourceType.UUID,\n",
    "        params=P.UUIDParams(\n",
    "            prefix=\"PROD-\",  # Add a prefix to the UUID\n",
    "            short_form=True  # Generate shorter UUIDs for readability\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Let's preview what we have so far\n",
    "dd.validate()\n",
    "preview = dd.preview()\n",
    "preview.dataset.df[[\"product_category\", \"product_subcategory\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subcategory Sampler\n",
    "\n",
    "Now let's explore a more advanced sampler: the subcategory sampler. This allows you to create hierarchical relationships between categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subcategory sampler - create relationships between categories\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"product_subcategory\",\n",
    "        type=P.SamplingSourceType.SUBCATEGORY,\n",
    "        params=P.SubcategoryParams(\n",
    "            category=\"product_category\",  # Parent column\n",
    "            values={\n",
    "                \"Electronics\": [\"Smartphones\", \"Laptops\", \"Headphones\", \"Cameras\", \"Accessories\"],\n",
    "                \"Clothing\": [\"Men's\", \"Women's\", \"Children's\", \"Activewear\", \"Accessories\"],\n",
    "                \"Home & Kitchen\": [\"Appliances\", \"Cookware\", \"Furniture\", \"Decor\", \"Organization\"],\n",
    "                \"Books\": [\"Fiction\", \"Non-Fiction\", \"Children's\", \"Textbooks\", \"Reference\"],\n",
    "                \"Toys\": [\"Action Figures\", \"Board Games\", \"Educational\", \"Outdoor\", \"Plush\"]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Preview to see how subcategories relate to categories\n",
    "dd.validate()\n",
    "preview = dd.preview()\n",
    "preview.dataset.df[[\"product_category\", \"product_subcategory\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expression Columns\n",
    "\n",
    "Expression columns allow you to define values based on other columns, using Jinja templates. This is powerful for creating logical relationships in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple expression - combining values from other columns\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"product_title\",\n",
    "        expr=\"{{ product_subcategory }} {{ product_category }} (ID: {{ product_id }})\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Expressions with calculations\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"total_value\",\n",
    "        expr=\"{{ price * quantity_in_stock | round(2) }}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Expressions with conditional logic\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"stock_status\",\n",
    "        expr=\"{% if quantity_in_stock == 0 %}Out of Stock{% elif quantity_in_stock < 10 %}Low Stock{% else %}In Stock{% endif %}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Preview the expressions\n",
    "preview = dd.preview()\n",
    "preview.dataset.df[[\"product_title\", \"quantity_in_stock\", \"total_value\", \"stock_status\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Generating Person Data\n",
    "\n",
    "Data Designer includes powerful capabilities for generating realistic person data. Let's explore these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate customer data using the person sampler\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"customer\",  # This creates a nested object with all person attributes\n",
    "        type=P.SamplingSourceType.PERSON,\n",
    "        params=P.PersonSamplerParams(\n",
    "            locale=\"en_US\",  # Set the locale for appropriate formatting\n",
    "            age_range=[18, 80]     # Maximum age\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Extract specific attributes from the customer object for easier use\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"customer_name\",\n",
    "        expr=\"{{ customer.first_name }} {{ customer.last_name }}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"customer_email\",\n",
    "        expr=\"{{ customer.email_address }}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"customer_location\",\n",
    "        expr=\"{{ customer.city }}, {{ customer.state }}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Let's add a second person for shipping recipient (could be self or other)\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"ship_to_self\",\n",
    "        type=P.SamplingSourceType.BERNOULLI,  # Boolean with probability\n",
    "        params=P.BernoulliSamplerParams(p=0.7)  # 70% chance to ship to self\n",
    "    )\n",
    ")\n",
    "\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"recipient\",  # Second person\n",
    "        type=P.SamplingSourceType.PERSON,\n",
    "        params=P.PersonSamplerParams(\n",
    "            locale=\"en_US\",\n",
    "            age_range=[18, 80]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Use conditional expressions to determine shipping details\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"shipping_name\",\n",
    "        expr=\"{% if ship_to_self %}{{ customer.first_name }} {{ customer.last_name }}{% else %}{{ recipient.first_name }} {{ recipient.last_name }}{% endif %}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"shipping_address\",\n",
    "        expr=\"{% if ship_to_self %}{{ customer.street_number }} {{ customer.street_name }}, {{ customer.city }}, {{ customer.state }} {{ customer.zipcode }}{% else %}{{ recipient.street_number }} {{ recipient.street_name }}, {{ recipient.city }}, {{ recipient.state }} {{ recipient.zipcode }}{% endif %}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Preview customer and shipping information\n",
    "dd.validate()\n",
    "preview = dd.preview()\n",
    "preview.dataset.df[[\"customer_name\", \"customer_email\", \"shipping_name\", \"shipping_address\", \"ship_to_self\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Order and Transaction Data\n",
    "\n",
    "Now let's combine what we've learned to create a more complex dataset with order and transaction information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an order ID\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"order_id\",\n",
    "        type=P.SamplingSourceType.UUID,\n",
    "        params=P.UUIDParams(\n",
    "            prefix=\"ORD-\",\n",
    "            short_form=True,\n",
    "            uppercase=True\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Order date (after product listing date)\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"order_date\",\n",
    "        type=P.SamplingSourceType.TIMEDELTA,\n",
    "        params=P.TimeDeltaParams(\n",
    "            dt_min=1,     # Minimum days after listing date\n",
    "            dt_max=90,    # Maximum days after listing date\n",
    "            reference_column_name=\"listed_date\", # Reference date\n",
    "            unit=\"D\"      # Unit is days\n",
    "        ),\n",
    "        convert_to=\"%Y-%m-%d\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Order quantity\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"order_quantity\",\n",
    "        type=P.SamplingSourceType.UNIFORM,\n",
    "        params=P.UniformSamplerParams(low=1, high=5)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate total order amount\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"order_total\",\n",
    "        expr=\"{{ (price * order_quantity) | round(2) }}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Shipping cost based on order total\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"shipping_cost\",\n",
    "        expr=\"{% if order_total > 50 %}0.00{% else %}5.99{% endif %}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate final amount\n",
    "dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"final_amount\",\n",
    "        expr=\"{{ (order_total + shipping_cost | float) | round(2) }}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate payment method\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"payment_method\",\n",
    "        type=P.SamplingSourceType.CATEGORY,\n",
    "        params=P.CategorySamplerParams(\n",
    "            values=[\"Credit Card\", \"Debit Card\", \"PayPal\", \"Apple Pay\", \"Google Pay\"],\n",
    "            weights=[0.4, 0.3, 0.15, 0.1, 0.05]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Order status\n",
    "dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"order_status\",\n",
    "        type=P.SamplingSourceType.CATEGORY,\n",
    "        params=P.CategorySamplerParams(\n",
    "            values=[\"Delivered\", \"Shipped\", \"Processing\", \"Cancelled\"],\n",
    "            weights=[0.6, 0.2, 0.15, 0.05]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Preview order information\n",
    "dd.validate()\n",
    "preview = dd.preview()\n",
    "preview.dataset.df[[\"order_id\", \"product_title\", \"order_quantity\", \"order_total\", \"shipping_cost\", \"final_amount\", \"order_status\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: LLM-Generated Columns\n",
    "\n",
    "One of the most powerful features of Data Designer is the ability to use large language models (LLMs) to generate text based on the context. Let's use this to create product descriptions and customer reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate product descriptions using LLM\n",
    "dd.add_column(\n",
    "    C.LLMGenColumn(\n",
    "        name=\"product_description\",\n",
    "        prompt=(\n",
    "            \"Write a concise 2-3 sentence product description for a {{ product_subcategory }} in the {{ product_category }} \"\n",
    "            \"category. The product costs ${{ price }}. Make it informative and appealing to potential customers. \"\n",
    "            \"Do not use bullet points.\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate customer reviews using LLM (conditionally based on order status)\n",
    "dd.add_column(\n",
    "    C.LLMGenColumn(\n",
    "        name=\"customer_review\",\n",
    "        prompt=(\n",
    "            \"{% if order_status == 'Delivered' %}\"\n",
    "            \"Write a brief customer review (1-2 sentences) from {{ customer_name }} about their purchase of a \"\n",
    "            \"{{ product_subcategory }} in the {{ product_category }} category. The customer paid ${{ price }} per item \"\n",
    "            \"and ordered {{ order_quantity }} units. \"\n",
    "            \"{% if price > 100 %}The product is in the premium range.{% else %}The product is in the standard range.{% endif %} \"\n",
    "            \"{% if order_quantity > 1 %}The customer bought multiple units.{% endif %} \"\n",
    "            \"Give the review a rating out of 5 stars.\"\n",
    "            \"{% else %}\"\n",
    "            \"No review available yet.\"\n",
    "            \"{% endif %}\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate order notes using LLM with different conditions\n",
    "dd.add_column(\n",
    "    C.LLMGenColumn(\n",
    "        name=\"order_notes\",\n",
    "        prompt=(\n",
    "            \"{% if order_status == 'Cancelled' %}\"\n",
    "            \"Write a brief note (1 sentence) explaining why customer {{ customer_name }} cancelled their order \"\n",
    "            \"for a {{ product_subcategory }}.\"\n",
    "            \"{% elif order_status == 'Processing' %}\"\n",
    "            \"Write a brief processing note (1 sentence) for order {{ order_id }} placed by {{ customer_name }}.\"\n",
    "            \"{% elif order_status == 'Shipped' %}\"\n",
    "            \"Write a brief shipping note (1 sentence) for order {{ order_id }} being delivered to {{ shipping_name }} \"\n",
    "            \"in {{ recipient.city }}, {{ recipient.state }}.\"\n",
    "            \"{% else %}\"\n",
    "            \"Order {{ order_id }} was successfully delivered to {{ shipping_name }}.\"\n",
    "            \"{% endif %}\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Preview LLM-generated content\n",
    "dd.validate()\n",
    "preview = dd.preview()\n",
    "preview.dataset.df[[\"product_title\", \"product_description\", \"customer_review\", \"order_notes\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding Constraints\n",
    "\n",
    "To ensure our data makes logical sense, we can add constraints that enforce relationships between columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure order quantity can't exceed quantity in stock\n",
    "dd.add_constraint(\n",
    "    target_column=\"order_quantity\",\n",
    "    type=\"column_inequality\",\n",
    "    params={\n",
    "        \"operator\": \"le\",  # less than or equal to\n",
    "        \"rhs\": \"quantity_in_stock\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ensure order date is after listing date\n",
    "dd.add_constraint(\n",
    "    target_column=\"order_date\",\n",
    "    type=\"column_inequality\",\n",
    "    params={\n",
    "        \"operator\": \"ge\",  # greater than or equal to\n",
    "        \"rhs\": \"listed_date\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Constrain price to be positive\n",
    "dd.add_constraint(\n",
    "    target_column=\"price\",\n",
    "    type=\"scalar_inequality\",\n",
    "    params={\n",
    "        \"operator\": \"gt\",  # greater than\n",
    "        \"rhs\": 0\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Generating the Final Dataset\n",
    "\n",
    "Now that we've designed our schema, let's generate a larger dataset and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a single record in more detail\n",
    "dd.validate()\n",
    "preview = dd.preview()\n",
    "preview.display_sample_record()  # This shows a nicely formatted single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a name for our dataset\n",
    "workflow_name = \"synthetic-ecommerce-data\"\n",
    "\n",
    "# Generate a dataset with 100 records\n",
    "workflow_run = dd.create(\n",
    "    num_records=100,  # Generate 100 records\n",
    "    name=workflow_name,\n",
    "    wait_for_completion=True  # Wait until generation is complete\n",
    ")\n",
    "\n",
    "print(f\"Generated dataset shape: {workflow_run.dataset.df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample of the generated dataset\n",
    "workflow_run.dataset.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to a CSV file\n",
    "csv_filename = f\"{workflow_name}.csv\"\n",
    "workflow_run.dataset.df.to_csv(csv_filename, index=False)\n",
    "print(f\"Dataset saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Working with Seed Data\n",
    "\n",
    "Data Designer allows you to jumpstart your synthetic data generation by using existing data as a foundation. This powerful capability, known as \"seeding,\" lets you:\n",
    "\n",
    "- Use real data samples as templates for synthetic generation\n",
    "- Create variations of existing datasets while maintaining their core structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Using an in-memory DataFrame as seed data\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame (in a real scenario, this could be your existing data)\n",
    "seed_data = pd.DataFrame({\n",
    "    'product_name': ['Premium Wireless Headphones', 'Smart Fitness Tracker', 'Portable Bluetooth Speaker', 'Ultra HD Monitor'],\n",
    "    'manufacturer': ['AudioTech', 'FitLife', 'SoundWave', 'VisualPro'],\n",
    "    'base_price': [129.99, 89.99, 49.99, 249.99],\n",
    "    'rating': [4.7, 4.2, 4.5, 4.8]\n",
    "})\n",
    "\n",
    "print(\"Original seed data shape:\", seed_data.shape)\n",
    "display(seed_data)\n",
    "\n",
    "# Create a new Data Designer instance\n",
    "seed_dd = gretel.data_designer.new(model_suite=model_suite)\n",
    "\n",
    "# Add the seed dataset to Data Designer\n",
    "seed_dd.with_seed_dataset(\n",
    "    seed_data,                    # Your DataFrame\n",
    "    sampling_strategy=\"shuffle\",  # Options: \"shuffle\", \"sequential\", or \"weighted\"\n",
    "    with_replacement=True,        # Whether to allow sampling the same row multiple times\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Loading seed data from a file\n",
    "# In practice, you would specify a real file path; this is just for demonstration\n",
    "\n",
    "# Uncomment this code to use with your own file\n",
    "\"\"\"\n",
    "# Load data from a CSV file\n",
    "file_seed_dd = gretel.data_designer.new(model_suite=model_suite)\n",
    "\n",
    "# Load data using pandas - works with CSV, Excel, JSON, etc.\n",
    "file_seed_df = pd.read_csv(\"your_data.csv\")  \n",
    "# Alternative: file_seed_df = pd.read_excel(\"your_data.xlsx\")\n",
    "# Alternative: file_seed_df = pd.read_json(\"your_data.json\")\n",
    "\n",
    "# Add the file-based seed dataset\n",
    "file_seed_dd.with_seed_dataset(\n",
    "    file_seed_df,\n",
    "    sampling_strategy=\"shuffle\",\n",
    "    with_replacement=True  # Set to True to generate datasets larger than your seed\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# For our example, we'll continue with our in-memory DataFrame\n",
    "# Now, let's enhance the seed data with synthetic columns\n",
    "\n",
    "# Add a discount column based on statistical distribution\n",
    "seed_dd.add_column(\n",
    "    C.SamplerColumn(\n",
    "        name=\"discount_percent\",\n",
    "        type=P.SamplingSourceType.UNIFORM,\n",
    "        params=P.UniformSamplerParams(low=0.0, high=0.3),\n",
    "        convert_to=\"float\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add a derived column that calculates the sale price\n",
    "seed_dd.add_column(\n",
    "    C.ExpressionColumn(\n",
    "        name=\"sale_price\",\n",
    "        expr=\"{{ (base_price * (1 - discount_percent)) | round(2) }}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add an LLM-generated product description referencing the seed data\n",
    "seed_dd.add_column(\n",
    "    C.LLMGenColumn(\n",
    "        name=\"product_description\",\n",
    "        prompt=(\n",
    "            \"Write a concise 2-3 sentence description for {{ product_name }} made by {{ manufacturer }}. \"\n",
    "            \"The product has a rating of {{ rating }} out of 5 stars and costs ${{ base_price }}. \"\n",
    "            \"Now on sale for ${{ sale_price }}.\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the enhanced seed-based data\n",
    "# We can generate more records than our original seed data when using with_replacement=True\n",
    "seed_dd.validate()\n",
    "seed_preview = seed_dd.preview()  # Generate 8 records from our 4-row seed\n",
    "seed_preview.dataset.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Structured Outputs\n",
    "\n",
    "When generating synthetic data with LLMs, you often need to ensure that the output follows a specific format or structure. This is especially important for applications that expect data to have a certain schema, such as APIs, databases, or data processing pipelines.\n",
    "\n",
    "Data Designer's structured output feature allows you to define precise schemas that LLM-generated data must conform to. \n",
    "\n",
    "Let's explore two ways to define structured outputs: using Pydantic models and using JSON Schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Using Pydantic Models for Structured Output\n",
    "# Pydantic is a data validation library that makes it easy to define data models\n",
    "\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "from typing import List, Optional\n",
    "\n",
    "# Define a model for individual review ratings\n",
    "class RatingBreakdown(BaseModel):\n",
    "    quality: int = Field(..., description=\"Rating for product quality (1-5)\")\n",
    "    value: int = Field(..., description=\"Rating for price-to-value ratio (1-5)\")\n",
    "    durability: int = Field(..., description=\"Rating for product durability (1-5)\")\n",
    "    appearance: int = Field(..., description=\"Rating for product appearance (1-5)\")\n",
    "    ease_of_use: int = Field(..., description=\"Rating for ease of use (1-5)\")\n",
    "\n",
    "# Define a model for product pros and cons\n",
    "class ProsAndCons(BaseModel):\n",
    "    pros: List[str] = Field(..., description=\"List of product pros/positive aspects\")\n",
    "    cons: List[str] = Field(..., description=\"List of product cons/negative aspects\")\n",
    "\n",
    "# Define a model for a detailed product review\n",
    "class DetailedReview(BaseModel):\n",
    "    overall_rating: float = Field(..., description=\"Overall product rating (1.0-5.0)\")\n",
    "    title: str = Field(..., description=\"Review title\")\n",
    "    content: str = Field(..., description=\"Main review content\")\n",
    "    rating_breakdown: RatingBreakdown = Field(..., description=\"Detailed ratings by category\")\n",
    "    pros_and_cons: ProsAndCons = Field(..., description=\"Lists of pros and cons\")\n",
    "    verified_purchase: bool = Field(..., description=\"Whether this is a verified purchase\")\n",
    "    would_recommend: bool = Field(..., description=\"Whether the reviewer would recommend this product\")\n",
    "    usage_duration: Optional[str] = Field(None, description=\"How long the reviewer has used the product\")\n",
    "\n",
    "# Create a new Data Designer instance\n",
    "structured_dd = gretel.data_designer.new(model_suite=model_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up basic product information\n",
    "structured_dd.add_column(\n",
    "    name=\"product_category\",\n",
    "    type=\"category\",\n",
    "    params={\"values\": [\"Electronics\", \"Home & Kitchen\", \"Sports & Outdoors\", \"Beauty & Personal Care\"]}\n",
    ")\n",
    "\n",
    "structured_dd.add_column(\n",
    "    name=\"product_name\",\n",
    "    type=\"llm-text\",\n",
    "    prompt=\"Generate a realistic product name for a {{ product_category }} item.\"\n",
    ")\n",
    "\n",
    "# Now, here's the key part - using our Pydantic model to structure the LLM output\n",
    "structured_dd.add_column(\n",
    "    name=\"detailed_review\",\n",
    "    type=\"llm-structured\",\n",
    "    prompt=(\n",
    "        \"Write a detailed product review for a {{ product_name }} in the {{ product_category }} category. \"\n",
    "        \"The review should be detailed and realistic, covering both positive and negative aspects.\"\n",
    "    ),\n",
    "    # The output_format parameter tells the LLM to generate data conforming to our model\n",
    "    output_format=DetailedReview\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the structured output - note how it follows our Pydantic schema exactly\n",
    "structured_dd.validate()\n",
    "preview = structured_dd.preview()\n",
    "preview.dataset.df\n",
    "\n",
    "# Display a nicely formatted sample to better see the structured data\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Using JSON Schema for Structured Output\n",
    "# JSON Schema is a standard for describing the structure of JSON data\n",
    "\n",
    "# Define a detailed review schema using JSON Schema that matches our Pydantic model\n",
    "review_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"overall_rating\": {\n",
    "            \"type\": \"number\",\n",
    "            \"description\": \"Overall product rating (1.0-5.0)\"\n",
    "        },\n",
    "        \"title\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Review title\"\n",
    "        },\n",
    "        \"content\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Main review content\"\n",
    "        },\n",
    "        \"rating_breakdown\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"quality\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Rating for product quality (1-5)\"\n",
    "                },\n",
    "                \"value\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Rating for price-to-value ratio (1-5)\"\n",
    "                },\n",
    "                \"durability\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Rating for product durability (1-5)\"\n",
    "                },\n",
    "                \"appearance\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Rating for product appearance (1-5)\"\n",
    "                },\n",
    "                \"ease_of_use\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Rating for ease of use (1-5)\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"quality\", \"value\", \"durability\", \"appearance\", \"ease_of_use\"],\n",
    "            \"description\": \"Detailed ratings by category\"\n",
    "        },\n",
    "        \"pros_and_cons\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"pros\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of product pros/positive aspects\"\n",
    "                },\n",
    "                \"cons\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\"type\": \"string\"},\n",
    "                    \"description\": \"List of product cons/negative aspects\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"pros\", \"cons\"],\n",
    "            \"description\": \"Lists of pros and cons\"\n",
    "        },\n",
    "        \"verified_purchase\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"Whether this is a verified purchase\"\n",
    "        },\n",
    "        \"would_recommend\": {\n",
    "            \"type\": \"boolean\",\n",
    "            \"description\": \"Whether the reviewer would recommend this product\"\n",
    "        },\n",
    "        \"usage_duration\": {\n",
    "            \"type\": [\"string\", \"null\"],\n",
    "            \"description\": \"How long the reviewer has used the product\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\n",
    "        \"overall_rating\", \n",
    "        \"title\", \n",
    "        \"content\", \n",
    "        \"rating_breakdown\", \n",
    "        \"pros_and_cons\", \n",
    "        \"verified_purchase\", \n",
    "        \"would_recommend\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create another Data Designer instance for our JSON Schema example\n",
    "json_schema_dd = gretel.data_designer.new(model_suite=model_suite)\n",
    "\n",
    "# Use the same product info setup as the Pydantic example\n",
    "json_schema_dd.add_column(\n",
    "    name=\"product_category\",\n",
    "    type=\"category\",\n",
    "    params={\"values\": [\"Electronics\", \"Home & Kitchen\", \"Sports & Outdoors\", \"Beauty & Personal Care\"]}\n",
    ")\n",
    "\n",
    "json_schema_dd.add_column(\n",
    "    name=\"product_name\",\n",
    "    type=\"llm-text\",\n",
    "    prompt=\"Generate a realistic product name for a {{ product_category }} item.\"\n",
    ")\n",
    "\n",
    "# Add the structured review column using JSON Schema\n",
    "json_schema_dd.add_column(\n",
    "    name=\"detailed_review\",\n",
    "    type=\"llm-structured\",\n",
    "    prompt=(\n",
    "        \"Write a detailed product review for a {{ product_name }} in the {{ product_category }} category. \"\n",
    "        \"The review should be detailed and realistic, covering both positive and negative aspects.\"\n",
    "    ),\n",
    "    # Note how we use json_schema instead of model for JSON Schema-based structured output\n",
    "    output_format=review_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the JSON Schema structured output\n",
    "preview = json_schema_dd.preview()\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a batch job\n",
    "Let's generate a small dataset of review records and analyze them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Generate 5 review records\n",
    "review_results = json_schema_dd.create(\n",
    "    num_records=100,\n",
    "    name=\"structured_reviews\",\n",
    "    wait_for_completion=True\n",
    ")\n",
    "\n",
    "# Access the structured data\n",
    "reviews_df = review_results.dataset.df\n",
    "\n",
    "# With structured data, you can access nested fields using dot notation or by parsing the JSON\n",
    "# Here we'll look at the review titles and overall ratings\n",
    "reviews_df[['detailed_review.title', 'detailed_review.overall_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and analyze data from our structured output\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Function to extract data from the structured review JSON\n",
    "def extract_review_info(row):\n",
    "    review = json.loads(row['detailed_review']) if isinstance(row['detailed_review'], str) else row['detailed_review']\n",
    "    \n",
    "    # Extract the rating breakdown sub-object\n",
    "    ratings = review['rating_breakdown']\n",
    "    \n",
    "    # Create a series with the extracted data\n",
    "    return pd.Series({\n",
    "        'overall_rating': review['overall_rating'],\n",
    "        'title_length': len(review['title']),\n",
    "        'content_length': len(review['content']),\n",
    "        'quality_rating': ratings['quality'],\n",
    "        'value_rating': ratings['value'],\n",
    "        'durability_rating': ratings['durability'],\n",
    "        'appearance_rating': ratings['appearance'],\n",
    "        'ease_of_use_rating': ratings['ease_of_use'],\n",
    "        'pros_count': len(review['pros_and_cons']['pros']),\n",
    "        'cons_count': len(review['pros_and_cons']['cons']),\n",
    "        'verified_purchase': review['verified_purchase'],\n",
    "        'would_recommend': review['would_recommend'],\n",
    "        'product_category': row['product_category']\n",
    "    })\n",
    "\n",
    "# Apply our extraction function to create a new DataFrame with the extracted data\n",
    "review_details = reviews_df.apply(extract_review_info, axis=1)\n",
    "\n",
    "# Now we can easily analyze the data - for example, calculating averages by product category\n",
    "review_details.groupby('product_category').agg({\n",
    "    'overall_rating': 'mean',\n",
    "    'quality_rating': 'mean',\n",
    "    'value_rating': 'mean',\n",
    "    'would_recommend': 'mean',  # Proportion that would recommend\n",
    "    'verified_purchase': 'mean'  # Proportion of verified purchases\n",
    "}).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also extract nested fields like the pros and cons\n",
    "# Let's collect all pros and cons across our reviews\n",
    "\n",
    "all_points = []\n",
    "for _, row in reviews_df.iterrows():\n",
    "    review = json.loads(row['detailed_review']) if isinstance(row['detailed_review'], str) else row['detailed_review']\n",
    "    product = row['product_name']\n",
    "    category = row['product_category']\n",
    "    \n",
    "    # Extract all pros\n",
    "    for point in review['pros_and_cons']['pros']:\n",
    "        all_points.append({\n",
    "            'product': product,\n",
    "            'category': category,\n",
    "            'type': 'pro',\n",
    "            'point': point\n",
    "        })\n",
    "    \n",
    "    # Extract all cons\n",
    "    for point in review['pros_and_cons']['cons']:\n",
    "        all_points.append({\n",
    "            'product': product,\n",
    "            'category': category,\n",
    "            'type': 'con',\n",
    "            'point': point\n",
    "        })\n",
    "\n",
    "# Create a DataFrame of all pros and cons\n",
    "points_df = pd.DataFrame(all_points)\n",
    "points_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed a comprehensive tour of Data Designer's core capabilities. In this tutorial, you've learned how to:\n",
    "\n",
    "1. Set up a Data Designer project\n",
    "2. Create various types of sampler columns (categorical, numerical, date/time, UUID)\n",
    "3. Define relationships between columns using subcategories\n",
    "4. Use expression columns with Jinja templates to create derived values\n",
    "5. Generate realistic person data with demographic details\n",
    "6. Create complex order and transaction data\n",
    "7. Use LLMs to generate contextual text like descriptions and reviews\n",
    "8. Add constraints to ensure data validity\n",
    "9. Generate and save your dataset\n",
    "10. Work with seed data from your own dataframes or files\n",
    "11. Create structured outputs using both Pydantic models and JSON Schema\n",
    "\n",
    "With these skills, you're well-equipped to create sophisticated synthetic datasets for a wide range of applications, from testing and development to privacy protection and AI training.\n",
    "\n",
    "Check out the other notebooks in this repository for more examples and specialized use cases!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
