{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMMHiDmEcYZY"
   },
   "source": [
    "# ðŸŽ¨ Gretel - Navigator Data Designer SDK: Text-to-Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNoaC7dX28y0"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U gretel_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k5NjjtzPQJi"
   },
   "outputs": [],
   "source": [
    "from gretel_client.navigator import DataDesigner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2NzEYJedJeA"
   },
   "source": [
    "## ðŸ“˜ Text-to-Python Configuration\n",
    "\n",
    "Below we show an example Text-to-Python `DataDesigner` configuration. The main sections are as follow:\n",
    "\n",
    "- **model_suite:** You can use `apache-2.0` or `llama-3.x` depending on the type of license you want associated with the data you generate. Selecting `apache-2.0` ensures that all models used by Data Designer comply with the `apache-2.0` license and using `llama-3.x` means the models used by Data Designer will fall under the `Llama 3` license.\n",
    "\n",
    "- **special_system_instructions:** This is an optional use-case-specific instruction to be added to the system prompt of all LLMs used during synthetic data generation.\n",
    "\n",
    "- **categorical_seed_columns:** Specifies categorical data seed columns that will be used to seed the synthetic data generation process. Here we fully specify all seed categories and subcategories. It is also possible to generate category values using the `num_new_values_to_generate` parameter.\n",
    "\n",
    "- **generated_data_columns:** Specifies data columns that are fully generated using LLMs, seeded by the categorical seed columns. The `generation_prompt` field is the prompt template that will be used to generate the data column. All data seeds and previously defined data columns can be used as template keyword arguments.\n",
    "\n",
    "- **post_processors:** Specifics validation / evaluation / processing that is applied to the dataset after generation. Here, we define a code validator and the `text_to_python` evaluation suite.\n",
    "\n",
    "To run the code you need to get your Gretel Api Key from https://console.gretel.ai/users/me/key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_string = \"\"\"\n",
    "model_suite: apache-2.0\n",
    "\n",
    "special_system_instructions: >-\n",
    "  You are an expert conversation designer and domain specialist. Your job is to\n",
    "  produce realistic user-assistant dialogues for fine-tuning a model. Always ensure:\n",
    "  - Responses are factually correct and contextually appropriate.\n",
    "  - Communication is clear, helpful, and matches the complexity level.\n",
    "  - Avoid disallowed content and toxicity.\n",
    "  - After the two-turn conversation, provide a single toxicity assessment for the user's messages in the entire conversation.\n",
    "\n",
    "categorical_seed_columns:\n",
    "  - name: domain\n",
    "    values: [Tech Support, Personal Finances, Educational Guidance]\n",
    "    subcategories:\n",
    "      - name: topic\n",
    "        values:\n",
    "          Tech Support:\n",
    "            - Troubleshooting a Laptop\n",
    "            - Setting Up a Home Wi-Fi Network\n",
    "            - Installing Software Updates\n",
    "          Personal Finances:\n",
    "            - Budgeting Advice\n",
    "            - Understanding Taxes\n",
    "            - Investment Strategies\n",
    "          Educational Guidance:\n",
    "            - Choosing a College Major\n",
    "            - Effective Studying Techniques\n",
    "            - Learning a New Language\n",
    "        num_new_values_to_generate: 3\n",
    "    num_new_values_to_generate: 3\n",
    "\n",
    "  - name: complexity\n",
    "    values: [Basic, Intermediate, Advanced]\n",
    "\n",
    "generated_data_columns:\n",
    "  # Turn 1: User initial message\n",
    "  - name: user_message\n",
    "    generation_prompt: >-\n",
    "      The user is seeking help or information in the {domain} domain, specifically about the topic of {topic}, at a {complexity} complexity level.\n",
    "      \n",
    "      The user_message should:\n",
    "      - Sound natural and realistic.\n",
    "      - Avoid disallowed content (e.g., harassment, hate, extremely sensitive requests).\n",
    "      - Reflect the specified domain, topic, and complexity level.\n",
    "\n",
    "  # Turn 1: Assistant responds\n",
    "  - name: assistant_message\n",
    "    generation_prompt: >-\n",
    "      As a helpful assistant, write a response to the user's query below:\n",
    "      Query: {user_message}\\n\n",
    "      \n",
    "      Instructions:\n",
    "      - Provide a clear, accurate, and contextually relevant response.\n",
    "      - Be correct, non-toxic, and helpful.\n",
    "      - Avoid disallowed content. If the request is disallowed, provide a safe refusal.\n",
    "      - To encourage variety, do not always start your response with the same phrase (e.g., avoid always beginning with \"Certainly!\"). \n",
    "      - You can start directly addressing the user's question or use different acknowledgments like \"Of course,\", \"Sure,\", \"Let's see,\" or simply begin explaining.\n",
    "      - Only provide the message, do not add headers, explanations, or assessments.\n",
    "\n",
    "  # Turn 2: User follows up\n",
    "  - name: user_message_2\n",
    "    generation_prompt: >-\n",
    "      The user now follows up on the assistant_message.\n",
    "      Previous User Query: {user_message}\\n\n",
    "      Previous Assistant Response: {assistant_message}\\n\n",
    "      \n",
    "      The second user_message should:\n",
    "      - Be a logical follow-up or request for clarification or more detail based on the assistant's prior response.\n",
    "      - Maintain the same domain, topic, and complexity.\n",
    "      - Sound natural and realistic.\n",
    "      - Avoid disallowed content.\n",
    "    columns_to_list_in_prompt: all_categorical_seed_columns\n",
    "\n",
    "  # Turn 2: Assistant responds again\n",
    "  - name: assistant_message_2\n",
    "    generation_prompt: >-\n",
    "      The user has followed up with another query:\n",
    "      Previous User Query: {user_message}\\n\n",
    "      Previous Assistant Response: {assistant_message}\\n\n",
    "      New User Query: {user_message_2}\\n\n",
    "      \n",
    "      Instructions:\n",
    "      - Provide a clear, accurate, and contextually relevant follow-up response.\n",
    "      - Maintain the complexity level and continue to be non-toxic and helpful.\n",
    "      - Avoid disallowed content. If the request is disallowed, provide a safe refusal.\n",
    "      - Again, do not always start with the same phrase. Vary your opening or start directly.\n",
    "      - Only provide the message, do not add headers, explanations, or assessments.\n",
    "    columns_to_list_in_prompt: all_categorical_seed_columns\n",
    "\n",
    "  # Toxicity Label for the entire 2-turn conversation\n",
    "  - name: toxicity_label\n",
    "    generation_prompt: >-\n",
    "      Analyze all user messages in this two-turn conversation and determine the overall toxicity level of the user's behavior.\n",
    "      \n",
    "      Consider:\n",
    "      - First User Message: {user_message}\n",
    "      - Assistant Response: {assistant_message}\n",
    "      - Second User Message: {user_message_2}\n",
    "      - Assistant Response: {assistant_message_2}\n",
    "      \n",
    "      Focus primarily on the user's messages to detect any disallowed content, harassment, hate, or harmful language.\n",
    "      If any user message exhibits toxicity, reflect it in the final label.\n",
    "      \n",
    "      Possible categories:\n",
    "      - \"None\": No toxicity detected in user messages.\n",
    "      - \"Mild\": Slightly rude or sarcastic but not hateful or harmful.\n",
    "      - \"Moderate\": Some disrespectful or harassing language.\n",
    "      - \"Severe\": Overt hate, harassment, or harmful content.\n",
    "      \n",
    "      Provide only one label. If all user messages are polite and safe, label \"None\".\n",
    "      Do not elaborate beyond providing the label.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data_designer = DataDesigner.from_config(config_string, api_key=\"prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDxYu6azd3c4"
   },
   "source": [
    "## ðŸ‘€ Generating a dataset preview\n",
    "\n",
    "- Preview mode allows you to quickly iterate on your data design.\n",
    "\n",
    "- Each preview generation call creates 10 records for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ef8Ws90cPbIu"
   },
   "outputs": [],
   "source": [
    "preview = data_designer.generate_dataset_preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5I2GjczNh_s"
   },
   "outputs": [],
   "source": [
    "# The preview dataset is accessible as a DataFrame\n",
    "preview.dataset[[\"domain\",\"topic\"]].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjYiKmcWd_2t"
   },
   "source": [
    "## ðŸ”Ž Easily inspect individual records\n",
    "\n",
    "- Run the cell below to display individual records for inspection.\n",
    "\n",
    "- Run the cell multiple times to cycle through the 10 preview records.\n",
    "\n",
    "- Alternatively, you can pass the `index` argument to `display_sample_record` to display a specific record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAWaJKnAP8ZJ"
   },
   "outputs": [],
   "source": [
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMjFAR0Yenrk"
   },
   "source": [
    "## ðŸ¤” Like what you see?\n",
    "\n",
    "- Submit a batch workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VziAxDPtQEes"
   },
   "outputs": [],
   "source": [
    "batch_job = data_designer.submit_batch_workflow(num_records=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dY1XI8q-Ru4z"
   },
   "outputs": [],
   "source": [
    "# Check to see if the Workflow is still active.\n",
    "batch_job.workflow_run_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDAG5KmQeQ0m"
   },
   "outputs": [],
   "source": [
    "df = batch_job.fetch_dataset(wait_for_completion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4joRe9aJZCM"
   },
   "outputs": [],
   "source": [
    "path = batch_job.download_evaluation_report(wait_for_completion=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOULXxjB7a5FBgCdNl8vi0v",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
