{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMMHiDmEcYZY"
   },
   "source": [
    "# üé® Gretel - Navigator Data Designer SDK: Conversational Data Synthesis\n",
    "\n",
    "This notebook demonstrates how to use the Gretel Navigator SDK to build a synthetic data generation pipeline step-by-step, rather than using a single YAML configuration. We will create multi-turn user-assistant dialogues tailored for fine-tuning language models. These synthetic dialogues can then be used as domain-specific training data to improve model performance in targeted scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNoaC7dX28y0"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U gretel_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k5NjjtzPQJi"
   },
   "outputs": [],
   "source": [
    "from gretel_client.navigator import DataDesigner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2NzEYJedJeA"
   },
   "source": [
    "## ‚öôÔ∏è Data Designer Configuration with the SDK\n",
    "\n",
    "Instead of relying on a single YAML configuration file, we construct our pipeline interactively. This provides granular control over how we guide LLMs to produce realistic, domain-specific conversations. By adjusting prompts, seed data, and instructions, we can quickly iterate and refine our data generation process.\n",
    "\n",
    "### Choosing the Model Suite\n",
    "When initializing the `DataDesigner`, you can specify a `model_suite` (e.g., `apache-2.0` or `llama-3.x`). This choice determines the models and associated licenses used during data generation. Choose a suite that aligns with your compliance and licensing requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_designer = DataDesigner(\n",
    "    api_key=\"prompt\",\n",
    "    model_suite=\"apache-2.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Special System Instructions\n",
    "\n",
    "We can provide global guidance (system instructions) to the underlying LLMs. This ensures the generated dialogues follow specific rules, maintain factual accuracy, and avoid disallowed content. These instructions will influence all subsequent generated text, helping maintain consistency and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_designer.special_system_instructions = \"\"\"\n",
    "    You are an expert conversation designer and domain specialist. Your job is to\n",
    "    produce realistic user-assistant dialogues for fine-tuning a model. Always ensure:\n",
    "    - Responses are factually correct and contextually appropriate.\n",
    "    - Communication is clear, helpful, and matches the complexity level.\n",
    "    - Avoid disallowed content and toxicity.\n",
    "    - After the two-turn conversation, provide a single toxicity assessment for the user's messages in the entire conversation.\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Categorical Seed Columns\n",
    "\n",
    "We define categorical seed columns that set the context for the generated dialogues. For example, domain and topic determine what the conversation is about, while complexity guides the level of detail and difficulty. By using `num_new_values_to_generate`, we can automatically expand the range of topics or domains, increasing the diversity of generated data without manually specifying all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_designer.add_categorical_seed_column(\n",
    "    name=\"domain\",\n",
    "    description=\"The domain of user assistant queries\",\n",
    "    values=[\"Tech Support\", \"Personal Finances\", \"Educational Guidance\"],\n",
    "    subcategories=[\n",
    "        {\n",
    "            \"name\": \"topic\",\n",
    "            \"values\": {\n",
    "                \"Tech Support\": [\n",
    "                    \"Troubleshooting a Laptop\",\n",
    "                    \"Setting Up a Home Wi-Fi Network\",\n",
    "                    \"Installing Software Updates\"\n",
    "                ],\n",
    "                \"Personal Finances\": [\n",
    "                    \"Budgeting Advice\",\n",
    "                    \"Understanding Taxes\",\n",
    "                    \"Investment Strategies\"\n",
    "                ],\n",
    "                \"Educational Guidance\": [\n",
    "                    \"Choosing a College Major\",\n",
    "                    \"Effective Studying Techniques\",\n",
    "                    \"Learning a New Language\"\n",
    "                ]\n",
    "            },\n",
    "            \"num_new_values_to_generate\": 3\n",
    "        }\n",
    "    ],\n",
    "    num_new_values_to_generate=3\n",
    ")\n",
    "\n",
    "data_designer.add_categorical_seed_column(\n",
    "    name=\"complexity\",\n",
    "    description=\"The complexity level of the user query\",\n",
    "    values=[\"Basic\", \"Intermediate\", \"Advanced\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Generated Data Columns\n",
    "We now define the columns that the model will generate. These prompts instruct the LLM to produce the actual conversation: a user query (user_message), the assistant‚Äôs response (assistant_message), a follow-up user query (user_message_2), and another assistant response (assistant_message_2). Finally, we generate a toxicity_label to assess user toxicity over the entire conversation.\n",
    "\n",
    "You can easily modify or refine these prompt templates to adjust the style, complexity, or constraints of the generated data. Maintaining continuity and consistency across turns ensures the dialogues are realistic and useful for fine-tuning.\n",
    "\n",
    "#### Turn 1: User Message and Assistant Response\n",
    "\n",
    "In the first turn, we define the user_message column to simulate the user's initial query and then the assistant_message column for the assistant's reply. Ensuring that the assistant message does not always start the same way helps produce more natural variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User initial message\n",
    "data_designer.add_generated_data_column(\n",
    "    name=\"user_message\",\n",
    "    generation_prompt=(\n",
    "        \"The user is seeking help or information in the {domain} domain, specifically about the topic of {topic}, \"\n",
    "        \"at a {complexity} complexity level.\\n\\n\"\n",
    "        \"The user_message should:\\n\"\n",
    "        \"- Sound natural and realistic.\\n\"\n",
    "        \"- Avoid disallowed content.\\n\"\n",
    "        \"- Reflect the specified domain, topic, and complexity level.\\n\"\n",
    "        \"- Do not include headers, explanations, or assessments.\\n\"\n",
    "        \"- Do not include formatting like '## ...' or similar.\\n\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Assistant responds\n",
    "data_designer.add_generated_data_column(\n",
    "    name=\"assistant_message\",\n",
    "    generation_prompt=(\n",
    "        \"As a helpful assistant, write a response to the user's query below:\\n\"\n",
    "        \"Query: {user_message}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Provide a clear, accurate, and contextually relevant response.\\n\"\n",
    "        \"- Be correct, non-toxic, and helpful.\\n\"\n",
    "        \"- Avoid disallowed content. If the request is disallowed, provide a safe refusal.\\n\"\n",
    "        \"- To encourage variety, do not always start your response with the same phrase.\\n\"\n",
    "        \"- Only provide the message, do not add headers, explanations, or assessments.\\n\"\n",
    "        \"- Do not include formatting like '## ...' or similar.\\n\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn 2: User Follow-Up and Assistant Response\n",
    "In the second turn, the user sends a follow-up message, and the assistant responds again, maintaining continuity, complexity, and context. The user‚Äôs follow-up should logically build on the previous exchange, and the assistant should reflect the given complexity level, ensuring cohesive multi-turn dialogues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User follows up\n",
    "data_designer.add_generated_data_column(\n",
    "    name=\"user_message_2\",\n",
    "    generation_prompt=(\n",
    "        \"The user now follows up on the assistant_message.\\n\"\n",
    "        \"Previous User Query: {user_message}\\n\"\n",
    "        \"Previous Assistant Response: {assistant_message}\\n\\n\"\n",
    "        \"The second user_message should:\\n\"\n",
    "        \"- Be a logical follow-up or request for clarification or more detail based on the assistant's prior response.\\n\"\n",
    "        \"- Maintain the same domain, topic, and complexity.\\n\"\n",
    "        \"- Sound natural and realistic.\\n\"\n",
    "        \"- Avoid disallowed content.\\n\"\n",
    "        \"- Do not start with 'Could you provide' or similar repetitive phrasing. Vary the question style.\\n\"\n",
    "        \"- Do not include headers, explanations, or assessments.\\n\"\n",
    "        \"- Do not include formatting like '## ...' or similar.\\n\"\n",
    "    ),\n",
    "    columns_to_list_in_prompt=\"all_categorical_seed_columns\"\n",
    ")\n",
    "\n",
    "# Assistant responds again\n",
    "data_designer.add_generated_data_column(\n",
    "    name=\"assistant_message_2\",\n",
    "    generation_prompt=(\n",
    "        \"The user has followed up with another query:\\n\"\n",
    "        \"Previous User Query: {user_message}\\n\"\n",
    "        \"Previous Assistant Response: {assistant_message}\\n\"\n",
    "        \"New User Query: {user_message_2}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Provide a clear, accurate, and contextually relevant follow-up response.\\n\"\n",
    "        \"- Maintain the complexity level and continue to be non-toxic and helpful.\\n\"\n",
    "        \"- Avoid disallowed content. If the request is disallowed, provide a safe refusal.\\n\"\n",
    "        \"- Vary your opening or start directly, do not always begin the same way.\\n\"\n",
    "        \"- Only provide the message, do not add headers, explanations, or assessments.\\n\"\n",
    "        \"- Do not include formatting like '## ...' or similar.\\n\"\n",
    "    ),\n",
    "    columns_to_list_in_prompt=\"all_categorical_seed_columns\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessment Column: Toxicity Label\n",
    "For the final step, we add a toxicity assessment column to classify the overall toxicity level of the user's messages across the entire two-turn conversation. By setting llm_type='judge', we ensure that a specialized classification model is used, making it well-suited for tasks like toxicity evaluation. This helps ensure that the final dataset is safe and compliant with given standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toxicity Label for the entire 2-turn conversation\n",
    "# Note: We set `llm_type='judge'` to indicate we are using a classification/judgment model.\n",
    "\n",
    "data_designer.add_generated_data_column(\n",
    "    name=\"toxicity_label\",\n",
    "    generation_prompt=(\n",
    "        \"Analyze all user messages in this two-turn conversation and determine the overall toxicity level of the user's behavior.\\n\\n\"\n",
    "        \"Consider:\\n\"\n",
    "        \"- First User Message: {user_message}\\n\"\n",
    "        \"- Assistant Response: {assistant_message}\\n\"\n",
    "        \"- Second User Message: {user_message_2}\\n\"\n",
    "        \"- Assistant Response: {assistant_message_2}\\n\\n\"\n",
    "        \"Focus primarily on the user's messages to detect any disallowed content, harassment, hate, or harmful language.\\n\"\n",
    "        \"If any user message exhibits toxicity, reflect it in the final label.\\n\\n\"\n",
    "        \"Possible categories:\\n\"\n",
    "        \"- \\\"None\\\": No toxicity detected in user messages.\\n\"\n",
    "        \"- \\\"Mild\\\": Slightly rude or sarcastic but not hateful or harmful.\\n\"\n",
    "        \"- \\\"Moderate\\\": Some disrespectful or harassing language.\\n\"\n",
    "        \"- \\\"Severe\\\": Overt hate, harassment, or harmful content.\\n\\n\"\n",
    "        \"Provide only one label. If all user messages are polite and safe, label \\\"None\\\".\\n\"\n",
    "        \"Do not elaborate beyond providing the label.\"\n",
    "    ),\n",
    "    llm_type=\"judge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÄ Generating a dataset preview\n",
    "\n",
    "- Preview mode allows you to quickly iterate on your data design.\n",
    "\n",
    "- Each preview generation call creates 10 records for inspection, helping you verify prompts and instructions before running a larger batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a preview\n",
    "preview = data_designer.generate_dataset_preview(num_records=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Easily inspect individual records\n",
    "\n",
    "- Run the cell below to display individual records for inspection.\n",
    "\n",
    "- Run the cell multiple times to cycle through the 10 preview records.\n",
    "\n",
    "- Alternatively, you can pass the `index` argument to `display_sample_record` to display a specific record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAWaJKnAP8ZJ"
   },
   "outputs": [],
   "source": [
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMjFAR0Yenrk"
   },
   "source": [
    "## ü§î Like what you see?\n",
    "\n",
    "- Submit a batch workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VziAxDPtQEes"
   },
   "outputs": [],
   "source": [
    "batch_job = data_designer.submit_batch_workflow(num_records=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dY1XI8q-Ru4z"
   },
   "outputs": [],
   "source": [
    "# Check to see if the Workflow is still active.\n",
    "batch_job.workflow_run_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDAG5KmQeQ0m"
   },
   "outputs": [],
   "source": [
    "df = batch_job.fetch_dataset(wait_for_completion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4joRe9aJZCM"
   },
   "outputs": [],
   "source": [
    "path = batch_job.download_evaluation_report(wait_for_completion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following these steps and leveraging the interactivity of the SDK, you can refine prompts, generate realistic dialogues, and ensure the resulting dataset is high-quality, non-toxic, and aligned with your domain-specific requirements."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOULXxjB7a5FBgCdNl8vi0v",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
