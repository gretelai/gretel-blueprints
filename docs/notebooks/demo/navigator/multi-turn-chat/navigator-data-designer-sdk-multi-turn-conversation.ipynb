{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/demo/navigator/navigator-data-designer-sdk-multi-turn-conversation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMMHiDmEcYZY"
   },
   "source": [
    "# üé® Gretel - Navigator Data Designer SDK: Synthetic Conversational Data\n",
    "\n",
    "This notebook demonstrates how to use the Gretel Navigator SDK to build a synthetic data generation pipeline step-by-step. We will create multi-turn user-assistant dialogues tailored for fine-tuning language models. These synthetic dialogues can then be used as domain-specific training data to improve model performance in targeted scenarios.\n",
    "\n",
    "These datasets could be used for developing and enhancing conversational AI applications, including customer support chatbots, virtual assistants, and interactive learning systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNoaC7dX28y0"
   },
   "outputs": [],
   "source": [
    "%pip install -Uqq gretel_client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1k5NjjtzPQJi"
   },
   "outputs": [],
   "source": [
    "from gretel_client.navigator import DataDesigner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2NzEYJedJeA"
   },
   "source": [
    "## ‚öôÔ∏è Data Designer Configuration with the SDK\n",
    "\n",
    "Instead of relying on a single YAML configuration file, here we build up our pipeline interactively. This provides granular control over how we guide LLMs to produce realistic, domain-specific conversations. By adjusting prompts, seed data, and instructions, we can quickly iterate and refine our data generation process.\n",
    "\n",
    "### üìö Choosing the Model Suite\n",
    "Specify the `model_suite` to determine which models and associated licenses are used during data generation.\n",
    "For example, use `apache-2.0` for open-source-friendly licensing or `llama-3.x` or `amazon-nova` for advanced proprietary models.\n",
    "Select the suite based on compliance and licensing requirements relevant to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available model suites: apache-2.0, llama-3.x, amazon-nova\n",
    "model_suite = \"apache-2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Setting Special System Instructions\n",
    "\n",
    "Provide system-wide instructions for the underlying LLMs to guide the data generation process. These instructions influence all generated dialogues, ensuring consistency, quality, and adherence to desired rules. The instructions specify guidelines for factual accuracy, contextual relevance, and tone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_system_instructions = \"\"\"\\\n",
    "You are an expert conversation designer and domain specialist. Your job is to\n",
    "produce realistic user-assistant dialogues for fine-tuning a model. Don't include ### Response ### in your response.\n",
    "Do not prefix your responses with column names and only provide your response. \n",
    "Always ensure:\n",
    "    - Responses are factually correct and contextually appropriate.\n",
    "    - Communication is clear, helpful, and matches the complexity level.\n",
    "    - Avoid disallowed content and toxicity.\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Initialize Gretel Navigator Data Designer\n",
    "\n",
    "Instantiate the `DataDesigner` with the [Gretel API key](https://console.gretel.ai/users/me/key), chosen model suite, and special system instructions.\n",
    "This initializes the pipeline and ensures that all subsequent synthetic data generation adheres to the defined parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_designer = DataDesigner(\n",
    "    api_key=\"prompt\",\n",
    "    model_suite=model_suite,\n",
    "    endpoint=\"https://api.gretel.cloud\",\n",
    "    special_system_instructions=special_system_instructions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Structured Outputs to make sure your data is in the right format\n",
    "\n",
    "You can use Pydantic to define a structure for the messages that are produced by Data Designer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Message(BaseModel):\n",
    "    \"\"\"A single message turn in the conversation.\"\"\"\n",
    "    role: Literal[\"user\", \"assistant\"] = Field(..., description=\"Which role is writing the message.\")\n",
    "    content: str = Field(..., description=\"Message contents.\")\n",
    "    \n",
    "    \n",
    "class ChatConversation(BaseModel):\n",
    "    \"\"\"A chat conversation between a user and an AI assistant.\n",
    "    * All conversations are initiated by the user role.\n",
    "    * The assistant role always responds the the user message.\n",
    "    * Turns alternate between user and assistant roles.\n",
    "    * The last message is always from the assistant role.\n",
    "    * Message content can be long or short.\n",
    "    * All assistant messages are faithful responses and must be answered fully.\n",
    "    \"\"\"\n",
    "    conversation: list[Message] = Field(..., description=\"List of all messages in the conversation.\")\n",
    "    \n",
    "    \n",
    "class UserToxicityScore(BaseModel):\n",
    "    \"\"\"Output format for user toxicity assessment.\n",
    "    \n",
    "    Toxicity Scores:\n",
    "    None: No toxicity detected in user messages.\n",
    "    Mild: Slightly rude or sarcastic but not hateful or harmful.\n",
    "    Moderate: Some disrespectful or harassing language.\n",
    "    Severe: Overt hate, harassment, or harmful content.\n",
    "    \"\"\"\n",
    "    reasons: list[str] = Field(..., description=\"Reasoning for user toxicity score.\")\n",
    "    score: Literal[\"None\", \"Mild\", \"Moderate\", \"Severe\"] = Field(..., description=\"Level of toxicity observed in the user role responses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üå± Adding Categorical Seed Columns\n",
    "\n",
    "We define categorical seed columns that set the context for the generated dialogues. For example, domain and topic determine what the conversation is about, while complexity guides the level of detail and difficulty. By using `num_new_values_to_generate`, we can automatically expand the range of topics or domains, increasing the diversity of generated data without manually specifying all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_designer.add_categorical_seed_column(\n",
    "    name=\"domain\",\n",
    "    description=\"The domain of user assistant queries\",\n",
    "    values=[\"Tech Support\", \"Personal Finances\", \"Educational Guidance\"],\n",
    "    subcategories=[\n",
    "        {\n",
    "            \"name\": \"topic\",\n",
    "            \"values\": {\n",
    "                \"Tech Support\": [\n",
    "                    \"Troubleshooting a Laptop\",\n",
    "                    \"Setting Up a Home Wi-Fi Network\",\n",
    "                    \"Installing Software Updates\"\n",
    "                ],\n",
    "                \"Personal Finances\": [\n",
    "                    \"Budgeting Advice\",\n",
    "                    \"Understanding Taxes\",\n",
    "                    \"Investment Strategies\"\n",
    "                ],\n",
    "                \"Educational Guidance\": [\n",
    "                    \"Choosing a College Major\",\n",
    "                    \"Effective Studying Techniques\",\n",
    "                    \"Learning a New Language\"\n",
    "                ]\n",
    "            },\n",
    "            \"num_new_values_to_generate\": 2\n",
    "        }\n",
    "    ],\n",
    "    num_new_values_to_generate=5\n",
    ")\n",
    "\n",
    "data_designer.add_categorical_seed_column(\n",
    "    name=\"complexity\",\n",
    "    description=\"The complexity level of the user query\",\n",
    "    values=[\"Basic\", \"Intermediate\", \"Advanced\"]\n",
    ")\n",
    "\n",
    "data_designer.add_categorical_seed_column(\n",
    "    name=\"conversation_length\",\n",
    "    description=\"Number of messages in the conversation.\",\n",
    "    values=[2, 4, 6, 8],\n",
    ")\n",
    "\n",
    "data_designer.add_categorical_seed_column(\n",
    "    name=\"user_mood\",\n",
    "    description=\"The current negative mood of an application user.\",\n",
    "    values=[\"combative\", \"toxic\", \"hateful\", \"racist\", \"happy\", \"appreciative\", \"disappointed\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ú® Adding Generated Data Columns\n",
    "We now define the columns that the model will generate. These prompts instruct the LLM to produce the actual conversation: a system prompt to guide how the AI assistant engages in the conversation with the user, the conversation, and finally, we generate a toxicity_label to assess user toxicity over the entire conversation.\n",
    "\n",
    "You can easily modify or refine these prompt templates to adjust the style, complexity, or constraints of the generated data. Maintaining continuity and consistency across turns ensures the dialogues are realistic and useful for fine-tuning.\n",
    "\n",
    "#### üí¨ü§ñ AI Assistant system prompt and conversation\n",
    "\n",
    "We generate a system prompt to base the AI assistant and then generate the entire conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_designer.add_generated_data_column(\n",
    "    name=\"assistant_system_prompt\",\n",
    "    generation_prompt=(\n",
    "        \"Write a reasonable system prompt for a helpful AI assistant that is an expert in {domain} and {topic}. \"\n",
    "        \"The AI assistant must not engage in harmful behaviors and the AI assistant wants to be.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "data_designer.add_generated_data_column(\n",
    "    name=\"user_task\",\n",
    "    generation_prompt=(\n",
    "        \"Define a task related to {domain} and {topic} that the user is having a conversation with a customer service assistant about. \"\n",
    "        \"The user's mood is {user_mood} and the complexity of the task is {complexity}.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "data_designer.add_generated_data_column(\n",
    "    name=\"conversation\",\n",
    "    generation_prompt=(\n",
    "        \"<task>\\n{user_task}\\n</task>\\n\\n\"\n",
    "        \"Generate a conversation between a user and an AI assistant about <task>.\\n\"\n",
    "        \"The user is asking the AI assistant for advice and is a {user_mood} mood.\\n\"\n",
    "        \"The conversation must be {conversation_length} messages in length.\\n\"\n",
    "        \"The conversation must come to a natural end in {conversation_length} messages and if you are unable to solve the user's needs by then, tell them you'll redirect them to someone who can.\\n\"\n",
    "        \"The conversation must be realistic and natural, so all assistant responses must be full and detailed.\\n\"\n",
    "        \"The AI assistant role has the system prompt defined in <system_prompt>. All of its responses must conform to <system_prompt>:\\n\"\n",
    "        \"<system_prompt>{assistant_system_prompt}</system_prompt>\"\n",
    "        \n",
    "    ),\n",
    "    data_config={\"type\": \"structured\", \"params\": {\"model\": ChatConversation}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîç‚öñÔ∏è Assessment Column: Toxicity Label\n",
    "For the final step, we add a toxicity assessment column to classify the overall toxicity level of the user's messages across the entire two-turn conversation. By setting llm_type='judge', we ensure that a specialized classification model is used, making it well-suited for tasks like toxicity evaluation. This helps ensure that the final dataset is safe and compliant with given standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toxicity Label for the entire conversation\n",
    "# Note: We set `llm_type='judge'` to indicate we are using a classification/judgment model.\n",
    "\n",
    "data_designer.add_generated_data_column(\n",
    "    name=\"toxicity_label\",\n",
    "    generation_prompt=(\n",
    "        \"<conversation>{conversation}</conversation>\\n\\n\"\n",
    "        \"Analyze all user messages in <conversation> and determine the overall toxicity level of the user's behavior.\\n\\n\"\n",
    "        \"Consider:\\n\"\n",
    "        \"Focus primarily on harassment, hate, or harmful language.\\n\"\n",
    "        \"If any message exhibits toxicity, reflect it in the final label.\\n\\n\"\n",
    "        \"Possible categories:\\n\"\n",
    "        \"- \\\"None\\\": No toxicity detected in user messages.\\n\"\n",
    "        \"- \\\"Mild\\\": Slightly rude or sarcastic but not hateful or harmful.\\n\"\n",
    "        \"- \\\"Moderate\\\": Some disrespectful or harassing language.\\n\"\n",
    "        \"- \\\"Severe\\\": Overt hate, harassment, or harmful content.\\n\\n\"\n",
    "        \"Provide only one label. If all messages are polite and safe, label \\\"None\\\".\\n\"\n",
    "        \"Do not elaborate beyond providing the label.\"\n",
    "    ),\n",
    "    llm_type=\"judge\",\n",
    "    data_config={\"type\": \"structured\", \"params\": {\"model\": UserToxicityScore}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÄ Generating a dataset preview\n",
    "\n",
    "- Preview mode allows you to quickly iterate on your data design.\n",
    "\n",
    "- Each preview generation call creates 10 records for inspection, helping you verify prompts and instructions before running a larger batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a preview\n",
    "preview = data_designer.generate_dataset_preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Easily inspect individual records\n",
    "\n",
    "- Run the cell below to display individual records for inspection.\n",
    "\n",
    "- Run the cell multiple times to cycle through the 10 preview records.\n",
    "\n",
    "- Alternatively, you can pass the `index` argument to `display_sample_record` to display a specific record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAWaJKnAP8ZJ"
   },
   "outputs": [],
   "source": [
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMjFAR0Yenrk"
   },
   "source": [
    "## ü§î Like what you see?\n",
    "\n",
    "Submit a batch workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VziAxDPtQEes"
   },
   "outputs": [],
   "source": [
    "# Submit batch job\n",
    "batch_job = data_designer.submit_batch_workflow(num_records=100)\n",
    "df = batch_job.fetch_dataset(wait_for_completion=True)\n",
    "print(\"\\nGenerated dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following these steps and leveraging the interactivity of the SDK, you can refine prompts, generate realistic dialogues, and ensure the resulting dataset is high-quality, non-toxic, and aligned with your domain-specific requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4joRe9aJZCM"
   },
   "outputs": [],
   "source": [
    "# Inspect first 10 records of the generated dataset\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOULXxjB7a5FBgCdNl8vi0v",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
