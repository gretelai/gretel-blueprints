{"cells":[{"cell_type":"markdown","metadata":{"id":"Sd091UzYy7w4"},"source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/demo/gretel-tuner-intro-tutorial.ipynb\"> \n","<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/> </a>\n","\n","# üßπ Hyperparameter Sweeps with **Gretel Tuner**\n","\n","\n","<br>\n","\n","<center><img src=\"https://gretel-public-website.s3.us-west-2.amazonaws.com/misc/sweep_the_params.jpg\" alt=\"Gretel\" width=\"500\"/></center>\n","\n","<br>\n","\n","In this tutorial, we will demonstrate how to tune the hyperparameters of a Gretel Synthetics model using **Gretel Tuner**.\n","\n","## üíø Installation\n","\n","- The tuner requires additional dependencies beyond the minimal requirements of [gretel_client](https://github.com/gretelai/gretel-python-client).\n","\n","- To install the tuner along with the client, add the `[tuner]` option to the pip install command:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gnX-SvbAA7dp"},"outputs":[],"source":["%%capture\n","!pip install gretel-client[tuner]"]},{"cell_type":"markdown","metadata":{"id":"fEejMSlA9qm6"},"source":["## üõú Configure your Gretel session\n","\n","- The [`Gretel` object](https://docs.gretel.ai/guides/high-level-sdk-interface/the-gretel-object) provides a high-level interface for streamlining interactions with Gretel's APIs.\n","\n","- Each `Gretel` instance is bound to a single [Gretel project](https://docs.gretel.ai/guides/gretel-fundamentals/projects).\n","\n","- Running the cell below will prompt you for your Gretel API key, which you can retrieve [here](https://console.gretel.ai/users/me/key).\n","\n","- With `validate=True`, your login credentials will be validated immediately at instantiation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YTQgF4xLBUfF"},"outputs":[],"source":["from gretel_client import Gretel\n","\n","gretel = Gretel(\n","    project_name=\"tuner-intro-tutorial\",\n","    api_key=\"prompt\",\n","    validate=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"71jpizc68mHG"},"outputs":[],"source":["# @title üóÇÔ∏è Pick a tabular data source üëá { display-mode: \"form\" }\n","# @markdown Run this cell to set the `data_source` path.\n","\n","\n","dataset_path_dict = {\n","    \"adult income in the USA (14000 records, 15 fields)\": \"https://raw.githubusercontent.com/gretelai/gretel-blueprints/main/sample_data/us-adult-income.csv\",\n","    \"hospital length of stay (9999 records, 18 fields)\": \"https://raw.githubusercontent.com/gretelai/gretel-blueprints/main/sample_data/sample-synthetic-healthcare.csv\",\n","    \"customer churn (7032 records, 21 fields)\": \"https://raw.githubusercontent.com/gretelai/gretel-blueprints/main/sample_data/monthly-customer-payments.csv\"\n","}\n","\n","data_source = \"adult income in the USA (14000 records, 15 fields)\" # @param [\"adult income in the USA (14000 records, 15 fields)\", \"hospital length of stay (9999 records, 18 fields)\", \"customer churn (7032 records, 21 fields)\"]\n","data_source = dataset_path_dict[data_source]"]},{"cell_type":"markdown","metadata":{"id":"SH3rOkag6DlV"},"source":["## ‚öôÔ∏è Define the tuner configuration\n","\n","* The tuner's main settings are set inside a single config, which can be passed as a yaml string, yaml file path, or dict.\n","* The tuner config follows the same format as the model section of the associated Gretel model config, with the following differences:\n"," * A `base_config` parameter is required to define the model and its default parameters. The value of this parameter can be a name from the [gretel-blueprints](https://github.com/gretelai/gretel-blueprints/tree/main/config_templates/gretel/synthetics) repo or a config file path.\n"," * An optional `metric` parameter can be used to select a Gretel metric to optimize during the hyperparameter sweeps. For tabular models, valid metrics are\n","   * `synthetic_data_quality_score` (default)\n","   * `field_correlation_stability`\n","   * `principal_component_stability`\n","   * `field_distribution_stability`\n"," * Instead of setting the model parameter values, you set how the tuner should sample them. Sampling options include\n","   * `choices` (sample from a discrete list of choices)\n","   * `int_range` (sample integers over a uniform range)\n","   * `float_range` (sample floats over a uniform range)\n","   * `log_range` (sample floats over a log-uniform range)\n","   * `fixed` (explicitly fix the parameter value).  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jkQnxLd9B9RT"},"outputs":[],"source":["tuner_config = \"\"\"\n","base_config: tabular-actgan\n","\n","metric: synthetic_data_quality_score\n","\n","params:\n","\n","    batch_size:\n","        fixed: 500\n","\n","    epochs:\n","        choices: [100, 500]\n","\n","    generator_lr:\n","        log_range: [0.00001, 0.001]\n","\n","    discriminator_lr:\n","        log_range: [0.00001, 0.001]\n","\n","    embedding_dim:\n","        choices: [64, 128, 256]\n","\n","    generator_dim:\n","        choices:\n","            - [512, 512, 512, 512]\n","            - [1024, 1024]\n","            - [1024, 1024, 1024]\n","            - [2048, 2048]\n","            - [2048, 2048, 2048]\n","\n","    discriminator_dim:\n","        choices:\n","            - [512, 512, 512, 512]\n","            - [1024, 1024]\n","            - [1024, 1024, 1024]\n","            - [2048, 2048]\n","            - [2048, 2048, 2048]\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"AtqMScCH6Sin"},"source":["## üèÉ‚Äç‚ôÇÔ∏è Run Gretel Tuner\n","\n","- The [Gretel object](https://docs.gretel.ai/guides/high-level-sdk-interface/the-gretel-object) has a convenience `run_tuner` method, which will run the parameter sweeps in a single command.\n","\n","- There is an optional `use_temporary_project` argument (default is `False`), which is useful if you plan to run a very large number of trials, each of which trains a model. If you use this option, be sure to save the best config, since the project (and hence best model) will be deleted upon completion.\n","\n","- The tuner submits training jobs to Gretel with different model configurations. While the submitted jobs are running remotely in the cloud, the tuner operates locally, initiating new jobs as model training completes from previous jobs.\n","\n","- Here, we use `n_trials = 4`, which is typically insufficient for finding an optimal model. For thorough hyperparameter tuning, we recommend conducting approximately 20-50 trials, depending on your metric score's convergence."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXEP_uh76QrC"},"outputs":[],"source":["# This call should take ~5-15 minutes to complete.\n","tuner_results = gretel.run_tuner(\n","    tuner_config,\n","    n_trials=4,\n","    n_jobs=2,\n","    data_source=data_source\n",")"]},{"cell_type":"markdown","metadata":{"id":"0yeYCbN1I-Sj"},"source":["## üìà Visualize the experiment results\n","\n","- Under the hood, Gretel Tuner uses [Optuna](https://optuna.readthedocs.io/en/stable/index.html) to drive the sampling of hyperparameters.\n","\n","- This means we can use Optuna's excellent visualization tools to better understand our tuning experiments."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cy_71hN3I_iI"},"outputs":[],"source":["import optuna.visualization as viz\n","\n","# Plot the optimization metric as a function of trial number.\n","viz.plot_optimization_history(tuner_results.study)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fz7ceUDUJFr6"},"outputs":[],"source":["# Compare the importances of the sampled hyperparameters.\n","viz.plot_param_importances(tuner_results.study)"]},{"cell_type":"markdown","metadata":{"id":"QAHZCtY96rhD"},"source":["## üßê Inspect the tuner results\n","\n","- The tuner returns a results object with information about the best model/config, as well as log data for all trials.\n","- Note that `best_model_id` will be `None` if you set `use_temporary_project=True`, since the project and its models will be deleted when the tuning job is finished. In this case, you should save the best config, which is stored as a dict in the `tuner_results.best_config` attribute, and use it to train a new model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XthmYULHEAre"},"outputs":[],"source":["tuner_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w1xc3Q6uI2Hc"},"outputs":[],"source":["# The best model config is the most important attribute.\n","tuner_results.best_config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GIE0zsMXGRiy"},"outputs":[],"source":["# The trial data is stored in a pandas DataFrame.\n","tuner_results.trial_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3q4Y8K54Ghkd"},"outputs":[],"source":["# Here's how you can fetch the best model's training job results.\n","trained = gretel.fetch_train_job_results(tuner_results.best_model_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nu9oH07QGojo"},"outputs":[],"source":["# Inspect the data used to generate Gretel's synthetic data quality report.\n","df_synth = trained.fetch_report_synthetic_data()\n","df_synth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGPU6VGh6r8k"},"outputs":[],"source":["# Inspect the full report from the best model.\n","trained.report.display_in_notebook()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMPYVeHqel9Z2iQ1tAtLMs3","provenance":[{"file_id":"1X3LV_RYJO7t7vE8BCnqugHIIkRZNv62V","timestamp":1701792825267}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
