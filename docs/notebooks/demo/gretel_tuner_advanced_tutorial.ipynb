{"cells":[{"cell_type":"markdown","metadata":{"id":"VikluRKM6P0s"},"source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/demo/gretel_tuner_advanced_tutorial.ipynb\"> \n","<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/> </a>\n","\n","# ðŸŽ›ï¸ Advanced **Gretel Tuner** Tutorial\n","\n","In this tutorial, we will demonstrate how to sweep ACTGAN's hyperparameters using **Gretel Tuner**, leveraging two advanced features:\n","\n","1. We will implement a custom, task-specific optimization metric.\n","\n","2. We will define a `sampler_callback` function, which applies arbitrary constraints on the sampled model configs.\n","\n","\n","## In the right place?\n","\n","If you are new to the **Gretel Tuner**, we recommend first working through the [Introductory Gretel Tuner Tutorial](https://colab.research.google.com/drive/1goVEJIufC4AebJ106FOpGmlCgT5UJswW?usp=sharing).\n","\n","\n","## ðŸ’¿ Installation\n","\n","- The tuner requires additional dependencies beyond the minimal requirements of [gretel_client](https://github.com/gretelai/gretel-python-client).\n","\n","- To install the tuner along with the client, add the `[tuner]` option to the pip install command:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13432,"status":"ok","timestamp":1701984465325,"user":{"displayName":"Johnny Greco","userId":"14197920642288392759"},"user_tz":300},"id":"cGOsT4r_1viR"},"outputs":[],"source":["%%capture\n","!pip install gretel-client[tuner]"]},{"cell_type":"markdown","metadata":{"id":"IEVokSr3jNPz"},"source":["## ðŸ›œ Configure your Gretel session\n","\n","- The [`Gretel` object](https://docs.gretel.ai/guides/high-level-sdk-interface/the-gretel-object) provides a high-level interface for streamlining interactions with Gretel's APIs.\n","\n","- Each `Gretel` instance is bound to a single [Gretel project](https://docs.gretel.ai/guides/gretel-fundamentals/projects).\n","\n","- Running the cell below will prompt you for your Gretel API key, which you can retrieve [here](https://console.gretel.ai/users/me/key).\n","\n","- With `validate=True`, your login credentials will be validated immediately at instantiation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13440,"status":"ok","timestamp":1701984478761,"user":{"displayName":"Johnny Greco","userId":"14197920642288392759"},"user_tz":300},"id":"SBpY0TIeW0vo","outputId":"731ee06f-722a-4655-b18a-da2721e1f479"},"outputs":[],"source":["from gretel_client import Gretel\n","\n","gretel = Gretel(\n","    project_name=\"tuner-advanced-tutorial\",\n","    api_key=\"prompt\",\n","    validate=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"Sjn43E4L6SxK"},"source":["## ðŸ¦ Preview bank marketing dataset\n","\n","- For this demo, we will use a subset of a [bank marketing dataset](https://archive.ics.uci.edu/dataset/222/bank+marketing)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"elapsed":445,"status":"ok","timestamp":1701984479203,"user":{"displayName":"Johnny Greco","userId":"14197920642288392759"},"user_tz":300},"id":"WFc4WsPz6Q1M","outputId":"9f405a36-4239-4e3e-f6e7-38c1448738b8"},"outputs":[],"source":["import pandas as pd\n","\n","data_source = \"https://raw.githubusercontent.com/gretelai/gretel-blueprints/main/sample_data/bank_marketing_small.csv\"\n","\n","df_ref = pd.read_csv(data_source)\n","df_ref.head()"]},{"cell_type":"markdown","metadata":{"id":"OGbgZp_Z181F"},"source":["## ðŸ—ï¸ Building custom optimization metrics\n","\n","- As we saw in the intro Gretel Tuner tutorial, Gretel's quality metrics such as the [Synthetic Data Quality Score](https://docs.gretel.ai/reference/evaluate/synthetic-data-quality-report#synthetic-data-quality-score-sqs) can be set as the tuner's optimization metric via its yaml config.\n","\n","- To use a custom metric, create a class that inherits `BaseTunerMetric` and implement a `__call__` method that takes a Gretel `Model` as input and returns the metric score as a float, as we demonstrate in the cell below.\n","\n","- `BaseTunerMetric` has two helper methods:\n","    - `get_gretel_report` - fetches the Gretel Synthetic Data Quality Report, which is useful if you want to incorporate Gretel's score(s) into your custom metric.\n","    - `submit_generate_for_trial` - submits a synthetic data generation job to Gretel, which is useful if you need to generate synthetic data beyond the data used in Gretel's report.\n","\n","> #### Example use case\n","Given the bank marketing dataset, suppose we have a use case that requires **(i)** our synthetic model to conditionally generate synthetic records with `job = 'entrepreneur'` and **(ii)** we really care about accurately reproducing the distribution of bank balances. In the cell below, we build both of these requirements into a custom metric called `BalanceKSComplementPlusSQS`, which calculates a metric score as follows. For each trial:\n","- Conditionally generate `num_samples` records with `target_job='entrepreneur'`.\n","- For records with `job = 'entrepreneur'`, compare the real and conditionally-generated `balance` distributions using the [KS statistic](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test) (lower is better).\n","- Calculate the custom metric score as a weighted sum of the KS complement (1 - KS -> higher is better) and Gretel's SQS score, which measures the general synthetic data quality.\n","\n","> **Note:** This example and custom metric are only meant to demonstrate functionality. Implementing a task-specific optimization metric in the real world requires careful consideration of your dataset and use case requirements."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":828,"status":"ok","timestamp":1701984480029,"user":{"displayName":"Johnny Greco","userId":"14197920642288392759"},"user_tz":300},"id":"w2L_nbgW2BQw"},"outputs":[],"source":["from scipy.stats import ks_2samp\n","\n","from gretel_client.tuner import BaseTunerMetric, MetricDirection\n","\n","class BalanceKSComplementPlusSQS(BaseTunerMetric):\n","    def __init__(self, df_ref, target_job=\"entrepreneur\", num_samples=500):\n","        self.target_job = target_job\n","        self.num_samples = num_samples\n","        self.balance_ref = df_ref.query(\"job==@target_job\")[\"balance\"]\n","\n","        # Set metric optimization direction.\n","        # (note the default is maximize, so this is optional in this case)\n","        self.direction = MetricDirection.MAXIMIZE\n","\n","    def __call__(self, model):\n","        # Fetch Gretel's synthetic data quality score for the model.\n","        report = self.get_gretel_report(model)\n","        sqs = report[\"synthetic_data_quality_score\"][\"raw_score\"] / 100\n","\n","        # (i) Conditionally generate synthetic records with the target job.\n","        seed_data = pd.DataFrame({\"job\": [self.target_job] * self.num_samples})\n","        df_synth = self.submit_generate_for_trial(model, seed_data=seed_data)\n","\n","        # (ii) Calculate the KS complement of the real and synthetic balances.\n","        ks_comp = 1 - ks_2samp(df_synth[\"balance\"], self.balance_ref).statistic\n","\n","        # Calculate score as weighted sum of the KS complement and SQS.\n","        score =  0.7 * ks_comp + 0.3 * sqs\n","\n","        return score"]},{"cell_type":"markdown","metadata":{"id":"e4GfVa7-MPlI"},"source":["## ðŸš€ Run Gretel Tuner with the custom metric\n","\n","- The [Gretel object](https://docs.gretel.ai/guides/high-level-sdk-interface/the-gretel-object) has a convenience `run_tuner` method, which will run the parameter sweeps in a single command.\n","\n","- The tuner submits training jobs to Gretel with different model configurations. While the submitted jobs run remotely in the cloud, the tuner runs **locally**, submitting new jobs as model training completes from previous jobs.\n","\n","- Here we use `n_trials = 4`, which is too small to find an optimal model. In an actual hyperparameter tuning experiment, we recommend using at least ~20-50 trials, depending on the observed convergence of the metric score.\n","\n","- The `sampler_callback` function is applied to each trial config before the training job is submitted. Its input argument is the model section of the config. In this example, we use it to set the constraint `generator_dim = discriminator_dim`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f48a82badd7b4b51a5bf82d40c0d3751","43d3cbc264e64d43b1dce6c64ad0eb87","7ef3c4225323442ba370443fce99b6df","b78569dfd6e6474aa6ea365aa49fb1ef","b151fe245bd04381973ad906499f9684","810e682650784f23801486fc669e6406","6416d1ee60374ba492df5e6d2b00b624","5d1660e11b5a4d0f92bc6034b8241423","c1173289513c480cb8a9e731da46f70b","56a0ef21fbd6481b8a6acad8bddb4af8","8c8ea4443d7644579a72a52c47d41b94"]},"id":"RyEvkqP1ieLx","outputId":"e172fc18-5523-4f18-ba3b-9bf035bbb121"},"outputs":[],"source":["# This cell should take ~10 minutes to complete.\n","tuner_config = \"\"\"\n","base_config: tabular-actgan\n","\n","params:\n","\n","    batch_size:\n","        fixed: 500\n","\n","    epochs:\n","        fixed: 500\n","\n","    generator_lr:\n","        log_range: [0.00001, 0.001]\n","\n","    discriminator_lr:\n","        log_range: [0.00001, 0.001]\n","\n","    generator_dim:\n","        choices:\n","            - [512, 512, 512, 512]\n","            - [1024, 1024]\n","            - [1024, 1024, 1024]\n","            - [2048, 2048]\n","            - [2048, 2048, 2048]\n","\"\"\"\n","\n","def sampler_callback(model_section):\n","    \"\"\"Always set discriminator_dim = generator_dim in ACTGAN's config.\"\"\"\n","    model_section[\"params\"][\"discriminator_dim\"] = model_section[\"params\"][\"generator_dim\"]\n","    return model_section\n","\n","target_job = \"entrepreneur\"\n","\n","df_ref = pd.read_csv(data_source)\n","\n","metric = BalanceKSComplementPlusSQS(df_ref, target_job=target_job)\n","\n","tuner_results = gretel.run_tuner(\n","    tuner_config,\n","    data_source=df_ref,\n","    n_jobs=2,\n","    n_trials=4,\n","    metric=metric,\n","    sampler_callback=sampler_callback\n",")"]},{"cell_type":"markdown","metadata":{"id":"eQBm12OdKNPF"},"source":["## ðŸ“ˆ Visualize the experiment results\n","\n","- Under the hood, Gretel Tuner uses [Optuna](https://optuna.readthedocs.io/en/stable/index.html) to drive the sampling of hyperparameters.\n","\n","- This means we can use Optuna's visualization tools to better understand our tuning experiments."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWfHeMyfKRZM"},"outputs":[],"source":["import optuna.visualization as viz\n","\n","# Plot the optimization metric as a function of trial number.\n","viz.plot_optimization_history(tuner_results.study)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJIJZEhGKSCF"},"outputs":[],"source":["# Compare the importances of the sampled hyperparameters.\n","viz.plot_param_importances(tuner_results.study)"]},{"cell_type":"markdown","metadata":{"id":"mSiM1-07OW_t"},"source":["## ðŸ¤– Conditionally generate synthetic data using the \"best\" model\n","-  We submit the generate job using the `best_model_id` from the above tuner results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KhgFHhydXZqx"},"outputs":[],"source":["generated = gretel.submit_generate(\n","    model_id=tuner_results.best_model_id,\n","    seed_data=pd.DataFrame({\"job\": [target_job] * 100})\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WyGnBDM13Izj"},"outputs":[],"source":["# The synthetic data is returned as a DataFrame.\n","generated.synthetic_data"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN+u+cHAzNUsLJrj6qrrcje","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"43d3cbc264e64d43b1dce6c64ad0eb87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_810e682650784f23801486fc669e6406","placeholder":"â€‹","style":"IPY_MODEL_6416d1ee60374ba492df5e6d2b00b624","value":"Best trial: 0. Best value: 0.788129:  50%"}},"56a0ef21fbd6481b8a6acad8bddb4af8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d1660e11b5a4d0f92bc6034b8241423":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6416d1ee60374ba492df5e6d2b00b624":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ef3c4225323442ba370443fce99b6df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d1660e11b5a4d0f92bc6034b8241423","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1173289513c480cb8a9e731da46f70b","value":2}},"810e682650784f23801486fc669e6406":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c8ea4443d7644579a72a52c47d41b94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b151fe245bd04381973ad906499f9684":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b78569dfd6e6474aa6ea365aa49fb1ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56a0ef21fbd6481b8a6acad8bddb4af8","placeholder":"â€‹","style":"IPY_MODEL_8c8ea4443d7644579a72a52c47d41b94","value":" 2/4 [03:56&lt;03:27, 103.58s/it]"}},"c1173289513c480cb8a9e731da46f70b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f48a82badd7b4b51a5bf82d40c0d3751":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43d3cbc264e64d43b1dce6c64ad0eb87","IPY_MODEL_7ef3c4225323442ba370443fce99b6df","IPY_MODEL_b78569dfd6e6474aa6ea365aa49fb1ef"],"layout":"IPY_MODEL_b151fe245bd04381973ad906499f9684"}}}}},"nbformat":4,"nbformat_minor":0}
