{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85df52da-e8e3-4710-92f7-9c852f7e98b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Generate Synthetic Data using Gretel's Databricks Connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ce3bc45-ca7e-4d8f-9c64-65952a448721",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "- This notebook demonstrates how to use Gretel Workflows and Gretel's Databricks Connector to read data from Databricks, generate synthetic data, and write the synthetic data back to Databricks\n",
    "\n",
    "- To run this notebook, you will ned an API key from the [Gretel Console](https://console.gretel.ai/), as well as the connection parameters specified in the [Databricks Connector docs](https://docs.gretel.ai/create-synthetic-data/workflows-and-connectors/connectors/data-warehouse/databricks#permissions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f1edebb-edd2-42ff-a106-e536d6c1930f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3ad222ab-1c6e-4457-91c6-7f7c3790bfe3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install gretel-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5732aadd-c3c5-435d-9d57-322582becd42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import yaml\n",
    "from getpass import getpass\n",
    "\n",
    "from gretel_client import create_or_get_unique_project\n",
    "from gretel_client.config import configure_session, get_session_config\n",
    "from gretel_client.rest_v1.api.connections_api import ConnectionsApi\n",
    "from gretel_client.rest_v1.api.logs_api import LogsApi\n",
    "from gretel_client.rest_v1.api.workflows_api import WorkflowsApi\n",
    "from gretel_client.rest_v1.models import (\n",
    "    CreateConnectionRequest,\n",
    "    CreateWorkflowRunRequest,\n",
    "    CreateWorkflowRequest,\n",
    ")\n",
    "from gretel_client.workflows.logs import print_logs_for_workflow_run\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Set up of API's needed to run workflows\n",
    "setup = configure_session(api_key=\"prompt\")\n",
    "session = get_session_config()\n",
    "\n",
    "connection_api = session.get_v1_api(ConnectionsApi)\n",
    "workflow_api = session.get_v1_api(WorkflowsApi)\n",
    "log_api = session.get_v1_api(LogsApi)\n",
    "\n",
    "project = create_or_get_unique_project(name=\"workflow-testing\")\n",
    "\n",
    "project.get_console_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b841c9e7-d749-4e6d-910e-8ca9c846728f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee1250d6-8ee5-47dd-b0e1-ed8cfb6d781c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Creates source and destination connections for databricks\n",
    "\"\"\"\n",
    "\n",
    "source_conn = connection_api.create_connection(\n",
    "    CreateConnectionRequest(\n",
    "        name=\"databricks-source\",\n",
    "        project_id=project.project_guid,\n",
    "        type=\"databricks\",\n",
    "        config={\n",
    "            \"server_hostname\": input('Source Connection(server_hostname):'),\n",
    "            \"http_path\": input('Source Connection(http_path):'),\n",
    "            \"catalog\": input('Source Connection(catalog):'),\n",
    "            \"schema\": input('Source Connection(schema):'),\n",
    "        },\n",
    "        credentials={\n",
    "            \"personal_access_token\": getpass(prompt='Source Connection(Personal Access Token (PAT)):')\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "dest_conn = connection_api.create_connection(\n",
    "    CreateConnectionRequest(\n",
    "        name=\"databricks-dest\",\n",
    "        project_id=project.project_guid,\n",
    "        type=\"databricks\",\n",
    "        config={\n",
    "            \"server_hostname\": input('Destination Connection(server_hostname):'),\n",
    "            \"http_path\": input('Destination Connection(http_path):'),\n",
    "            \"catalog\": input('Destination Connection(catalog):'),\n",
    "            \"schema\": input('Destination Connection(schema):'),\n",
    "        },\n",
    "        credentials={\n",
    "            \"personal_access_token\": getpass(prompt='Destination Connection(Personal Access Token (PAT)): ')\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56630eed-867a-48ca-925d-9f798ca8ba6c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fba16f6-39ef-4981-b835-258ed6b4f9ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Sample config for a Gretel Workflow that\n",
    "1. Reads data from databricks\n",
    "2. Generates synthetic data using our ACTGAN (https://docs.gretel.ai/create-synthetic-data/models/synthetics/gretel-actgan) model.\n",
    "3. Writes generated synthetic data back to a Databricks Destination\n",
    "\n",
    "Note: volume name can be edited in 'databricks-destination' action\n",
    "\"\"\"\n",
    "\n",
    "workflow_config = yaml.safe_load(f\"\"\"\n",
    "name: my-databricks-workflow\n",
    "actions:\n",
    "  - name: databricks-read\n",
    "    type: databricks_source\n",
    "    connection: {source_conn.id}\n",
    "    config:\n",
    "      sync:\n",
    "        mode: subset\n",
    "        algorithm: contiguous\n",
    "        target_row_count: 1000\n",
    "  - name: model-train-run\n",
    "    type: gretel_tabular\n",
    "    input: databricks-read\n",
    "    config:\n",
    "      project_id: {project.project_guid}\n",
    "      train:\n",
    "        model_config:\n",
    "          schema_version: \"1.0\"\n",
    "          name: tabular-actgan\n",
    "          models:\n",
    "            - actgan:\n",
    "                data_source: __tmp__\n",
    "                params:\n",
    "                  epochs: auto\n",
    "                  generator_dim:\n",
    "                    - 1024\n",
    "                    - 1024\n",
    "                  discriminator_dim:\n",
    "                    - 1024\n",
    "                    - 1024\n",
    "                  generator_lr: 0.0001\n",
    "                  discriminator_lr: 0.00033\n",
    "                  batch_size: auto\n",
    "                  auto_transform_datetimes: false\n",
    "                generate:\n",
    "                  num_records: 5000\n",
    "                privacy_filters:\n",
    "                  outliers: null\n",
    "                  similarity: null\n",
    "        dataset: \"{{outputs.databricks-read.dataset}}\"\n",
    "      run:\n",
    "        num_records_multiplier: 1\n",
    "  - name: databricks-write\n",
    "    type: databricks_destination\n",
    "    connection: {dest_conn.id}\n",
    "    input: model-train-run\n",
    "    config:\n",
    "      sync:\n",
    "        mode: replace\n",
    "      dataset: \"{{outputs.model-train-run.dataset}}\"\n",
    "      volume: \"{input(\"Provide name for the volume: \")}\"\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Creates a workflow with the config above\n",
    "workflow = workflow_api.create_workflow(\n",
    "    CreateWorkflowRequest(\n",
    "        name=\"Databricks E2E Demo\",\n",
    "        project_id=project.project_guid,\n",
    "        config=workflow_config,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e51a96ed-40df-49d3-a650-dae19908ba78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Running Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "717566eb-76e8-4b29-9525-5976da504d9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Kicks off a run of the workflow created\n",
    "workflow_run = workflow_api.create_workflow_run(\n",
    "    CreateWorkflowRunRequest(workflow_id=workflow.id)\n",
    ")\n",
    "\n",
    "print_logs_for_workflow_run(workflow_run.id, session)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gretel-demo-databricks-connector (1)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
