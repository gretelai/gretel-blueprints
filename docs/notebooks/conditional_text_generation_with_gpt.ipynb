{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTRxpSlaczHY"
      },
      "source": [
        "# Generating Synthetic Text\n",
        "\n",
        "This notebook will walk you through generating realistic but synthetic text examples using an open-source implementation of OpenAI's GPT-3 architecture. \n",
        "\n",
        "In this example, we will generate new annotated text utterances that can be used to augment a real world financial dataset called `banking77`. This augmented dataset will have additional annotated examples that can help downstream ML models better understand and respond to new customer queries. To run this notebook, you will need an API key from the Gretel console,  at https://console.gretel.cloud. \n",
        "<br>\n",
        "\n",
        "** **Limitations and Biases** **\n",
        "Large-scale language models such as Gretel GPT may produce untrue and/or offensive content without warning. We recommend having a human curate or filter the outputs before releasing them, both to censor undesirable content and to improve the quality of the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEM6kjRsczHd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U gretel-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhBCe4PfrTWW"
      },
      "source": [
        "## Set up your project\n",
        "* `DATASET_PATH`: Specify a dataset to run on.\n",
        "* `INTENT`: Select an intent from the training data to boost examples for.\n",
        "* `SEPARATOR`: Specify a separator character (default=`,`) to combine intents and texts with into a single column.\n",
        "* `PROJECT`: Specify a project name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ-TmAdwczHd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "from gretel_client import configure_session\n",
        "from gretel_client.helpers import poll\n",
        "from gretel_client.projects import create_or_get_unique_project, get_project\n",
        "from gretel_client.projects.models import read_model_config\n",
        "\n",
        "\n",
        "DATASET_PATH = 'https://gretel-public-website.s3.us-west-2.amazonaws.com/datasets/banking77.csv'\n",
        "INTENT = \"card arrival\"\n",
        "SEPARATOR = ','\n",
        "PROJECT = 'banking77'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOygU-1MrTWY"
      },
      "outputs": [],
      "source": [
        "# Log into Gretel and configure project\n",
        "\n",
        "configure_session(api_key=\"prompt\", cache=\"yes\", endpoint=\"https://api.gretel.cloud\", validate=True, clear=True)\n",
        "\n",
        "project = create_or_get_unique_project(name=PROJECT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9LTh7GO6VIu"
      },
      "source": [
        "## Load and preview the training dataset\n",
        "Create single-column CSV training set by combining `intent` + `SEPARATOR` + `text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMg9nX6SczHe"
      },
      "outputs": [],
      "source": [
        "def create_dataset(dataset_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Combine intents and text into a single string to pass to GPT-X.\n",
        "    \"\"\"\n",
        "    records = []\n",
        "    max_tokens = 0\n",
        "    \n",
        "    df = pd.read_csv(dataset_path)\n",
        "    df['intent_and_text'] = df['intent'] + SEPARATOR + df['text']\n",
        "    return df\n",
        "    \n",
        "\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "df = create_dataset(DATASET_PATH)\n",
        "df[['intent_and_text']].to_csv('finetune.csv', index=False)\n",
        "print(f\"Total training set length {sum([len(x) for x in df['intent_and_text'].values])} bytes.\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxnH8th-65Dh"
      },
      "source": [
        "## Train the synthetic model\n",
        "In this step, we will task the worker running in the Gretel cloud, or locally, to fine-tune the GPT language model on the source dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4-E_F0qczHe",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%%time \n",
        "\n",
        "def calc_epochs(num_rows, minutes=30) -> float:\n",
        "    \"\"\"Estimate the number of rows that can be trained within a time period\"\"\"\n",
        "    rows_per_minute = 102.0\n",
        "    return (rows_per_minute * minutes) / num_rows                                      \n",
        "\n",
        "config = read_model_config(\"synthetics/natural-language\")\n",
        "config['models'][0]['gpt_x']['pretrained_model'] = \"gretelai/mpt-7b\"\n",
        "config['models'][0]['gpt_x']['epochs'] = calc_epochs(len(df))\n",
        "config['models'][0]['gpt_x']['generate'] = {'num_records': 1}\n",
        "config\n",
        "\n",
        "# Create and submit model\n",
        "model = project.create_model_obj(model_config=config, data_source=df)\n",
        "model.name = f\"{PROJECT}-mpt-7b\"\n",
        "model.submit_cloud()\n",
        "\n",
        "poll(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IkWOnVQ7oo1"
      },
      "source": [
        "## Generate synthetic text data\n",
        "The next cells walk through sampling data from the fine-tuned model using a prompt (conditional data generation). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8gD9Q2XSFyv"
      },
      "outputs": [],
      "source": [
        "# Generate new text examples for a given intent by seeding\n",
        "# model generation with examples from the class. \n",
        "\n",
        "# NOTE: We have found prompting the model with \n",
        "# ~25 examples for the class you wish to \n",
        "# generate to work well in practice.\n",
        "\n",
        "%%time \n",
        "\n",
        "def create_prompt(df: pd.DataFrame, intent: str = \"\", recs: int = 25) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Seed Gretel GPT text generation with an intent from the training data.\n",
        "    \"\"\"\n",
        "    # NOTE: When creating a DataFrame for prompts, it must be a 1-column DataFrame!\n",
        "    sample = df.query(f'intent == \"{intent}\"').head(recs)\n",
        "    prompt = \"\\n\".join([x[0] for x in sample[['intent_and_text']].values])\n",
        "    \n",
        "    # NOTE: the column name provide here does not matter, the returned\n",
        "    # synthetic DataFrame will have the original column name that\n",
        "    # was used to train the model, in this case it will be \"intent_and_text\"\n",
        "    return pd.DataFrame([prompt], columns=[\"prompt_text\"])\n",
        "\n",
        "\n",
        "prompt_df = create_prompt(df=df, intent=INTENT, recs=25)\n",
        "\n",
        "record_handler = model.create_record_handler_obj(\n",
        "    params={\"maximum_text_length\": 1000},\n",
        "    data_source=prompt_df\n",
        ")\n",
        "record_handler.submit_cloud()\n",
        "poll(record_handler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy8q3f2dTAHv"
      },
      "source": [
        "# Creating synthetic intents\n",
        "\n",
        "In the cell below, we process the raw texts generated by Gretel GPT into a structured dataframe format, by splitting each row based on the intent prefix (`card_arrival`) that was used to prompt generation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fx4aeMOSFyw",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def get_intents(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Extract new intents generated by the GPT-X model.\n",
        "    \"\"\"\n",
        "    MIN_LENGTH = 20\n",
        "    texts = []\n",
        "    \n",
        "    for idx, row in gptx_df.iterrows(): \n",
        "        for text in row[0].split(f\"{INTENT}{SEPARATOR}\"):\n",
        "            text = text.strip()\n",
        "            if len(text) > MIN_LENGTH:\n",
        "                texts.append([INTENT, text])\n",
        "\n",
        "    intents = pd.DataFrame(texts, columns=['intent', 'synthetic_text'])\n",
        "    return intents\n",
        "\n",
        "\n",
        "gptx_df = pd.read_csv(record_handler.get_artifact_link(\"data\"), compression='gzip')\n",
        "gptx_df\n",
        "syn = get_intents(df=gptx_df)\n",
        "syn.head(15)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}