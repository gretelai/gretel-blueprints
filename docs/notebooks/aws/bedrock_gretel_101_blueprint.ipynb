{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awlODvx7fQeB"
      },
      "source": [
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/sdk_blueprints/Gretel_Navigator_IAPI_101_Blueprint.ipynb)\n",
        "\n",
        "<br>\n",
        "\n",
        "<center><img src=\"https://gretel-public-website.s3.us-west-2.amazonaws.com/assets/brand/gretel_brand_wordmark.svg\" alt=\"Gretel\" width=\"350\"/></center>\n",
        "\n",
        "<br>\n",
        "\n",
        "## ðŸ‘‹ Welcome to the Navigator real-time inference API 101 Blueprint!\n",
        "\n",
        "In this Blueprint, we will introduce the Python SDK for our Navigator real-time inference API, which makes it easy to generate high-quality synthetic tabular and text data with just a few lines of code, powered by [Gretel Navigator](https://gretel.ai/navigator).\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "## âœ… Set up your Gretel account\n",
        "\n",
        "To get started, you will need a [free Gretel account](https://console.gretel.ai/).\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Ready? Let's go ðŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HplFGj5HNZiJ"
      },
      "source": [
        "## ðŸ’¾ Install `gretel-client` and its dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZPDLpEPIXSW"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gretel-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHqesHdmOCe_"
      },
      "source": [
        "## ðŸ›œ Configure your Gretel session\n",
        "\n",
        "- [The Gretel object](https://docs.gretel.ai/create-synthetic-data/gretel-sdk/the-gretel-object) provides a high-level interface for streamlining interactions with Gretel's APIs.\n",
        "\n",
        "- Retrieve your Gretel API key [here](https://console.gretel.ai/users/me/key)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLIgnOzcNpHD"
      },
      "outputs": [],
      "source": [
        "from gretel_client import Gretel\n",
        "\n",
        "gretel = Gretel(api_key=\"prompt\", validate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GO2SLE3ebdw"
      },
      "source": [
        "## ðŸš€ Real-time inference API\n",
        "\n",
        "- The Navigator real-time inference API makes it possible to programmatically run Navigator outside the [Gretel Console](https://console.gretel.ai/navigator).\n",
        "\n",
        "- Our [Python SDK](https://github.com/gretelai/gretel-python-client) provides an intuitive high-level interface for the Navigator API.\n",
        "\n",
        "- Navigator currently supports two data generation modes: `\"tabular\"` and `\"natural_language\"`. In both modes, you can choose the backend model that powers the generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsiUQH5hP9TV"
      },
      "outputs": [],
      "source": [
        "# list \"tabular\" backend models\n",
        "gretel.factories.get_navigator_model_list(\"tabular\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zGw50JLQDWP"
      },
      "outputs": [],
      "source": [
        "# list \"natural_language\" backend models\n",
        "gretel.factories.get_navigator_model_list(\"natural_language\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrbIPm_5QKX4"
      },
      "source": [
        "**Notes:**\n",
        "\n",
        "- `gretelai/auto` automatically selects the current default model, which will change with time as models continue to evolve.\n",
        "\n",
        "- The `factories` attribute of the `Gretel` object provides methods for creating new objects that interact with Gretel's APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru2Ogl83BSqn"
      },
      "source": [
        "## ðŸ“Š Tabular data generation\n",
        "\n",
        "- We use the `initialize_navigator_api` method of the `factories` attribute to create a Navigator API object.\n",
        "\n",
        "- With `model_type = \"tabular\"` (which is the default), we initialize Navigator's tabular API.\n",
        "\n",
        "- To select a different backend model, use the optional `backend_model` argument, which defaults to `gretelai/auto`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1InUug1Aeahi"
      },
      "outputs": [],
      "source": [
        "tabular = gretel.factories.initialize_navigator_api(\"tabular\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T7EydHVS4vd"
      },
      "outputs": [],
      "source": [
        "# generate tabular data from a natural language prompt\n",
        "\n",
        "prompt = \"\"\"\\\n",
        "Generate customer bank transaction data. Include the following columns:\n",
        "- customer_name\n",
        "- customer_id\n",
        "- transaction_date\n",
        "- transaction_amount\n",
        "- transaction_type\n",
        "- transaction_category\n",
        "- account_balance\n",
        "\"\"\"\n",
        "\n",
        "df = tabular.generate(prompt, num_records=25)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUwOGBXuWQqf"
      },
      "outputs": [],
      "source": [
        "# add column to the generated table using the `edit` method\n",
        "\n",
        "prompt = \"\"\"\\\n",
        "Add the following column to the provided table:\n",
        "\n",
        "- customer_address\n",
        "\"\"\"\n",
        "\n",
        "df_edited = tabular.edit(prompt, seed_data=df)\n",
        "\n",
        "df_edited"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYScZw6tm55b"
      },
      "source": [
        "## ðŸ“š Natural language data generation\n",
        "\n",
        "- With `model_type = \"natural_language\"`, we initialize Navigator's natural language API.\n",
        "\n",
        "- To select a different backend model, use the optional backend_model argument, which defaults to `gretelai/gpt-auto`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAUSBwRJfUtC"
      },
      "outputs": [],
      "source": [
        "llm = gretel.factories.initialize_navigator_api(\"natural_language\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTuFhwvzfYb5"
      },
      "outputs": [],
      "source": [
        "# generate text from a natural language prompt\n",
        "llm.generate(\"Please tell me a funny joke about data scientists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lerj0Ld-mwHc"
      },
      "outputs": [],
      "source": [
        "# let's see if the LLM is funnier with a higher generation temperature\n",
        "llm.generate(\"Please tell me a funny joke about data scientists.\", temperature=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te5ojPFGa75a"
      },
      "source": [
        "## ðŸ¤– Combining Navigator's APIs\n",
        "\n",
        "- Navigator's APIs can be combined to dynamically create/augment prompts for tabular data generation.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqtC1XM7bOFC"
      },
      "outputs": [],
      "source": [
        "# use the \"natural_language\" API to generate the fields of a tabular dataset\n",
        "\n",
        "dataset_type = \"insurance fraud\"\n",
        "\n",
        "\n",
        "llm_prompt = f\"\"\"\\\n",
        "List 8 fields you expect to find in an {dataset_type} dataset.\n",
        "\n",
        "Important: Include descriptions for each field. Please do not explain yourself.\n",
        "\"\"\"\n",
        "\n",
        "fields = llm.generate(llm_prompt, temperature=0.1)\n",
        "\n",
        "print(fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpH0UBF6c1jk"
      },
      "outputs": [],
      "source": [
        "# use the \"tabular\" API to generate a dataset using the above generated fields\n",
        "\n",
        "final_prompt = f\"\"\"\\\n",
        "Create an {dataset_type} dataset with the following fields:\n",
        "\n",
        "{fields}\n",
        "\"\"\"\n",
        "\n",
        "print(final_prompt, end=\"\\n\\n\")\n",
        "\n",
        "df = tabular.generate(final_prompt, num_records=25)\n",
        "\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}