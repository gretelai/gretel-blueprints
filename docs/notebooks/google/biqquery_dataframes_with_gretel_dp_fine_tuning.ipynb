{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/zredlined/798670a15869533851df13725d589e4e/bigframes-demo-2-creating-differentially-private-synthetic-text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8FxOdDYkca0"
      },
      "source": [
        "# ðŸ¤– Unlock Sensitive Text in BigQuery with Differentially Private Synthetic Text\n",
        "\n",
        "Harness the power of sensitive text data for AI and analytics using [Gretel](https://gretel.ai)'s differentially private synthetic data, [Google BigQuery](https://cloud.google.com/bigquery), and the [BigFrames SDK](https://cloud.google.com/python/docs/reference/bigframes/latest).\n",
        "\n",
        "## ðŸ” In this Notebook:\n",
        "\n",
        "1. Retrieve 30k sensitive clinical notes from BigQuery\n",
        "2. Generate differentially private synthetic notes (Îµ = 5) using Gretel GPT\n",
        "3. Evaluate synthetic data quality and utility\n",
        "4. Store AI-ready synthetic data in BigQuery for downstream applications\n",
        "\n",
        "## ðŸ’ª Why It Matters:\n",
        "\n",
        "- **Robust Privacy**: Îµ = 5 offers strong protection against attacks while maintaining data utility\n",
        "- **Efficiency at Scale**: High-quality results with just 30k records, versus millions typically required\n",
        "- **Versatile Applications**: Safely use in healthcare, finance, customer support, and more\n",
        "- **Unrestricted Usage**: Train ML models or perform analytics without privacy concerns\n",
        "- **Potential to Outperform**: At scale, synthetic data can often exceed real data in ML tasks\n",
        "\n",
        "Gretel's approach combines state-of-the-art LLMs with differential privacy, processing ~30k records in about 2 hours on a single GPU.\n",
        "\n",
        "[Explore Gretel GPT](https://docs.gretel.ai/create-synthetic-data/models/synthetics/gretel-gpt) | [Learn about DP Synthetic Text](https://gretel.ai/blog/generate-differentially-private-synthetic-text-with-gretel-gpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByGXgHrUgA20"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -Uqq \"gretel-client>=0.22.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz-Prx7XNaBS"
      },
      "outputs": [],
      "source": [
        "# Install bigframes if it's not already installed in the environment.\n",
        "\n",
        "# %%capture\n",
        "# !pip install bigframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwmtdvRlgHPD"
      },
      "outputs": [],
      "source": [
        "from gretel_client import Gretel\n",
        "from gretel_client.bigquery import BigFrames\n",
        "\n",
        "gretel = Gretel(api_key=\"prompt\", validate=True, project_name=\"bigframes-dp\")\n",
        "\n",
        "# This is the core interface we will use moving forward!\n",
        "gretel_bigframes = BigFrames(gretel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52FR7Gohcyds"
      },
      "outputs": [],
      "source": [
        "import bigframes.pandas as bpd\n",
        "\n",
        "BIGQUERY_PROJECT = \"gretel-vertex-demo\"\n",
        "\n",
        "# Set BigFrames options\n",
        "bpd.options.display.progress_bar = None\n",
        "bpd.options.bigquery.project = BIGQUERY_PROJECT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QzezpOzNaBS"
      },
      "outputs": [],
      "source": [
        "# Define the source project and dataset\n",
        "project_id = \"gretel-public\"\n",
        "dataset_id = \"public\"\n",
        "table_id = \"clinical-notes\"\n",
        "\n",
        "# Construct the table path\n",
        "table_path = f\"{project_id}.{dataset_id}.{table_id}\"\n",
        "\n",
        "# Read the table into a DataFrame\n",
        "df = bpd.read_gbq_table(table_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeOXLFA6GN8P"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def print_dataset_statistics(data_source):\n",
        "    \"\"\"Print high level dataset statistics\"\"\"\n",
        "    num_rows = data_source.shape[0]\n",
        "    num_chars = data_source['text'].str.len().sum()\n",
        "\n",
        "    print(f\"\\nNumber of rows: {num_rows}\")\n",
        "    print(f\"Number of characters: {num_chars}\")\n",
        "\n",
        "def print_wrapped_text(text, width=128):\n",
        "    \"\"\"Print text wrapped to a specified width\"\"\"\n",
        "    wrapped_text = textwrap.fill(text, width=width)\n",
        "    print(wrapped_text)\n",
        "\n",
        "print(\"Sample Dialogue:\\n\")\n",
        "print_wrapped_text(df.iloc[0]['text'])\n",
        "print_dataset_statistics(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heSGzxZ1i1tj"
      },
      "source": [
        "## ðŸ§¬ Generating Differentially Private Synthetic Text with Gretel GPT\n",
        "\n",
        "Gretel GPT offers cutting-edge capabilities for generating high-quality, domain-specific synthetic text with differential privacy guarantees. Key features include:\n",
        "\n",
        "- Achieves strong privacy protection with a differential privacy (DP) epsilon value of 5\n",
        "- Maintains high semantic quality of generated text\n",
        "- Requires significantly less input data compared to traditional approaches (10k+ records vs 1M+)\n",
        "- Leverages pre-trained language models to enhance output quality\n",
        "- Balances data utility with rigorous privacy protection\n",
        "\n",
        "Gretel GPT enables the creation of synthetic text that captures the nuances of your specific domain while providing formal privacy guarantees. This approach is particularly valuable for regulated industries such as healthcare and finance, where data sensitivity is paramount.\n",
        "\n",
        "By utilizing DP-SGD training optimizations and flash attention 2, Gretel GPT achieves 5x faster training and generation, completing the process in about 2 hours on a single GPU in Gretel Hybrid on GCP. This efficiency, combined with the ability to work with smaller datasets, makes it an ideal solution for organizations looking to leverage sensitive text data safely and effectively.\n",
        "\n",
        "[Learn more about Gretel GPT and Differential Privacy](https://gretel.ai/blog/generate-differentially-private-synthetic-text-with-gretel-gpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qm34rcxvgO94"
      },
      "outputs": [],
      "source": [
        "# Submit the fine-tuning job to Gretel\n",
        "\n",
        "# Configuration for fine-tuning job\n",
        "fine_tune_config = {\n",
        "    \"base_config\": \"natural-language\",\n",
        "    \"job_label\": \"clinicalnotes_epsilon_5\",\n",
        "    \"pretrained_model\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    \"params\": {\n",
        "        \"batch_size\": 16,\n",
        "        \"steps\": 2500,\n",
        "        \"weight_decay\": 0.01,\n",
        "        \"warmup_steps\": 100,\n",
        "        \"lr_scheduler\": \"linear\",\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"max_tokens\": 512,\n",
        "    },\n",
        "    \"peft_params\": {\n",
        "        \"lora_r\": 8,\n",
        "        \"lora_alpha_over_r\": 1,\n",
        "    },\n",
        "    \"privacy_params\": {\n",
        "        \"dp\": True,\n",
        "        \"epsilon\": 5,\n",
        "        \"delta\": \"auto\"\n",
        "    },\n",
        "    \"generate\": {\n",
        "        \"num_records\": 80,\n",
        "        \"temperature\": 0.8,\n",
        "        \"maximum_text_length\": 512\n",
        "    }\n",
        "}\n",
        "\n",
        "# Submit the job and get the model ID\n",
        "train_results = gretel_bigframes.submit_train(dataframe=df, **fine_tune_config)\n",
        "model_id = train_results.model_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-0AXK-cJDcC"
      },
      "source": [
        "### ðŸ”„ Loading the Fine-tuned Model\n",
        "\n",
        "If you want to reload the trained model object later, do it like this:\n",
        "\n",
        "```python\n",
        "train_results = gretel_bigframes.fetch_train_job_results(model_id)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syXbwU7JNaBT"
      },
      "outputs": [],
      "source": [
        "# Attach to the training job\n",
        "train_results = gretel_bigframes.fetch_train_job_results(\"66e9a333bff4baa0b71844ce\")\n",
        "\n",
        "# train_results.wait_for_completion()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2yQSSqFaOU1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuJbvpWTNaBT"
      },
      "outputs": [],
      "source": [
        "# Check the status of the training job\n",
        "\n",
        "train_results.refresh()\n",
        "train_results.job_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCJHY7D0fu1m"
      },
      "outputs": [],
      "source": [
        "# Display the full report within this notebook\n",
        "\n",
        "train_results.report.display_in_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfF8tIkbHdEr"
      },
      "outputs": [],
      "source": [
        "# Fetch the synthetically generated data\n",
        "\n",
        "df_synth = train_results.fetch_report_synthetic_data()\n",
        "\n",
        "print(\"Sample Synthetically Generated Clinical Notes:\\n\")\n",
        "print_wrapped_text(df_synth.iloc[1]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpFGzkULwCEJ"
      },
      "outputs": [],
      "source": [
        "# Write the synthetically generated data to your table in BQ\n",
        "# NOTE: The BQ Dataset must already exist!\n",
        "\n",
        "project_id = BIGQUERY_PROJECT\n",
        "dataset_id = \"syntheticdata\"\n",
        "table_id = \"clinical-notes\"\n",
        "\n",
        "# Construct the table path\n",
        "table_path = f\"{project_id}.{dataset_id}.{table_id}\"\n",
        "\n",
        "# Write to the destination table in BQ, un-comment to actually write to BQ.\n",
        "# df_synth.to_gbq(table_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul7V8-BgJoLR"
      },
      "source": [
        "## ðŸŒ± Preparing Seed Data for Conditional Generation\n",
        "\n",
        "Seed data allows us to guide the synthetic data generation process. By providing partial information, we can:\n",
        "\n",
        "- Generate context-specific synthetic records\n",
        "- Explore various scenarios or patient profiles\n",
        "- Ensure the generated data aligns with specific use cases or research questions\n",
        "\n",
        "In this example, we're creating seed data with initial clinical contexts to demonstrate conditional generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqK-W_OJJp_b"
      },
      "outputs": [],
      "source": [
        "import bigframes.pandas as bpd\n",
        "\n",
        "# A dataframe with example clinical contexts to complete.\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"A 73-year-old man presented with a fall down of 13 stairs at her home while intoxicated. His past medical history \",\n",
        "        \"A 28 year old female was presented to our clinic with a left knee injury that had occurred a few days before while skiing.\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "seed_data = bpd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X9LcI6JJhv1"
      },
      "source": [
        "## ðŸ¤– Generate Additional Differentially Private Synthetic Data\n",
        "\n",
        "Now that we have our fine-tuned model and seed data, we can generate more synthetic records. This process:\n",
        "\n",
        "- Maintains the differential privacy guarantees of our original training\n",
        "- Allows for flexible data generation based on different seeds or prompts\n",
        "- Can be used to augment datasets or create specialized subsets for specific analyses\n",
        "\n",
        "Remember, you can adjust parameters like `temperature` to control the creativity of the generated text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1Fogi6YJku6"
      },
      "outputs": [],
      "source": [
        "generate_results = gretel_bigframes.submit_generate(\n",
        "    \"66e9a333bff4baa0b71844ce\",\n",
        "    seed_data=seed_data,\n",
        "    temperature=0.8,\n",
        "    maximum_text_length=512\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bu_rjEy0NaBT"
      },
      "outputs": [],
      "source": [
        "generate_job_id = generate_results.record_id # save off the Job ID for generation\n",
        "generate_results.wait_for_completion()\n",
        "\n",
        "# Restore the generation job if needed\n",
        "# generate_results = gretel_bigframes.fetch_generate_job_results(train_results.model_id, generate_job_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCKbWXCpJ2dc"
      },
      "outputs": [],
      "source": [
        "# Inspect conditionally generated data\n",
        "\n",
        "print(\"\\n\\nSample Clinical Notes:\\n\")\n",
        "print_wrapped_text(data['text'][1] + generate_results.synthetic_data.iloc[1]['text'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}