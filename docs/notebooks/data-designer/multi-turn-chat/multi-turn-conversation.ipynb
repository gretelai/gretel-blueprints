{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_parent\" href=\"https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/data-designer/multi-turn-chat/multi-turn-conversation.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Data Designer: Synthetic Conversational Data with Person Details\n",
    "\n",
    "This notebook demonstrates how to use the Gretel Navigator SDK to build a synthetic data generation pipeline step-by-step. We will create multi-turn user-assistant dialogues tailored for fine-tuning language models, enhanced with realistic person details. These synthetic dialogues can then be used as domain-specific training data to improve model performance in targeted scenarios.\n",
    "\n",
    "These datasets could be used for developing and enhancing conversational AI applications, including customer support chatbots, virtual assistants, and interactive learning systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U gretel_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field # type: ignore\n",
    "from gretel_client.navigator_client import Gretel # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Data Designer Configuration with the SDK\n",
    "\n",
    "Instead of relying on a single YAML configuration file, here we build up our pipeline interactively. This provides granular control over how we guide LLMs to produce realistic, domain-specific conversations. By adjusting prompts, seed data, and instructions, we can quickly iterate and refine our data generation process.\n",
    "\n",
    "### üìö Choosing the Model Suite\n",
    "Specify the `model_suite` to determine which models and associated licenses are used during data generation.\n",
    "For example, use `apache-2.0` for open-source-friendly licensing or `llama-3.x` or `amazon-nova` for advanced proprietary models.\n",
    "Select the suite based on compliance and licensing requirements relevant to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available model suites: apache-2.0, llama-3.x\n",
    "model_suite = \"apache-2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Setting Special System Instructions\n",
    "\n",
    "Provide system-wide instructions for the underlying LLMs to guide the data generation process. These instructions influence all generated dialogues, ensuring consistency, quality, and adherence to desired rules. The instructions specify guidelines for factual accuracy, contextual relevance, and tone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöÄ Initialize Gretel Navigator Data Designer\n",
    "\n",
    "Instantiate the Gretel client and create a new data designer with the chosen model suite and special system instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gretel = Gretel(api_key=\"prompt\")\n",
    "\n",
    "# Initialize the new Data Designer\n",
    "aidd = gretel.data_designer.new(    \n",
    "    model_suite=model_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pydantic Models for Structured Outputs\n",
    "\n",
    "You can use Pydantic to define a structure for the messages that are produced by Data Designer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    \"\"\"A single message turn in the conversation.\"\"\"\n",
    "    role: Literal[\"user\", \"assistant\"] = Field(..., description=\"Which role is writing the message.\")\n",
    "    content: str = Field(..., description=\"Message contents.\")\n",
    "\n",
    "\n",
    "class ChatConversation(BaseModel):\n",
    "    \"\"\"A chat conversation between a specific user and an AI assistant.\n",
    "    * All conversations are initiated by the user role.\n",
    "    * The assistant role always responds to the user message.\n",
    "    * Turns alternate between user and assistant roles.\n",
    "    * The last message is always from the assistant role.\n",
    "    * Message content can be long or short.\n",
    "    * All assistant messages are faithful responses and must be answered fully.\n",
    "    \"\"\"\n",
    "    conversation: list[Message] = Field(..., description=\"List of all messages in the conversation.\")\n",
    "\n",
    "\n",
    "class UserToxicityScore(BaseModel):\n",
    "    \"\"\"Output format for user toxicity assessment.\n",
    "\n",
    "    Toxicity Scores:\n",
    "    None: No toxicity detected in user messages.\n",
    "    Mild: Slightly rude or sarcastic but not hateful or harmful.\n",
    "    Moderate: Some disrespectful or harassing language.\n",
    "    Severe: Overt hate, harassment, or harmful content.\n",
    "    \"\"\"\n",
    "    reasons: list[str] = Field(..., description=\"Reasoning for user toxicity score.\")\n",
    "    score: Literal[\"None\", \"Mild\", \"Moderate\", \"Severe\"] = Field(..., description=\"Level of toxicity observed in the user role responses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üå± Adding Categorical Seed Columns\n",
    "\n",
    "Define categorical seed columns that set the context for the generated dialogues. Domain, topic, complexity, conversation length, and user mood will influence the generated conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add domain column with subcategories for topics\n",
    "aidd.add_column(\n",
    "    name=\"domain\",\n",
    "    type=\"category\",\n",
    "    params={\n",
    "        \"values\": [\"Tech Support\", \"Personal Finances\", \"Educational Guidance\"],\n",
    "        \"num_new_values_to_generate\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add topic subcategory\n",
    "aidd.add_column(\n",
    "    name=\"topic\",\n",
    "    type=\"subcategory\",\n",
    "    params={\n",
    "        \"category\": \"domain\",\n",
    "        \"values\": {\n",
    "            \"Tech Support\": [\n",
    "                \"Troubleshooting a Laptop\",\n",
    "                \"Setting Up a Home Wi-Fi Network\",\n",
    "                \"Installing Software Updates\"\n",
    "            ],\n",
    "            \"Personal Finances\": [\n",
    "                \"Budgeting Advice\",\n",
    "                \"Understanding Taxes\",\n",
    "                \"Investment Strategies\"\n",
    "            ],\n",
    "            \"Educational Guidance\": [\n",
    "                \"Choosing a College Major\",\n",
    "                \"Effective Studying Techniques\",\n",
    "                \"Learning a New Language\"\n",
    "            ]\n",
    "        },\n",
    "        \"num_new_values_to_generate\": 2\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add complexity column\n",
    "aidd.add_column(\n",
    "    name=\"complexity\",\n",
    "    type=\"category\",\n",
    "    params={\n",
    "        \"values\": [\"Basic\", \"Intermediate\", \"Advanced\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add conversation length column\n",
    "aidd.add_column(\n",
    "    name=\"conversation_length\",\n",
    "    type=\"category\",\n",
    "    params={\n",
    "        \"values\": [2, 4, 6, 8]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add user mood column\n",
    "aidd.add_column(\n",
    "    name=\"user_mood\",\n",
    "    type=\"category\",\n",
    "    params={\n",
    "        \"values\": [\"happy\", \"silly\", \"sarcastic\", \"combative\", \"disappointed\", \"toxic\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ú® Adding Generated Data Columns\n",
    "Now define the columns that the model will generate. These prompts instruct the LLM to produce the actual conversation: a system prompt to guide how the AI assistant engages in the conversation with the user, the conversation, and finally, we generate a toxicity_label to assess user toxicity over the entire conversation.\n",
    "\n",
    "#### üí¨ü§ñ AI Assistant system prompt and conversation\n",
    "\n",
    "We generate a system prompt to base the AI assistant and then generate the entire conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate assistant system prompt\n",
    "aidd.add_column(\n",
    "    name=\"assistant_system_prompt\",\n",
    "    type=\"llm-text\",\n",
    "    system_prompt=\"Keep this to a maximum of two sentences.\",\n",
    "    prompt=\"Write a reasonable system prompt for a helpful AI assistant with expertise in {{domain}} and {{topic}}. The AI assistant must not engage in harmful behaviors.\"\n",
    ")\n",
    "\n",
    "# Generate the user's task\n",
    "aidd.add_column(\n",
    "    name=\"user_task\",\n",
    "    type=\"llm-text\",\n",
    "    system_prompt=\"The task should be clear, focused on a single goal, and at most two sentences. Focus only on the task and don't provide only the task information.\",\n",
    "    prompt=\"Define a simple task related to {{topic}} of {{complexity}} complexity for the user.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Generate the conversation\n",
    "aidd.add_column(\n",
    "    name=\"conversation\",\n",
    "    type=\"llm-structured\",\n",
    "    prompt=(    \n",
    "        \"<task>\\n{{user_task}}\\n</task>\\n\\n\"\n",
    "\n",
    "        \"<system_prompt>{{assistant_system_prompt}}</system_prompt>\\n\\n\"\n",
    "\n",
    "        \"Generate a conversation between a user and an AI assistant with <system_prompt> about <task>.\\n\"\n",
    "        \"User is asking the assistant for advice and is in a {{user_mood}} mood.\\n\"\n",
    "        \"The conversation must be {{conversation_length}} messages in length.\\n\"\n",
    "        \"The conversation must come to a natural end in {{conversation_length}} messages and if the assistant is unable \"\n",
    "        \"to solve the user's needs by then, they should offer to continue the conversation later or redirect them to additional resources.\\n\"\n",
    "        \"The conversation must be realistic and natural, incorporating details from both the user's and assistant's profiles.\\n\"\n",
    "        \"The AI assistant role has the system prompt defined in <system_prompt>. All of its responses must conform to <system_prompt>:\\n\"\n",
    "    ),\n",
    "    output_format=ChatConversation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîç‚öñÔ∏è Assessment Column: Toxicity Label\n",
    "For the final step, we add a toxicity assessment column to classify the overall toxicity level of the user's messages across the entire conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Toxicity Label for the entire conversation\n",
    "\n",
    "from gretel_client.data_designer.params import Rubric\n",
    "\n",
    "# Define Toxicity Rubric\n",
    "toxicity_rubric = Rubric(\n",
    "    name=\"Toxicity\",\n",
    "    description=\"Evaluation of harmful, harassing, or hateful language in conversations\",\n",
    "    scoring={\n",
    "        \"4\": \"No toxicity detected; conversation is respectful and appropriate.\",\n",
    "        \"3\": \"Mild toxicity; slightly rude or sarcastic but not hateful or harmful.\",\n",
    "        \"2\": \"Moderate toxicity; contains disrespectful or harassing language.\",\n",
    "        \"1\": \"Severe toxicity; contains overt hate, harassment, or harmful content.\",\n",
    "        \"0\": \"Extreme toxicity; contains dangerous, threatening, or abusive content.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "TOXICITY_PROMPT_TEMPLATE = \"\"\"\\\n",
    "You are an expert in content moderation and digital communication ethics. You are evaluating the toxicity level in user messages.\n",
    "Take a deep breath and carefully analyze the conversation provided. Use the rubric to score the level of toxicity in the USER'S messages only.\n",
    "\n",
    "Consider:\n",
    "- Focus primarily on harassment, hate, or harmful language\n",
    "- Evaluate the full context of the conversation\n",
    "- Be objective and consistent in your assessment\n",
    "- If any single message exhibits toxicity, it should influence the final score\n",
    "\n",
    "## CONVERSATION\n",
    "{{ conversation }}\n",
    "\"\"\"\n",
    "\n",
    "aidd.add_column(\n",
    "    name=\"toxicity_evaluation\",\n",
    "    type='llm-judge',\n",
    "    prompt=TOXICITY_PROMPT_TEMPLATE,\n",
    "    rubrics=[toxicity_rubric]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëÄ Generating a dataset preview\n",
    "\n",
    "- Preview mode allows you to quickly iterate on your data design.\n",
    "\n",
    "- Each preview generation call creates 10 records for inspection, helping you verify prompts and instructions before running a larger batch job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a preview\n",
    "preview = aidd.preview(verbose_logging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîé Easily inspect individual records\n",
    "\n",
    "- Run the cell below to display individual records for inspection.\n",
    "\n",
    "- Run the cell multiple times to cycle through the 10 preview records.\n",
    "\n",
    "- Alternatively, you can pass the `index` argument to display a specific record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Like what you see?\n",
    "\n",
    "Submit a batch workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Submit batch job\n",
    "workflow_run = aidd.create(\n",
    "    num_records=100,\n",
    "    name=\"multi_turn_conversation_with_person_details\"\n",
    ")\n",
    "\n",
    "workflow_run.wait_until_done()\n",
    "print(\"\\nGenerated dataset shape:\", workflow_run.dataset.df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following these steps and leveraging the interactivity of the SDK, you can refine prompts, generate realistic dialogues with detailed personas, and ensure the resulting dataset is high-quality, non-toxic, and aligned with your domain-specific requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect first 10 records of the generated dataset\n",
    "workflow_run.dataset.df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
