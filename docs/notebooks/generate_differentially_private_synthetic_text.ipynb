{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBKZt39TDjtg"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/gretelai/gretel-blueprints/blob/main/docs/notebooks/generate_differentially_private_synthetic_text.ipynb)\n",
        "\n",
        "<br>\n",
        "\n",
        "<center><a href=https://gretel.ai/><img src=\"https://gretel-public-website.s3.us-west-2.amazonaws.com/assets/brand/gretel_brand_wordmark.svg\" alt=\"Gretel\" width=\"350\"/></a></center>\n",
        "\n",
        "<br>\n",
        "\n",
        "## Generate Differentially Private Synthetic Text with Gretel GPT\n",
        "\n",
        "In this Blueprint, we'll demonstrate fine-tuning Gretel GPT on a dataset using differential privacy, generating synthetic text suitable for analytics, ML, or AI applications. You will need need a [free Gretel account](https://console.gretel.ai/) to run this notebook. If this is your first time using the Gretel Client SDK, you can learn more about it [here](https://docs.gretel.ai/gretel-basics/getting-started/blueprints).\n",
        "\n",
        "<br>\n",
        "\n",
        "### Dataset\n",
        "\n",
        "1. **alexa/Commonsense-Dialogues on ü§ó**: Consists of 9k snippets of everyday conversations between people. Training time: 2hrs.\n",
        "\n",
        "#### Ready? Let's go üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZxWWj_7TI7A"
      },
      "source": [
        "## üíæ Install gretel-client and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S0NOyRBDl8z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install -Uqq gretel-client datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RJknbq_UP0P"
      },
      "source": [
        "## üõú Configure your Gretel session\n",
        "\n",
        "- Each `Gretel` instance is bound to a single [Gretel project](https://docs.gretel.ai/guides/gretel-fundamentals/projects).  \n",
        "\n",
        "- Set the project name at instantiation or use the `set_project` method.\n",
        "\n",
        "- Retrieve your API key [here](https://console.gretel.ai/users/me/key)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRCq0YkmFM2a"
      },
      "outputs": [],
      "source": [
        "from gretel_client import Gretel\n",
        "\n",
        "gretel = Gretel(project_name=\"dp-synthetic-text\", api_key=\"prompt\", validate=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lsie0tS2TBWE"
      },
      "source": [
        "## üìÇ Load and Process the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-_4S3bkIVXY"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "def print_dataset_statistics(data_source):\n",
        "    \"\"\"Print high level dataset statistics\"\"\"\n",
        "    num_rows = data_source.shape[0]\n",
        "    num_chars = data_source['text'].str.len().sum()\n",
        "\n",
        "    print(f\"Number of rows: {num_rows}\")\n",
        "    print(f\"Number of characters: {num_chars}\")\n",
        "\n",
        "# Load the commonsense dialogues dataset, preprocessed into dialog format\n",
        "dataset = load_dataset(\"meowterspace42/commonsense_dialogues\")\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "dataset_df = dataset['train'].to_pandas()\n",
        "\n",
        "print(\"Sample Dialogue:\\n\")\n",
        "print(dataset_df.iloc[0]['text'])\n",
        "print_dataset_statistics(dataset_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0JGPigkkRc9"
      },
      "source": [
        "## üèóÔ∏è Train Gretel GPT with a **custom configuration**\n",
        "\n",
        "###Base Configuration\n",
        "For the full base YAML configuration for Gretel GPT, refer to [this link](https://github.com/gretelai/gretel-blueprints/blob/main/config_templates/gretel/synthetics/natural-language.yml).\n",
        "\n",
        "###Customizing the Configuration\n",
        "You can customizing the configuration using *keyword arguments* in the `submit_train` method. The keywords can be any of the sections under the model, such as `params`, `generate`, or `privacy_params`. The values must be dictionaries with parameters from the associated section. Tip: Use the `job_label` argument to append a descriptive label to the model's name.\n",
        "\n",
        "‚òï Go grab grab a coffee while the model fine-tunes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "105TCaRNFhRu"
      },
      "outputs": [],
      "source": [
        "# Submit the fine-tuning job to Gretel\n",
        "\n",
        "trained = gretel.submit_train(\n",
        "    base_config=\"natural-language\",\n",
        "    job_label=\"commonsense_epsilon_8\",\n",
        "    data_source=dataset_df,\n",
        "    params={\n",
        "        \"pretrained_model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "        \"batch_size\": 8,\n",
        "        \"steps\": None,\n",
        "        \"epochs\": 3,\n",
        "        \"max_tokens\": 512,\n",
        "        \"learning_rate\": 0.001\n",
        "    },\n",
        "    privacy_params={\n",
        "        \"dp\": True,\n",
        "        \"epsilon\": 8,\n",
        "        \"delta\": \"auto\"\n",
        "    },\n",
        "    generate={\n",
        "        \"num_records\": 100,\n",
        "        \"temperature\": 0.8,\n",
        "        \"maximum_text_length\": 512\n",
        "    }\n",
        ")\n",
        "print(trained.model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYykhGryqmFR"
      },
      "source": [
        "### üîÑ Loading a Fine-tuned Model\n",
        "\n",
        "If you want to reload the trained model object later, do it like this:\n",
        "\n",
        "```python\n",
        "trained = gretel.fetch_train_job_results(model_id)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwpIrSbnEIZ1"
      },
      "source": [
        "## üìà View the synthetic quality report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYV5cC9NWZ2f"
      },
      "outputs": [],
      "source": [
        "# view synthetic data quality scores\n",
        "print(trained.report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfWRuAFmlx-E"
      },
      "source": [
        "## üìÑ View the sample generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R0yVdne-5lq"
      },
      "outputs": [],
      "source": [
        "df = trained.fetch_report_synthetic_data()\n",
        "\n",
        "print(\"Sample Dialogue:\\n\")\n",
        "print(df.iloc[0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocQpD_G2BZTj"
      },
      "source": [
        "## üå± Prepare the seed data\n",
        "\n",
        "- Conditional data generation is accomplished by submitting seed data, which can be given as a file path or `DataFrame`.\n",
        "\n",
        "- The seed data should contain a subset of the dataset's columns with the desired seed values.\n",
        "\n",
        "- Currently, only categorical seed columns are supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHfEXYnF8aBg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# A dataframe with 5 sample commonsense conversation contexts to complete.\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"The context of the following conversation is that Ashley went to a fancy dinner party at a high-end restaurant. She accidentally spilled soup on the host's expensive rug.\",\n",
        "        \"The context of the following conversation is that John missed his flight and is now trying to find an alternative way to get to his business meeting on time.\",\n",
        "        \"The context of the following conversation is that Mary found a stray cat on her way home and is figuring out what to do with it.\",\n",
        "        \"The context of the following conversation is that Mike's car broke down in the middle of a road trip, and he needs to get it fixed to continue his journey.\",\n",
        "        \"The context of the following conversation is that Sarah is planning a surprise birthday party for her best friend and needs to keep it a secret while making all the arrangements.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "seed_data = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7v0K1APTclU"
      },
      "source": [
        "## ü§ñ Generate additional DP synthetic data\n",
        "\n",
        "- The `submit_generate` method requires either `num_records` **or** `seed_data` as a keyword argument.\n",
        "\n",
        "- If `seed_data` is given, the number of generated records will equal `len(seed_data)`.\n",
        "\n",
        "- **Tip:** You can generate data from any trained model in the current project by using its associated `model_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjxXnVSzWbLi"
      },
      "outputs": [],
      "source": [
        "generated = gretel.submit_generate(trained.model_id, seed_data=seed_data, temperature=0.8, maximum_text_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7xVnr-JU5Sd"
      },
      "outputs": [],
      "source": [
        "# inspect conditionally generated data\n",
        "print(\"Sample Dialogue:\\n\")\n",
        "print(generated.synthetic_data.iloc[0]['text'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
