{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a513acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the required packages\n",
    "\n",
    "%%capture\n",
    "!pip install gretel_client pandas matplotlib numpy scipy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85467d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages to use the DGAN API\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math\n",
    "\n",
    "import yaml\n",
    "\n",
    "from getpass import getpass\n",
    "from gretel_client import configure_session, ClientConfig\n",
    "from gretel_client.helpers import poll\n",
    "from gretel_client.projects.projects import get_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure session through the prompt method\n",
    "\n",
    "configure_session(api_key=\"grtu6243a294e23061d46e656297dd1f720840fb06aa63f5f09db7ff20a68d99e558\", validate=True, cache=\"no\", endpoint=\"https://api-dev.gretel.cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and load the oil datasets that we will generate synthetic data for\n",
    "def get_oil():\n",
    "    wti = pd.read_csv('https://datahub.io/core/oil-prices/r/wti-daily.csv')\n",
    "    brent = pd.read_csv('https://datahub.io/core/oil-prices/r/brent-daily.csv')\n",
    "    wti.columns = ['Date', 'WTI Price']\n",
    "    brent.columns = ['Date', 'Brent Price']\n",
    "    oil = wti.merge(brent)\n",
    "    return oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e0942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the oil data\n",
    "df = get_oil()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate attribute column which is needed in order to use long style frames in the DGAN MIF Framework. We can set the \n",
    "#example size by setting the seq_len size.\n",
    "def generate_dataframe_with_batches(df, batch_size):\n",
    "    df_ = df[:math.floor(len(df)/batch_size)*batch_size]\n",
    "    columns = []\n",
    "    for i in range(0, len(df_), batch_size):\n",
    "        for j in range(batch_size):\n",
    "            columns.append(i)\n",
    "    df_['attributes'] = columns\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 1000\n",
    "df_input = generate_dataframe_with_batches(df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f39e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112988bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup config and train model\n",
    "\n",
    "TMP_FILE = \"tmp_train.csv\"\n",
    "\n",
    "CONFIG_STRING = f\"\"\"\n",
    "schema_version: 1.0\n",
    "\n",
    "name: \"oildata\"\n",
    "\n",
    "models:\n",
    "  - timeseries_dgan:\n",
    "        data_source: \"_\"\n",
    "\n",
    "        time_column: \"Date\"\n",
    "        example_id_column: \"attributes\"\n",
    "        df_style: \"long\"\n",
    "        \n",
    "        params:\n",
    "            epochs: 10\n",
    "            max_sequence_len: {seq_len}\n",
    "            sample_len: {seq_len}  # Must evenly divide max_sequence_len, length of time series\n",
    "            batch_size: 5000 \n",
    "            generator_learning_rate: 0.0001\n",
    "            discriminator_learning_rate: 0.0001\n",
    "            attribute_discriminator_learning_rate: 1e-4\n",
    "            apply_feature_scaling: True\n",
    "            apply_example_scaling: True\n",
    "            feature_num_layers: 3\n",
    "            feature_num_units: 100\n",
    "            feature_noise_dim: 10\n",
    "            \n",
    "        generate:\n",
    "            num_records: 500\n",
    "\n",
    "\"\"\"\n",
    "config = yaml.safe_load(CONFIG_STRING)\n",
    "\n",
    "project = get_project(display_name=\"DGAN\", create=True)\n",
    "\n",
    "print(f\"Follow model training at: {project.get_console_url()}\")\n",
    "\n",
    "model = project.create_model_obj(model_config=config)\n",
    "\n",
    "df_input.to_csv(TMP_FILE, index=False)\n",
    "model.data_source = TMP_FILE\n",
    "\n",
    "model.submit(upload_data_source=True)\n",
    "\n",
    "poll(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3133e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab synthetic data\n",
    "\n",
    "synthetic_df = pd.read_csv(model.get_artifact_link(\"data_preview\"), compression=\"gzip\")\n",
    "synthetic_df = synthetic_df.drop(columns = 'attributes')\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfac4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the correlations in the synthetic data between the variables and the correlations in the real data between the variables. \n",
    "# We want to see that all the cells are as close to 0 as possible.\n",
    "print(\"Difference in real correlations and synethic data correlations:\")\n",
    "print(df.iloc[: , 1:].corr() - synthetic_df.iloc[: , 1:].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's visualize the probability distribution of each feature and it's respective synthetic data alternate.\n",
    "for val in list(df.iloc[:,1:].columns):\n",
    "    plt.figure(figsize = (16,8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist([np.array(df[val]), np.array(synthetic_df[val])], \n",
    "             label=[\"real\", \"synthetic\"],\n",
    "             bins=50,\n",
    "             density=True,\n",
    "             )\n",
    "    plt.legend()\n",
    "    plt.xlabel(val)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ed91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to calculate autocorrelation which will be visualized below.\n",
    "def autocorr(X, Y):\n",
    "    EPS = 1e-8\n",
    "    Xm = torch.mean(X, 1).unsqueeze(1)\n",
    "    Ym = torch.mean(Y, 1).unsqueeze(1)\n",
    "    r_num = torch.sum((X - Xm) * (Y - Ym), 1)\n",
    "    r_den = torch.sqrt(torch.sum((X - Xm)**2, 1) * torch.sum((Y - Ym)**2, 1))\n",
    "\n",
    "    r_num[r_num == 0] = EPS\n",
    "    r_den[r_den == 0] = EPS\n",
    "\n",
    "    r = r_num / r_den\n",
    "    r[r > 1] = 0\n",
    "    r[r < -1] = 0\n",
    "\n",
    "    return r\n",
    "    \n",
    "def get_autocorr(feature):\n",
    "    feature = torch.from_numpy(feature)\n",
    "    feature_length = feature.shape[1]\n",
    "    autocorr_vec = torch.Tensor(feature_length - 2)\n",
    "\n",
    "    for j in range(1, feature_length - 1):\n",
    "      autocorr_vec[j - 1] = torch.mean(autocorr(feature[:, :-j], feature[:, j:]))\n",
    "\n",
    "    return autocorr_vec.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4389c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate numpy array in order to visualize the autocorrelation between real and synthetic data\n",
    "def generate_numpy_for_autocorr(df, batch_size):\n",
    "    features = df.iloc[: , 1:].to_numpy()\n",
    "    n = features.shape[0] // batch_size\n",
    "\n",
    "    # Shape is now (# examples, # time points, # features)\n",
    "    features = features[:(n*batch_size),:].reshape(-1, batch_size, features.shape[1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb282d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate autocorrelation features from synthetic and real data and plot!\n",
    "synthetic_acf = get_autocorr(generate_numpy_for_autocorr(df, seq_len))\n",
    "acf = get_autocorr(generate_numpy_for_autocorr(synthetic_df, seq_len))\n",
    "# Figure 1, autocorrelation\n",
    "plt.plot(acf, label=\"real\")\n",
    "plt.plot(synthetic_acf, label=\"generated\")\n",
    "plt.xlabel(\"Time lag (days)\")\n",
    "plt.ylabel(\"Autocorrelation\")\n",
    "plt.title(\"Autocorrelation of Heartbeat 1 and Heartbeat 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
