{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate synthetic data on downstream regression models\n",
    "\n",
    "### How to use this notebook\n",
    "Use this notebook to understand the quality and performance of your synthetic or augmented data on downstream machine learning regression tasks. \n",
    "\n",
    "### Installation\n",
    "Install Gretel Client to use Gretel's synthetic models as well as the Gretel Evaluate Regression model. You'll have to get your API key from the [Gretel console](https://www.console.gretel.ai) to configure your session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U gretel-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_client import configure_session\n",
    "\n",
    "configure_session(endpoint=\"https://api.gretel.cloud\", api_key=\"prompt\", cache=\"yes\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Try: Generate synthetic data, then evaluate the synthetic data on regression models against real-world data\n",
    " First, we'll generate synthetic data using a publicly available [processed Cleveland Clinic heart disease dataset](https://archive.ics.uci.edu/ml/datasets/heart+disease), which predicts the likelihood of heart disease present in a patient. We'll use Gretel's LSTM model to train on the real-world data and generate the synthetic data. For the regression evaluation, we'll predict the heart rate value in this target column: \"0\".\n",
    " \n",
    " To use the Gretel Evaluate Regression model, you must indicate the target column. Optionally, you can change the test-holdout amount, which is a float indicating the amount of real-world data you want to use as a holdout for testing the downstream regression models. You can also optionally select which models to use and which metric to optimize for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SUPPORTED MODELS AND METRICS ####\n",
    "## If you want to only use certain regression models, you can also indicate which models you want the autoML library to use, by indicating from the list below. \n",
    "## By default, all models will be used in the autoML training. \n",
    "## If you want to change the metric that the regression models will use to optimize for, you can select one metric from regression_metrics below. \n",
    "## The default metric is R2.\n",
    "\n",
    "regression_models = [\n",
    "    \"lr\",\n",
    "    \"lasso\",\n",
    "    \"ridge\",\n",
    "    \"en\",\n",
    "    \"lar\",\n",
    "    \"llar\",\n",
    "    \"omp\",\n",
    "    \"br\",\n",
    "    \"ard\",\n",
    "    \"par\",\n",
    "    \"ransac\",\n",
    "    \"tr\",\n",
    "    \"huber\",\n",
    "    \"kr\",\n",
    "    \"svm\",\n",
    "    \"knn\",\n",
    "    \"dt\",\n",
    "    \"rf\",\n",
    "    \"et\",\n",
    "    \"ada\",\n",
    "    \"gbr\",\n",
    "    \"mlp\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"dummy\"\n",
    "]\n",
    "\n",
    "regression_metrics = [\n",
    "    \"mae\",\n",
    "    \"mse\",\n",
    "    \"rmse\",\n",
    "    \"r2\",\n",
    "    \"rmsle\",\n",
    "    \"mape\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a project on Gretel Cloud using the following example project name. Then, notice that the config includes both the synthetic data model and evaluation model. Note we're using the default Gretel ACTGAN model configuration in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a project with a name that describes this use case\n",
    "from gretel_client.projects import create_or_get_unique_project\n",
    "\n",
    "project = create_or_get_unique_project(name=\"heart-disease-regression-evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_client.helpers import poll\n",
    "from gretel_client.projects.models import read_model_config\n",
    "\n",
    "# We'll import the Dow Jones stock price dataset from Gretel's public S3 bucket\n",
    "# You can modify this to select a dataset of your choice\n",
    "dataset_path = \"https://gretel-datasets.s3.amazonaws.com/processed_cleveland_heart_disease_uci/data.csv\" \n",
    "\n",
    "# Modify the default config to add an extra downstream task.\n",
    "# We do this by adding an evaluate stanza to our config.\n",
    "# Regression example, uncomment the additional params to change from defaults.\n",
    "config = read_model_config(\"synthetics/tabular-lstm\")\n",
    "\n",
    "config[\"models\"][0][\"synthetics\"][\"evaluate\"] = {\n",
    "    # Available downstream tasks are \"classification\" or \"regression\"\n",
    "    \"task\": 'regression',\n",
    "    ### Set to the target you wish to predict -- Change this if you try a different data set!\n",
    "    \"target\": '0',  # target column for regression prediction\n",
    "    # \"holdout\": 0.2,  # default holdout value = 0.2\n",
    "    # \"models\": regression_models,  # default set of models\n",
    "    # \"metric\": \"r2\",  # default metric used for sorting results, choose one\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and run the model\n",
    "## Note: this will both train and run the model to generate synthetic data as well as \n",
    "## run the downstream metrics evaluation immediately after\n",
    "\n",
    "model = project.create_model_obj(\n",
    "    model_config=config, \n",
    "    data_source=dataset_path\n",
    ")\n",
    "\n",
    "model.submit_cloud()\n",
    "\n",
    "poll(model)\n",
    "\n",
    "# Save all artifacts\n",
    "model.download_artifacts(\"/tmp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or: BYO synthetic or augmented data to evaluate downstream metrics against real-world data\n",
    "Already have your synthetic or augmented data? You can use your own CSV or JSON(L) data files in the Gretel Evaluate Regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Evaluate SDK using your custom config\n",
    "from gretel_client.evaluation.downstream_regression_report import DownstreamRegressionReport\n",
    "\n",
    "# Params\n",
    "# Synthetic data, REQUIRED for evaluate model\n",
    "# Download this sample heart disease synthetic dataset: https://drive.google.com/uc?export=download&id=18klkKYMsU0RsSE3Eyjz6HmPxGw2wwcaH\n",
    "# And make sure the file path is correct\n",
    "data_source = \"/Users/nicolepang/Downloads/synthetic_heart_disease_dataset.csv\" \n",
    "\n",
    "# Real data, REQUIRED for evaluate model\n",
    "ref_data = \"https://gretel-datasets.s3.amazonaws.com/processed_cleveland_heart_disease_uci/data.csv\" \n",
    "\n",
    "# Target to predict, REQUIRED for evaluate model\n",
    "target = '0'  # numeric field for regression example, this column is heart rate\n",
    "\n",
    "# Default holdout value\n",
    "# test_holdout = 0.2\n",
    "\n",
    "# Supply a subset if you do not want all of these, default is to use all of them\n",
    "# models = regression_models\n",
    "\n",
    "# Metric to use for ordering results, defaults are \"acc\" (Accuracy) for classification, \"r2\" (R2) for regression.\n",
    "# metric = \"r2\"\n",
    "\n",
    "# Create a downstream regression report\n",
    "evaluate = DownstreamRegressionReport(\n",
    "    # project=None,  # Create a temp project\n",
    "    target=target, \n",
    "    data_source=data_source, \n",
    "    ref_data=ref_data,\n",
    "    # holdout=test_holdout,\n",
    "    # models=models,\n",
    "    # metric=metric,\n",
    "    output_dir= '/tmp', # directory for saving report\n",
    "    # runner_mode=\"cloud\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "Could not open the file '/Users/nicolepang/Downloads/synthetic_heart_disease_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/projects/common.py:41\u001b[0m, in \u001b[0;36mvalidate_data_source\u001b[0;34m(data_source)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(data_source) \u001b[39mas\u001b[39;00m ds:\n\u001b[1;32m     42\u001b[0m         ds\u001b[39m.\u001b[39mseek(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/smart_open/smart_open_lib.py:188\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[1;32m    186\u001b[0m     transport_params \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 188\u001b[0m fobj \u001b[39m=\u001b[39m _shortcut_open(\n\u001b[1;32m    189\u001b[0m     uri,\n\u001b[1;32m    190\u001b[0m     mode,\n\u001b[1;32m    191\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    192\u001b[0m     buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[1;32m    193\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    194\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    195\u001b[0m     newline\u001b[39m=\u001b[39;49mnewline,\n\u001b[1;32m    196\u001b[0m )\n\u001b[1;32m    197\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/smart_open/smart_open_lib.py:361\u001b[0m, in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    359\u001b[0m     open_kwargs[\u001b[39m'\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m errors\n\u001b[0;32m--> 361\u001b[0m \u001b[39mreturn\u001b[39;00m _builtin_open(local_path, mode, buffering\u001b[39m=\u001b[39;49mbuffering, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopen_kwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/nicolepang/Downloads/synthetic_heart_disease_data.csv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Now you can run the model and get the report\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m evaluate\u001b[39m.\u001b[39;49mrun() \u001b[39m# this will wait for the job to finish\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/evaluation/reports.py:155\u001b[0m, in \u001b[0;36mBaseReport.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/evaluation/reports.py:149\u001b[0m, in \u001b[0;36mBaseReport._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject:\n\u001b[1;32m    148\u001b[0m     \u001b[39mwith\u001b[39;00m tmp_project() \u001b[39mas\u001b[39;00m proj:\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_in_project(proj)\n\u001b[1;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_in_project(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproject)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/evaluation/reports.py:144\u001b[0m, in \u001b[0;36mBaseReport._run_in_project\u001b[0;34m(self, project)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_in_project\u001b[39m(\u001b[39mself\u001b[39m, project: Project):\n\u001b[1;32m    139\u001b[0m     model \u001b[39m=\u001b[39m project\u001b[39m.\u001b[39mcreate_model_obj(\n\u001b[1;32m    140\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config,\n\u001b[1;32m    141\u001b[0m         data_source\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source,\n\u001b[1;32m    142\u001b[0m         ref_data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mref_data,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_model(model\u001b[39m=\u001b[39;49mmodel)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/evaluation/reports.py:83\u001b[0m, in \u001b[0;36mBaseReport._run_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_model\u001b[39m(\u001b[39mself\u001b[39m, model: Model):\n\u001b[1;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner_mode \u001b[39m==\u001b[39m RunnerMode\u001b[39m.\u001b[39mCLOUD:\n\u001b[0;32m---> 83\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_cloud(model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m     84\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunner_mode \u001b[39m==\u001b[39m RunnerMode\u001b[39m.\u001b[39mLOCAL:\n\u001b[1;32m     85\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_local(model\u001b[39m=\u001b[39mmodel)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/evaluation/downstream_regression_report.py:92\u001b[0m, in \u001b[0;36mDownstreamRegressionReport._run_cloud\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_cloud\u001b[39m(\u001b[39mself\u001b[39m, model: Model):\n\u001b[0;32m---> 92\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_run_cloud(model, base_artifact_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mregression_report\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/evaluation/reports.py:118\u001b[0m, in \u001b[0;36mBaseReport._run_cloud\u001b[0;34m(self, model, base_artifact_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_cloud\u001b[39m(\u001b[39mself\u001b[39m, model: Model, base_artifact_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreport\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 118\u001b[0m     job \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49msubmit_cloud()\n\u001b[1;32m    119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_await_completion(job)\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(\n\u001b[1;32m    122\u001b[0m         smart_open\u001b[39m.\u001b[39mopen(job\u001b[39m.\u001b[39mget_artifact_link(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbase_artifact_name\u001b[39m}\u001b[39;00m\u001b[39m_json\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39mread()\n\u001b[1;32m    123\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/projects/jobs.py:121\u001b[0m, in \u001b[0;36mJob.submit_cloud\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Submit this model to be scheduled for runing in Gretel Cloud.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[39mReturns:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m    The response from the Gretel API.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    117\u001b[0m     \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source, _DataFrameT)\n\u001b[1;32m    118\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source\u001b[39m.\u001b[39mempty\n\u001b[1;32m    119\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source\n\u001b[1;32m    120\u001b[0m ):\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupload_data_source()\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mref_data\u001b[39m.\u001b[39mis_empty:\n\u001b[1;32m    124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupload_ref_data()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/projects/jobs.py:239\u001b[0m, in \u001b[0;36mJob.upload_data_source\u001b[0;34m(self, _validate)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resolves and uploads the data source specified in the\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39mmodel config.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m    A Gretel artifact key.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexternal_data_source \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    235\u001b[0m     (\u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source, _DataFrameT) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source\u001b[39m.\u001b[39mempty)\n\u001b[1;32m    236\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source\n\u001b[1;32m    237\u001b[0m ):\n\u001b[1;32m    238\u001b[0m     \u001b[39m# NOTE: This assignment re-writes the gretel artifact onto the config\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproject\u001b[39m.\u001b[39;49mupload_artifact(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_source, _validate)\n\u001b[1;32m    240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_source\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/projects/projects.py:234\u001b[0m, in \u001b[0;36mProject.upload_artifact\u001b[0;34m(self, artifact_path, _validate)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m _validate:\n\u001b[0;32m--> 234\u001b[0m         validate_data_source(artifact_path)\n\u001b[1;32m    235\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(artifact_path, Path):\n\u001b[1;32m    236\u001b[0m         artifact_path \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(artifact_path)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/gretel_client/projects/common.py:44\u001b[0m, in \u001b[0;36mvalidate_data_source\u001b[0;34m(data_source)\u001b[0m\n\u001b[1;32m     42\u001b[0m         ds\u001b[39m.\u001b[39mseek(\u001b[39m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mraise\u001b[39;00m DataSourceError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not open the file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdata_source\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mex\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     peek \u001b[39m=\u001b[39m JsonReader(data_source)\n",
      "\u001b[0;31mDataSourceError\u001b[0m: Could not open the file '/Users/nicolepang/Downloads/synthetic_heart_disease_data.csv'"
     ]
    }
   ],
   "source": [
    "# Now you can run the model and get the report\n",
    "evaluate.run() # this will wait for the job to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary representation of how well the top 3 models trained on synthetic data performed against the \n",
    "# top 3 models trained on real-world data. 'Value' is the synthetic or augmented data's performance against real-world data (averaged)\n",
    "evaluate.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return the full report JSON details.\n",
    "evaluate.as_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This will return the full HTML contents of the report.\n",
    "evaluate.as_html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can check out the results of the autoML downstream models and keep synthesizing or augmenting your data to get the best results for you. \n",
    "Happy synthesizing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1264641a2296bed54b65447ff0d3f452674f070f0748798274bc429fe6ce8efd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
