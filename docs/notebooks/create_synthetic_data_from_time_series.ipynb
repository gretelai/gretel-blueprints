{
 "cells": [
 {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gretelai/gretel-blueprints/blob/main/docs/notebooks/create_synthetic_data_from_time_series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUnwBU_zYz2D"
   },
   "source": [
    "# Synthesize Time Series data from your own DataFrame\n",
    "\n",
    "This Blueprint demonstrates how to create synthetic time series data with Gretel. We assume that within the dataset\n",
    "there is at least:\n",
    "\n",
    "1. A specific column holding time data points\n",
    "\n",
    "2. One or more columns that contain measurements or numerical observations for each point in time.\n",
    "\n",
    "For this Blueprint, we will generate a very simple sine wave as our time series data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4-JFrb-Yz2G"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install numpy matplotlib pandas\n",
    "!pip install -U gretel-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHShf3MdYz2I"
   },
   "outputs": [],
   "source": [
    "# Specify your Gretel API key\n",
    "\n",
    "import pandas as pd\n",
    "from gretel_client import configure_session\n",
    "\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "\n",
    "configure_session(api_key=\"prompt\", cache=\"yes\", validate=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "moLu6jA3Yz2I"
   },
   "outputs": [],
   "source": [
    "# Create a simple timeseries with a sine and cosine wave\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "day = 24 * 60 * 60\n",
    "year = 365.2425 * day\n",
    "\n",
    "\n",
    "def load_dataframe() -> pd.DataFrame:\n",
    "    \"\"\"Create a time series x sin wave dataframe.\"\"\"\n",
    "    df = pd.DataFrame(columns=[\"date\", \"sin\", \"cos\", \"const\"])\n",
    "\n",
    "    df.date = pd.date_range(start=\"2017-01-01\", end=\"2021-07-01\", freq=\"4h\")\n",
    "    df.sin = 1 + np.sin(df.date.astype(\"int64\") // 1e9 * (2 * np.pi / year))\n",
    "    df.sin = (df.sin * 100).round(2)\n",
    "\n",
    "    df.cos = 1 + np.cos(df.date.astype(\"int64\") // 1e9 * (2 * np.pi / year))\n",
    "    df.cos = (df.cos * 100).round(2)\n",
    "\n",
    "    df.date = df.date.apply(lambda d: d.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    df.const = \"abcxyz\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = load_dataframe()\n",
    "train_df.set_index(\"date\").plot(figsize=(12, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7IlPWWPb38C"
   },
   "source": [
    "# Fine-tuning hyper-parameters for time-series\n",
    "\n",
    "In this cell, we define the `date` field as the time_field for our task, and `sin` and `cos` as trend fields where we wish to model the differences between each time step.\n",
    "\n",
    "## Hyper parameters\n",
    "\n",
    "- `vocab_size` is set to 0 to use character-based tokenization vs. sentencepiece\n",
    "- `predict_batch_size` is set to 1, which reduces generation speed but maximimizes use of model to replay long-term dependencies from the training sequences\n",
    "- `validation_split` is set to False, as randomly sampled time-series records will have an information leakage problem between the train and test sets.\n",
    "- `learning_rate` is set to 0.001, which increases training time but gives the model additional time to learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1q3ighmYz2J"
   },
   "outputs": [],
   "source": [
    "from gretel_client.projects import create_or_get_unique_project\n",
    "from gretel_client.helpers import poll\n",
    "from gretel_client.projects.models import read_model_config\n",
    "\n",
    "\n",
    "# Create a project and model configuration.\n",
    "project = create_or_get_unique_project(name=\"time-series-synthetic\")\n",
    "\n",
    "# Pull down the default synthetic config.  We will modify it slightly.\n",
    "config = read_model_config(\"synthetics/default\")\n",
    "\n",
    "\n",
    "# Here we create an object to specify the timeseries task.\n",
    "time_field = \"date\"\n",
    "trend_fields = [\"sin\", \"cos\"]\n",
    "\n",
    "task = {\n",
    "    \"type\": \"time_series\",\n",
    "    \"attrs\": {\"time_field\": time_field, \"trend_fields\": trend_fields},\n",
    "}\n",
    "\n",
    "config[\"models\"][0][\"synthetics\"][\"task\"] = task\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"epochs\"] = 100\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"vocab_size\"] = 0\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"learning_rate\"] = 1e-3\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"predict_batch_size\"] = 1\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"validation_split\"] = False\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"reset_states\"] = True\n",
    "config[\"models\"][0][\"synthetics\"][\"params\"][\"overwrite\"] = True\n",
    "config[\"models\"][0][\"synthetics\"][\"generate\"][\"num_records\"] = train_df.shape[0]\n",
    "config[\"models\"][0][\"synthetics\"][\"generate\"][\"max_invalid\"] = train_df.shape[0]\n",
    "\n",
    "# Get a csv to work with, just dump out the train_df.\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "model = project.create_model_obj(model_config=config, data_source=\"train.csv\")\n",
    "\n",
    "# Upload the training data. Train the model.\n",
    "model.submit_cloud()\n",
    "poll(model)\n",
    "\n",
    "synthetic = pd.read_csv(model.get_artifact_link(\"data_preview\"), compression=\"gzip\")\n",
    "synthetic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoT24lMpYz2K"
   },
   "outputs": [],
   "source": [
    "# Does the synthetic data look similar? Yep!\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "for k, v in enumerate(trend_fields):\n",
    "    train_df[[\"date\", v]].set_index(\"date\").plot(ax=axs[k], ls=\"--\")\n",
    "    synthetic[[\"date\", v]].set_index(\"date\").plot(ax=axs[k], alpha=0.7)\n",
    "    axs[k].legend([\"training\", \"synthetic\"], loc=\"lower right\")\n",
    "    axs[k].set_title(v)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfe_3m68ajwn"
   },
   "outputs": [],
   "source": [
    "# For time series data we dump out the date column to seed the record handler.\n",
    "train_df[\"date\"].to_csv(\"date_seeds.csv\", index=False)\n",
    "\n",
    "# Use the model to generate more synthetic data.\n",
    "record_handler = model.create_record_handler_obj(\n",
    "    params={\"num_records\": 5000, \"max_invalid\": 5000},\n",
    "    data_source=\"date_seeds.csv\",\n",
    ")\n",
    "\n",
    "record_handler.submit_cloud()\n",
    "\n",
    "poll(record_handler)\n",
    "\n",
    "# Create a second synthetic dataframe\n",
    "synthetic_2 = pd.read_csv(record_handler.get_artifact_link(\"data\"), compression=\"gzip\")\n",
    "synthetic_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZxrdBOdaxxk"
   },
   "outputs": [],
   "source": [
    "# Does the synthetic data look similar? Yep!\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
    "for k, v in enumerate(trend_fields):\n",
    "    train_df[[\"date\", v]].set_index(\"date\").plot(ax=axs[k], ls=\"--\")\n",
    "    synthetic[[\"date\", v]].set_index(\"date\").plot(ax=axs[k], alpha=0.7)\n",
    "    synthetic_2[[\"date\", v]].set_index(\"date\").plot(ax=axs[k], alpha=0.7)\n",
    "    axs[k].legend([\"training\", \"synthetic\", \"synthetic_2\"], loc=\"lower right\")\n",
    "    axs[k].set_title(v)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "create_synthetic_data_from_time_series.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
