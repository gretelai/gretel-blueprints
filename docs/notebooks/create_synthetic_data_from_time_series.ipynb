{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "create_synthetic_data_from_time_series.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUnwBU_zYz2D"
      },
      "source": [
        "# Synthesize Time Series data from your own DataFrame\n",
        "\n",
        "This Blueprint demonstrates how to create synthetic time series data with Gretel. We assume that within the dataset\n",
        "there is at least:\n",
        "\n",
        "1) A specific column holding time data points\n",
        "\n",
        "2) One or more columns that contain measurements or numerical observations for each point in time.\n",
        "\n",
        "For this Blueprint, we will generate a very simple sine wave as our time series data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4-JFrb-Yz2G"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install pyyaml smart_open numpy pandas\n",
        "!pip install -U gretel-client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHShf3MdYz2I"
      },
      "source": [
        "# Specify your Gretel API key\n",
        "\n",
        "from getpass import getpass\n",
        "import pandas as pd\n",
        "from gretel_client import configure_session, ClientConfig\n",
        "\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "configure_session(ClientConfig(api_key=getpass(prompt=\"Enter Gretel API key\"), \n",
        "                               endpoint=\"https://api.gretel.cloud\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moLu6jA3Yz2I"
      },
      "source": [
        "# Create a simple timeseries with a sine and cosine wave\n",
        "\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "day = 24 * 60 * 60\n",
        "year = 365.2425 * day\n",
        "\n",
        "\n",
        "def load_dataframe() -> pd.DataFrame:\n",
        "    \"\"\" Create a time series x sin wave dataframe. \"\"\"\n",
        "    df = pd.DataFrame(columns=['date', 'sin', 'cos', 'const'])\n",
        "    \n",
        "    df.date = pd.date_range(start='2017-01-01', end='2021-07-01', freq='4h')\n",
        "    df.sin = 1 + np.sin(df.date.astype('int64') // 1e9 * (2 * np.pi / year))\n",
        "    df.sin = (df.sin * 100).round(2)\n",
        "    \n",
        "    df.cos = 1 + np.cos(df.date.astype('int64') // 1e9 * (2 * np.pi / year))\n",
        "    df.cos = (df.cos * 100).round(2)\n",
        "    \n",
        "    df.date = df.date.apply(lambda d: d.strftime('%Y-%m-%d'))\n",
        "    \n",
        "    df.const = 'abcxyz'\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = load_dataframe()\n",
        "train_df.set_index('date').plot(figsize=(12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7IlPWWPb38C"
      },
      "source": [
        "# Fine-tuning hyper-parameters for time-series\n",
        "In this cell, we define the `date` field as the time_field for our task, and `sin` and `cos` as trend fields where we wish to model the differences between each time step.\n",
        "\n",
        "## Hyper parameters\n",
        "* `vocab_size` is set to 0 to use character-based tokenization vs. sentencepiece\n",
        "* `predict_batch_size` is set to 1, which reduces generation speed but maximimizes use of model to replay long-term dependencies from the training sequences\n",
        "* `validation_split` is set to False, as randomly sampled time-series records will have an information leakage problem between the train and test sets.\n",
        "* `learning_rate` is set to 0.001, which increases training time but gives the model additional time to learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1q3ighmYz2J"
      },
      "source": [
        "from smart_open import open\n",
        "import yaml\n",
        "\n",
        "from gretel_client import create_project\n",
        "from gretel_client.helpers import poll\n",
        "\n",
        "# Create a project and model configuration.\n",
        "project = create_project(display_name=\"time-series-synthetic\")\n",
        "\n",
        "# Pull down the default synthetic config.  We will modify it slightly.\n",
        "with open(\"https://raw.githubusercontent.com/gretelai/gretel-blueprints/main/config_templates/gretel/synthetics/default.yml\", 'r') as stream:\n",
        "    config = yaml.safe_load(stream)\n",
        "\n",
        "# Here we create an object to specify the timeseries task.\n",
        "time_field=\"date\"\n",
        "trend_fields=[\"sin\", \"cos\"]\n",
        "\n",
        "task = {\n",
        "    'type': 'time_series',\n",
        "    'attrs': {\n",
        "        'time_field': time_field,\n",
        "        'trend_fields': trend_fields\n",
        "    }\n",
        "}\n",
        "\n",
        "config['models'][0]['synthetics']['task'] = task\n",
        "config['models'][0]['synthetics']['params']['epochs'] = 100\n",
        "config['models'][0]['synthetics']['params']['vocab_size'] = 0\n",
        "config['models'][0]['synthetics']['params']['learning_rate'] = 1e-3\n",
        "config['models'][0]['synthetics']['params']['predict_batch_size'] = 1\n",
        "config['models'][0]['synthetics']['params']['validation_split'] = False\n",
        "config['models'][0]['synthetics']['params']['reset_states'] = True\n",
        "config['models'][0]['synthetics']['params']['overwrite'] = True\n",
        "config['models'][0]['synthetics']['generate']['num_records'] = train_df.shape[0]\n",
        "config['models'][0]['synthetics']['generate']['max_invalid'] = train_df.shape[0]\n",
        "\n",
        "model = project.create_model_obj(model_config=config)\n",
        "\n",
        "# Get a csv to work with, just dump out the train_df.\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "model.data_source = 'train.csv'\n",
        "\n",
        "# Upload the training data.  Train the model.\n",
        "model.submit(upload_data_source=True)\n",
        "poll(model)\n",
        "\n",
        "synthetic = pd.read_csv(model.get_artifact_link(\"data_preview\"), compression='gzip')\n",
        "synthetic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoT24lMpYz2K"
      },
      "source": [
        "# Does the synthetic data look similar? Yep!\n",
        "\n",
        "synthetic.set_index('date').plot(figsize=(12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfe_3m68ajwn"
      },
      "source": [
        "# Use the model to generate more synthetic data.\n",
        "record_handler = model.create_record_handler_obj()\n",
        "\n",
        "# For time series data we dump out the date column to seed the record handler.\n",
        "train_df['date'].to_csv('date_seeds.csv', index=False)\n",
        "\n",
        "record_handler.submit(\n",
        "    action=\"generate\",\n",
        "    params={\"num_records\": 5000, \"max_invalid\": 5000},\n",
        "    data_source='date_seeds.csv',\n",
        "    upload_data_source=True\n",
        ")\n",
        "\n",
        "poll(record_handler)\n",
        "\n",
        "# Create a second synthetic dataframe\n",
        "synthetic_2 = pd.read_csv(record_handler.get_artifact_link(\"data\"), compression='gzip')\n",
        "synthetic_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZxrdBOdaxxk"
      },
      "source": [
        "# Does the synthetic data look the similar? Yep!\n",
        "\n",
        "synthetic_2.set_index('date').plot(figsize=(12, 8))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}