{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/zredlined/c42d71d7c94078e0ff9b864c1dd6ec24/privacy-safe-llm-training-for-financial-risk-analysis-azure-openai-gretel-synthetic-data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSeuwj8fRtYv"
   },
   "source": [
    "# üîí Safe Fine-Tuning of Azure OpenAI Models: Financial Risk Analysis with Gretel's Privacy-Preserving Synthetic Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to safely train Large Language Models (LLMs) on sensitive financial data using privacy-preserving synthetic data. When working with regulated data in domains like finance, healthcare, or personal information, directly training models on raw data can pose significant privacy and compliance risks.\n",
    "\n",
    "We solve this challenge using:\n",
    "- ü§ñ **[Gretel](https://gretel.ai)**: Synthetic data platform for generating training data for ML and AI use cases.  \n",
    "- ‚òÅÔ∏è **[Azure OpenAI Fine-tuning](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning)**: Fine-tuning capabilities for customizing LLMs to specific domains\n",
    "- üìä **Financial Risk Analysis**: A practical use case showing how to train models to analyze financial documents for risk assessment\n",
    "\n",
    "## üõ†Ô∏è What We'll Build\n",
    "\n",
    "We'll create a financial risk analysis model that can:\n",
    "- Process financial documents and regulatory filings\n",
    "- Identify potential risks and exposures\n",
    "- Generate structured risk assessments in JSON format\n",
    "- Maintain data privacy compliance through synthetic training data\n",
    "\n",
    "## üìà The Data\n",
    "\n",
    "We're using Gretel's [`gretel-financial-risk-analysis-v1`](https://huggingface.co/datasets/gretelai/gretel-financial-risk-analysis-v1) dataset, which contains:\n",
    "- Synthetic financial documents and regulatory filings\n",
    "- Corresponding risk assessments and analysis\n",
    "- Built-in privacy guarantees through differential privacy\n",
    "- Real-world patterns while protecting sensitive information\n",
    "\n",
    "## üìö Notebook Structure\n",
    "1. Set up Azure OpenAI credentials and environment\n",
    "2. Load and prepare the Gretel synthetic dataset\n",
    "3. Fine-tune an Azure OpenAI model\n",
    "4. Monitor training progress\n",
    "5. Evaluate the resulting model\n",
    "\n",
    "This approach enables organizations to leverage LLMs for financial analysis while maintaining strict data privacy and regulatory compliance. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxm2euY0GDif"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "\n",
    "!pip install -U -qq openai gretel_client datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGuMOkHiGrYP"
   },
   "outputs": [],
   "source": [
    "# Load secrets and create our Azure client\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "os.environ['AZURE_OPENAI_ENDPOINT'] = \"https://YOUR_ENDPOINT.openai.azure.com/\"\n",
    "os.environ['AZURE_OPENAI_API_KEY'] = getpass(\"Enter your API key: \")\n",
    "\n",
    "azure_client = AzureOpenAI(api_version=\"2024-08-01-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from gretel_client.fine_tuning import OpenAIFormatter, OpenAIFineTuner\n",
    "\n",
    "HF_DATASET_NAME = \"gretelai/gretel-financial-risk-analysis-v1\"\n",
    "\n",
    "# All metadata related to the fine-tuning job will be stored here\n",
    "CHECKPOINT_FILE = \"openai_checkpoint.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic dataset from Huggingface. Any Training and Validation DataFrame can be used here.\n",
    "\n",
    "dataset = load_dataset(HF_DATASET_NAME)\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "validation_df = dataset[\"test\"].to_pandas()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a formatter object to convert the DataFrame into a format that OpenAI can understand.\n",
    "\n",
    "# When creating the formatter object, you can specify the columns that you want to use for the input and output as string template variables.\n",
    "# The string template variables will be replaced with the actual values from the DataFrame when the training dataset is created and if \n",
    "# any of the string template variables are not found in the DataFrame, an error will be raised.\n",
    "\n",
    "# For this specific example, we do not need to do any special formatting from the DataFrame, so we only specify string template variables\n",
    "# directly with no other text.\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"You are an expert financial risk analyst. Analyze the provided text for financial risks,\n",
    "    and output a structured assessment in JSON format including risk detection, specific risk flags,\n",
    "    financial exposure details, and analysis notes.\"\"\"\n",
    "\n",
    "# This formatter will be provided to our fine tuning object later on.\n",
    "formatter = OpenAIFormatter(system_message=SYSTEM_MESSAGE, user_template=\"{input}\", assistant_template=\"{output}\")\n",
    "\n",
    "# We can take a peek at what the formatter will do to the DataFrame\n",
    "formatter.peek_ft_dataset(input_dataset=train_df, n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we create our Fine Tuning Adapter. We will use this instance throughout the rest of the tutorial.\n",
    "\n",
    "fine_tuner = OpenAIFineTuner(\n",
    "    openai_client=azure_client,\n",
    "    formatter=formatter,\n",
    "    train_data=train_df,\n",
    "    validation_data=validation_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we progress through the tutorial, we will store our checkpoint occasioonally to disk. \n",
    "# The fine tuner instnace can be reloaded from this checkpoint by providing it as a kwarg to the constructor:\n",
    "\n",
    "# fine_tuner = OpenAIFineTuner(openai_client=azure_client, checkpoint=CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will prepare our training and validation datasets and upload them to the OpenAI Service. This is handled automatically by the fine tuner.\n",
    "\n",
    "fine_tuner.prepare_and_upload_data()\n",
    "fine_tuner.save_checkpoint(CHECKPOINT_FILE) # save our file IDs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will start fine tuning our model.\n",
    "# By default, this method will wait and accumulate the training event logs.\n",
    "# If you terminate this cell, see the next cell for how to re-attach to the job.\n",
    "\n",
    "fine_tuner.start_fine_tuning(model=\"gpt-4o-mini-2024-07-18\", epochs=1, checkpoint_save_path=CHECKPOINT_FILE)\n",
    "fine_tuner.save_checkpoint(CHECKPOINT_FILE) # save our file IDs to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-attach to the fine tuning job. This will load and display all available logging events from the job.\n",
    "\n",
    "fine_tuner.wait_for_fine_tune_job(checkpoint_save_path=CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuner.graph_training_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, with our fine-tuned model, we can create a deployment so we can run inference.\n",
    "# To run a deployment, you can use the Azure shell. Run this cell to get the full CLI command to use.\n",
    "\n",
    "# NOTE: This will be the \"model\" name that is used in subsequent chat completions\n",
    "deployment_name = \"risk-analysis-gpt\"\n",
    "\n",
    "# Retrieve this information from the Azure AI Studio portal.\n",
    "resource_group = \"gretel-fine-tuning-dev\"\n",
    "resource_name = \"gretel-fine-tuning-dev\"\n",
    "\n",
    "print(f\"\"\"Model can be deployed via Azure shell command: \\n\\n az cognitiveservices account deployment create \\\\\n",
    "    --resource-group {resource_group} \\\\\n",
    "    --name {resource_name} \\\\\n",
    "    --deployment-name {deployment_name} \\\\\n",
    "    --model-name {fine_tuner.checkpoint.open_ai_fine_tuned_model_id} \\\\\n",
    "    --model-version \"1\" \\\\\n",
    "    --model-format OpenAI \\\\\n",
    "    --sku-capacity \"1\" \\\\\n",
    "    --sku-name \"Standard\"\n",
    "\"\"\".format(resource_group=resource_group, resource_name=resource_name, deployment_name=deployment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With our model deployed, let's create a dataset we'd like to send to our fine-tuned model.\n",
    "\n",
    "test_cases = [\n",
    "    # Case 1: High financial risk scenario\n",
    "    \"\"\"\n",
    "    The Company has entered into a five-year contract to purchase raw materials\n",
    "    from a single supplier in a volatile market. The contract requires minimum\n",
    "    purchases of $10M annually with no cancellation clause. Recent market analysis\n",
    "    suggests potential price fluctuations of up to 40% in the next year.\n",
    "    \"\"\",\n",
    "\n",
    "    # Case 2: Moderate financial risk scenario\n",
    "    \"\"\"\n",
    "    Company XYZ announced a major expansion into emerging markets, requiring\n",
    "    $50M in upfront capital expenditure. The project will be funded through\n",
    "    a combination of variable-rate loans (60%) and existing cash reserves.\n",
    "    Market analysts expect interest rates to rise by 2% over the next year.\n",
    "    \"\"\",\n",
    "\n",
    "    # Case 3: No financial risk scenario\n",
    "    \"\"\"\n",
    "    The company has successfully completed its annual employee satisfaction survey\n",
    "    with a 95% participation rate. Results show high employee engagement scores\n",
    "    across all departments. The HR department is planning to implement new\n",
    "    professional development programs next quarter, which will be covered by\n",
    "    the existing training budget.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# With our existing formatter, we can also create a dataset that can be used for completion tasks.\n",
    "# The `user_messages` parameter is a list of dictionaries where each dictionary contains the input message.\n",
    "# The dictionary keys should match the string template variables in the formatter that were earlier specified and \n",
    "# are also columns in the training dataset.\n",
    "messages = formatter.create_completion_dataset(user_messages=[{\"input\": prompt} for prompt in test_cases])\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = fine_tuner.create_chat_completitions(deployment_name, messages=messages, model_params={\"temperature\": 0}, parse_json=True)\n",
    "responses"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/RhBRfXz03titK6DHNKmQ",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
