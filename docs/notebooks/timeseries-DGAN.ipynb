{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Synthetic Time Series Data with DoppelGanger**\n",
        "\n",
        "\n",
        "This Blueprint demonstrates how to create synthetic time series data via Gretel API with DoppelGanger (DGAN). The notebook provides a step-by-step process on how to take a raw dataframe and generate high-quality synthetic time series data. Specifically, we take a dataset containing daily prices over the past 35 years of two different oils (WTI and Brent) and show how to:\n",
        "\n",
        "\n",
        "1.   Load and manipulate the dataset so that it is in the correct format for DGAN\n",
        "2.   Set up a training configuration file for the MIF Framework \n",
        "3.   Submitting and polling the model for training purposes\n",
        "4.   Generating and saving unlimited high quality synthetic data\n",
        "5.   Visualizing and comparing the synthetic and real data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NYS8U5A1KSFq"
      },
      "id": "NYS8U5A1KSFq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a513acf2"
      },
      "outputs": [],
      "source": [
        "#install the required packages\n",
        "\n",
        "%%capture\n",
        "!pip install gretel_client pandas matplotlib numpy scipy torch"
      ],
      "id": "a513acf2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e85467d2"
      },
      "outputs": [],
      "source": [
        "#import necessary packages to use the DGAN API\n",
        "\n",
        "import math\n",
        "from getpass import getpass\n",
        "from typing import List, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import torch\n",
        "import yaml\n",
        "from gretel_client import configure_session\n",
        "from gretel_client.helpers import poll\n",
        "from gretel_client.projects.projects import get_project\n",
        "from plotly.subplots import make_subplots"
      ],
      "id": "e85467d2"
    },
    {
      "cell_type": "code",
      "source": [
        "_GRETEL_PALETTE = [\"#A051FA\", \"#18E7AA\"]\n",
        "_GRAPH_OPACITY = 0.75\n",
        "_GRAPH_BARGAP = 0.2  # gap between bars of adjacent location coordinates\n",
        "_GRAPH_BARGROUPGAP = 0.1  # gap between bars of the same location coordinates\n",
        "\n",
        "\n",
        "def combine_subplots(\n",
        "    figures: List[go.Figure],\n",
        "    titles: List[str] = None,\n",
        "    subplot_type: str = \"xy\",\n",
        "    shared_xaxes=True,\n",
        "    shared_yaxes=True,\n",
        ") -> go.Figure:\n",
        "    \"\"\"\n",
        "    Take a list of go.Figures and make a single go.Figure out of them.  They will all be on one row.\n",
        "    Args:\n",
        "        figures: List of go.Figures to combine.\n",
        "        titles: List of subplot titles, must be same length as number of traces.\n",
        "        subplot_type: see https://plotly.com/python/subplots/#subplots-types,\n",
        "        shared_xaxes: Passed into plotly make_subplots call, see\n",
        "            https://plotly.com/python-api-reference/generated/plotly.subplots.make_subplots.html\n",
        "        shared_yaxes: Passed into plotly make_subplots call, see\n",
        "            https://plotly.com/python-api-reference/generated/plotly.subplots.make_subplots.html\n",
        "    Returns:\n",
        "        a single new plotly.graph_objects.Figure.\n",
        "    \"\"\"\n",
        "    specs = [[{\"type\": subplot_type}] * len(figures)]\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=1,\n",
        "        cols=len(figures),\n",
        "        specs=specs,\n",
        "        shared_xaxes=shared_xaxes,\n",
        "        shared_yaxes=shared_yaxes,\n",
        "        subplot_titles=titles,\n",
        "    )\n",
        "    for i, f in enumerate(figures):\n",
        "        for t in f.select_traces():\n",
        "            fig.add_trace(trace=t, row=1, col=i + 1)\n",
        "        fig.layout.update(f.layout)\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "DIh7fzlELU3F"
      },
      "id": "DIh7fzlELU3F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correlation_heatmap(matrix: pd.DataFrame, name: str = \"Correlation\") -> go.Figure:\n",
        "    \"\"\"\n",
        "    Generate the figure for a list of correlation matrices.\n",
        "    Arguments:\n",
        "        matrix: The correlation matrix computed by dython.\n",
        "        name: Name to use in add_trace.\n",
        "    Returns:\n",
        "        A plotly.graph_objects.Figure, a subplot with heatmaps.\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "    fields = [x if len(x) <= 15 else x[0:14] + \"...\" for x in matrix.columns]\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(\n",
        "            z=matrix,\n",
        "            y=fields,\n",
        "            x=fields,\n",
        "            xgap=1,\n",
        "            ygap=1,\n",
        "            coloraxis=\"coloraxis\",\n",
        "            name=name,\n",
        "        )\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        coloraxis=dict(\n",
        "            colorscale=[\n",
        "                [0.0, \"#E8F3C6\"],\n",
        "                [0.25, \"#94E2BA\"],\n",
        "                [0.5, \"#31B8C0\"],\n",
        "                [0.75, \"#4F78B3\"],\n",
        "                [1.0, \"#76137F\"],\n",
        "            ],\n",
        "            cmax=1.0,\n",
        "            cmin=0,\n",
        "        ),\n",
        "        showlegend=True,\n",
        "        xaxis=dict(visible=False),\n",
        "        yaxis=dict(visible=False),\n",
        "    )\n",
        "    fig.update_yaxes(dtick=1)\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "L8BWlGFcLV9G"
      },
      "id": "L8BWlGFcLV9G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def histogram(left: pd.Series, right: pd.Series) -> Optional[go.Figure]:\n",
        "    \"\"\"\n",
        "    Generate a histogram distplot for a numeric distribution.\n",
        "    Arguments:\n",
        "        left: The left pd.Series for which we make the histogram.\n",
        "        right: The right pd.Series for which we make the histogram.\n",
        "    Returns:\n",
        "        A plotly.graph_objects.Figure\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "    fig.update_layout(\n",
        "        yaxis_title_text=\"Percentage\",\n",
        "        bargap=_GRAPH_BARGAP,\n",
        "        bargroupgap=_GRAPH_BARGROUPGAP,\n",
        "        showlegend=False,\n",
        "    )\n",
        "\n",
        "    left_copy = pd.Series(left)\n",
        "    left_copy.dropna(inplace=True)\n",
        "    right_copy = pd.Series(right)\n",
        "    right_copy.dropna(inplace=True)\n",
        "\n",
        "    # FIXME quantile, min and max will fail on empty Series. For now, fail fast and return empty fig.\n",
        "    if len(left_copy) == 0 or len(right_copy) == 0:\n",
        "        return fig\n",
        "\n",
        "    q1 = np.quantile(left_copy, 0.25)\n",
        "    q3 = np.quantile(left_copy, 0.75)\n",
        "    iqr = q3 - q1\n",
        "    max_range = min(max(left_copy), (q3 + (1.5 * iqr)))\n",
        "    min_range = max(min(left_copy), (q1 - (1.5 * iqr)))\n",
        "\n",
        "    filtered_left_copy = [i for i in left_copy if min_range <= i <= max_range]\n",
        "    filtered_right_copy = [i for i in right_copy if min_range <= i <= max_range]\n",
        "    binsize = (max_range - min_range) / 30\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=filtered_left_copy,\n",
        "            histnorm=\"percent\",\n",
        "            name=\"Training\",\n",
        "            xbins=dict(start=min_range, end=max_range, size=binsize),\n",
        "            marker=dict(color=_GRETEL_PALETTE[0]),\n",
        "            opacity=_GRAPH_OPACITY,\n",
        "            hovertemplate=\"(%{x}, %{y:.2f})\",\n",
        "        )\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=filtered_right_copy,\n",
        "            histnorm=\"percent\",\n",
        "            name=\"Synthetic\",\n",
        "            xbins=dict(start=min_range, end=max_range, size=binsize),\n",
        "            marker=dict(color=_GRETEL_PALETTE[1]),\n",
        "            opacity=_GRAPH_OPACITY,\n",
        "            hovertemplate=\"(%{x}, %{y:.2f})\",\n",
        "        )\n",
        "    )\n",
        "    return fig\n"
      ],
      "metadata": {
        "id": "1F9FWT9cLa_S"
      },
      "id": "1F9FWT9cLa_S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48d0e9f3"
      },
      "outputs": [],
      "source": [
        "#configure session through the prompt method\n",
        "\n",
        "configure_session(api_key=\"prompt\", validate=True, cache=\"no\", endpoint=\"https://api-dev.gretel.cloud\")"
      ],
      "id": "48d0e9f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e96a75c"
      },
      "outputs": [],
      "source": [
        "# download and load the oil datasets that we will generate synthetic data for\n",
        "\n",
        "def get_oil():\n",
        "    wti = pd.read_csv(\"https://datahub.io/core/oil-prices/r/wti-daily.csv\")\n",
        "    brent = pd.read_csv(\"https://datahub.io/core/oil-prices/r/brent-daily.csv\")\n",
        "    wti.columns = [\"Date\", \"WTI Price\"]\n",
        "    brent.columns = [\"Date\", \"Brent Price\"]\n",
        "    oil = wti.merge(brent)\n",
        "    return oil\n"
      ],
      "id": "5e96a75c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "900e0942"
      },
      "outputs": [],
      "source": [
        "#view the oil data\n",
        "\n",
        "df = get_oil()\n",
        "df.head()"
      ],
      "id": "900e0942"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "112988bf"
      },
      "outputs": [],
      "source": [
        "# Setup config and train model\n",
        "\n",
        "TMP_FILE = \"tmp_train.csv\"\n",
        "\n",
        "CONFIG_STRING = f\"\"\"\n",
        "schema_version: 1.0\n",
        "\n",
        "name: \"dganoilblueprint\"\n",
        "\n",
        "models:\n",
        "  - timeseries_dgan:\n",
        "        data_source: \"_\"\n",
        "        time_column: \"Date\"\n",
        "        df_style: \"long\"\n",
        "        params:\n",
        "            sample_len: 6\n",
        "            max_sequence_len: 6\n",
        "            feature_noise_dim: 30\n",
        "            feature_num_layers: 1\n",
        "            feature_num_units: 156\n",
        "            apply_feature_scaling: True\n",
        "            generator_learning_rate: 3.672877287106205e-05\n",
        "            discriminator_learning_rate: 4.156645891017197e-05\n",
        "            batch_size: 400\n",
        "            epochs: 10\n",
        "            \n",
        "        generate:\n",
        "            num_records: 500\n",
        "\n",
        "\"\"\"\n",
        "config = yaml.safe_load(CONFIG_STRING)\n",
        "\n",
        "project = get_project(display_name=\"DGAN-oil\", create=True)\n",
        "\n",
        "print(f\"Follow model training at: {project.get_console_url()}\")\n",
        "\n",
        "model = project.create_model_obj(model_config=config)\n",
        "\n",
        "df.to_csv(TMP_FILE, index=False)\n",
        "model.data_source = TMP_FILE\n",
        "\n",
        "model.submit(upload_data_source=True)\n",
        "\n",
        "poll(model)"
      ],
      "id": "112988bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfZ60CGB9yo4"
      },
      "outputs": [],
      "source": [
        "# Generate as much synthetic data as you want\n",
        "\n",
        "record_handler = model.create_record_handler_obj(\n",
        "    params={\"num_records\": 50000, \"max_invalid\": 500}\n",
        ")\n",
        "record_handler.submit_cloud()\n",
        "poll(record_handler)"
      ],
      "id": "TfZ60CGB9yo4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3133e5f3"
      },
      "outputs": [],
      "source": [
        "# Grab synthetic data\n",
        "\n",
        "synthetic_df = pd.read_csv(record_handler.get_artifact_link(\"data\"), compression=\"gzip\")\n",
        "synthetic_df = synthetic_df.drop(columns = 'id_column')\n",
        "synthetic_df.head()"
      ],
      "id": "3133e5f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bfac4a5"
      },
      "outputs": [],
      "source": [
        "# Let's compare the correlations in the synthetic data between the variables and the correlations in the real data between the variables. \n",
        "# We want to see that all the cells are as close to 0 as possible.\n",
        "print(\"Difference in real correlations and synethic data correlations:\")\n",
        "correlation_heatmap(df.iloc[: , 1:].corr() - synthetic_df.iloc[: , 1:].corr())"
      ],
      "id": "1bfac4a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FmWGdwkgmlD"
      },
      "outputs": [],
      "source": [
        "h1 = histogram(df['WTI Price'], synthetic_df['WTI Price'])\n",
        "h2 = histogram(df['Brent Price'], synthetic_df['Brent Price'])\n",
        "combine_subplots(\n",
        "    figures=[h1, h2],\n",
        "    titles=['WTI Price', 'Brent Price'],\n",
        "    subplot_type = \"xy\",\n",
        "    shared_xaxes=True,\n",
        "    shared_yaxes=True,\n",
        ")"
      ],
      "id": "0FmWGdwkgmlD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "095ed91d"
      },
      "outputs": [],
      "source": [
        "#Functions to calculate autocorrelation which will be visualized below.\n",
        "def autocorr(X, Y):\n",
        "    EPS = 1e-8\n",
        "    Xm = torch.mean(X, 1).unsqueeze(1)\n",
        "    Ym = torch.mean(Y, 1).unsqueeze(1)\n",
        "    r_num = torch.sum((X - Xm) * (Y - Ym), 1)\n",
        "    r_den = torch.sqrt(torch.sum((X - Xm)**2, 1) * torch.sum((Y - Ym)**2, 1))\n",
        "\n",
        "    r_num[r_num == 0] = EPS\n",
        "    r_den[r_den == 0] = EPS\n",
        "\n",
        "    r = r_num / r_den\n",
        "    r[r > 1] = 0\n",
        "    r[r < -1] = 0\n",
        "\n",
        "    return r\n",
        "    \n",
        "def get_autocorr(feature):\n",
        "    feature = torch.from_numpy(feature)\n",
        "    feature_length = feature.shape[1]\n",
        "    autocorr_vec = torch.Tensor(feature_length - 2)\n",
        "\n",
        "    for j in range(1, feature_length - 1):\n",
        "      autocorr_vec[j - 1] = torch.mean(autocorr(feature[:, :-j], feature[:, j:]))\n",
        "\n",
        "    return autocorr_vec.cpu().detach().numpy()"
      ],
      "id": "095ed91d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c4389c4"
      },
      "outputs": [],
      "source": [
        "#function to generate numpy array in order to visualize the autocorrelation between real and synthetic data\n",
        "def generate_numpy_for_autocorr(df, batch_size):\n",
        "    features = df.iloc[: , 1:].to_numpy()\n",
        "    n = features.shape[0] // batch_size\n",
        "\n",
        "    # Shape is now (# examples, # time points, # features)\n",
        "    features = features[:(n*batch_size),:].reshape(-1, batch_size, features.shape[1])\n",
        "    return features"
      ],
      "id": "8c4389c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bb282d0"
      },
      "outputs": [],
      "source": [
        "#Generate autocorrelation features from synthetic and real data and plot!\n",
        "synthetic_acf = get_autocorr(generate_numpy_for_autocorr(df, seq_len))\n",
        "acf = get_autocorr(generate_numpy_for_autocorr(synthetic_df, seq_len))\n",
        "# Figure 1, autocorrelation\n",
        "plt.plot(acf, label=\"real\")\n",
        "plt.plot(synthetic_acf, label=\"generated\")\n",
        "plt.xlabel(\"Time lag (days)\")\n",
        "plt.ylabel(\"Autocorrelation\")\n",
        "plt.title(\"Autocorrelation of WTI Oil and Brent Oil\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "9bb282d0"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "create_synthetic_data_from_dgan_api.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}