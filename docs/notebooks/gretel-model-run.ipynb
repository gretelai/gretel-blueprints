{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5898fe3-ef34-4397-8676-c5d8e0a7eec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install the gretel-client\n",
    "!pip install -U gretel-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9301648e-5548-4a12-b43a-c44ad8377872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "from gretel_client import configure_session\n",
    "from gretel_client.projects.models import read_model_config\n",
    "from gretel_client.projects import create_or_get_unique_project\n",
    "from gretel_client.helpers import poll\n",
    "from smart_open import open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263357f",
   "metadata": {},
   "source": [
    "## 1. Gather data files from the s3 source bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bdc974b-c9d1-4f31-8586-c2f28f0703f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_unprocessed_files_with_extension(source_bucket, dest_bucket, extension='.csv'):\n",
    "\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_objects_v2(Bucket=source_bucket)\n",
    "\n",
    "    files = []\n",
    "    for obj in response['Contents']:\n",
    "        key = obj['Key']\n",
    "        if key.endswith(extension):\n",
    "            try:\n",
    "                s3.head_object(Bucket=dest_bucket, Key=f'{os.path.splitext(key)[0]}_synth.csv')\n",
    "            except:\n",
    "                files.append(key)\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63c15780-f81d-4087-a672-a551e47b26df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hospital-records-wk6-2023': {'data_source': 's3://gretel-source-data-bucket/hospital-records-wk6-2023.csv',\n",
       "  'nb_rows': 9999,\n",
       "  'nb_cols': 18}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_bucket = 'gretel-source-data-bucket'\n",
    "dest_bucket = 'gretel-destination-data-bucket'\n",
    "extension = '.csv'\n",
    "\n",
    "s3_files = get_unprocessed_files_with_extension(source_bucket, dest_bucket, extension=extension)\n",
    "\n",
    "gretel_dict = {}\n",
    "for s3_file in s3_files:\n",
    "    key = os.path.splitext(s3_file)[0]\n",
    "    df = pd.read_csv(f's3://{source_bucket}/{s3_file}')\n",
    "    gretel_dict[key] = {}\n",
    "    gretel_dict[key]['data_source'] = f's3://{source_bucket}/{s3_file}'\n",
    "    gretel_dict[key]['nb_rows'] = len(df)\n",
    "    gretel_dict[key]['nb_cols'] = len(df.columns)\n",
    "    \n",
    "display(gretel_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d706603",
   "metadata": {},
   "source": [
    "## 2. Run Gretel Transform+Synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c3c5042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define some helper functions\n",
    "\n",
    "def get_secret():\n",
    "\n",
    "    secret_name = \"prod/Gretel/ApiKey\"\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        # For a list of exceptions thrown, see\n",
    "        # https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "        raise e\n",
    "\n",
    "    # Decrypts secret using the associated KMS key.\n",
    "    secret = json.loads(get_secret_value_response['SecretString'])\n",
    "\n",
    "    return secret[\"gretelApiKey\"]\n",
    "\n",
    "def track_status_greteljob(job_dict, project_name, model_id_key, record_id_key=None):\n",
    "\n",
    "    project = create_or_get_unique_project(name=project_name)\n",
    "    \n",
    "    for key in job_dict:\n",
    "        model_id = job_dict[key][model_id_key]\n",
    "        model = project.get_model(model_id)\n",
    "        if record_id_key:\n",
    "            record_id = gretel_dict[key][record_id_key]\n",
    "            job = model.get_record_handler(record_id)\n",
    "            job_id = record_id\n",
    "        else:\n",
    "            job = model\n",
    "            job_id = model_id\n",
    "            \n",
    "        while True:\n",
    "            job.refresh()\n",
    "            if job.status != 'completed':\n",
    "                print(key, job_id, job.status)\n",
    "                time.sleep(30)\n",
    "            else:\n",
    "                print(f\"Processing {key} with {job_id} is complete.\")\n",
    "                break\n",
    "\n",
    "def gretel_transform_train(job_dict, project_name, data_source_key, config=None):\n",
    "\n",
    "    project = create_or_get_unique_project(name=project_name)\n",
    "\n",
    "    if not config:\n",
    "        config = read_model_config(\"https://raw.githubusercontent.com/gretelai/gdpr-helpers/main/src/config/transforms_config.yaml\")\n",
    "    \n",
    "    for key in job_dict:\n",
    "        model = project.create_model_obj(\n",
    "            model_config=config, data_source=gretel_dict[key][data_source_key]\n",
    "        )\n",
    "        model.name = f\"transform-{key}\"\n",
    "        model.submit_cloud()\n",
    "        job_dict[key]['transform_model_id'] = model.model_id\n",
    "\n",
    "    print(\"Status of transform training jobs:\")\n",
    "    track_status_greteljob(\n",
    "        job_dict,\n",
    "        project_name=project_name,\n",
    "        model_id_key=\"transform_model_id\"\n",
    "    )\n",
    "\n",
    "def gretel_transform_run(job_dict, project_name, data_source_key, config=None):\n",
    "\n",
    "    project = create_or_get_unique_project(name=project_name)\n",
    "\n",
    "    for key in job_dict:\n",
    "        model_id = job_dict[key]['transform_model_id']\n",
    "        model = project.get_model(model_id)\n",
    "        record_handler = model.create_record_handler_obj(\n",
    "            data_source=job_dict[key][data_source_key],\n",
    "        )\n",
    "        record_handler.submit_cloud()\n",
    "        job_dict[key]['transform_record_id'] = record_handler.record_id\n",
    "\n",
    "    print(\"Status of transform run jobs:\")\n",
    "    track_status_greteljob(\n",
    "        job_dict,\n",
    "        project_name=project_name,\n",
    "        model_id_key=\"transform_model_id\",\n",
    "        record_id_key=\"transform_record_id\"\n",
    "    )\n",
    "\n",
    "    # Store the de-identified data\n",
    "    for key in job_dict:\n",
    "        model_id = job_dict[key][\"transform_model_id\"]\n",
    "        model = project.get_model(model_id)\n",
    "        record_id = job_dict[key][\"transform_record_id\"]\n",
    "        record_handler = model.get_record_handler(record_id)\n",
    "        gretel_dict[key]['deidentified_data_source'] = pd.read_csv(record_handler.get_artifact_link(\"data\"), compression=\"gzip\")\n",
    "\n",
    "def gretel_synthetics_train(job_dict, project_name, data_source_key, config=None):\n",
    "    \n",
    "    project = create_or_get_unique_project(name=project_name)\n",
    "\n",
    "    if not config:\n",
    "        config = read_model_config(\"synthetics/tabular-actgan\")\n",
    "    \n",
    "    for key in job_dict:\n",
    "        model = project.create_model_obj(\n",
    "            model_config=config, data_source=gretel_dict[key][data_source_key]\n",
    "        )\n",
    "        model.name = f\"synthetics-{key}\"\n",
    "        model.submit_cloud()\n",
    "        job_dict[key]['model_id'] = model.model_id\n",
    "\n",
    "    print(\"Status of synthetics training jobs:\")\n",
    "    track_status_greteljob(\n",
    "        job_dict,\n",
    "        project_name=project_name,\n",
    "        model_id_key=\"model_id\"\n",
    "    )\n",
    "\n",
    "def gretel_synthetics_run(job_dict, project_name, data_source_key, config=None):\n",
    "\n",
    "    project = create_or_get_unique_project(name=project_name)\n",
    "\n",
    "    for key in job_dict:\n",
    "        model_id = job_dict[key]['model_id']\n",
    "        model = project.get_model(model_id)\n",
    "        num_records = gretel_dict[key]['nb_rows']\n",
    "        record_handler = model.create_record_handler_obj(\n",
    "            params={\"num_records\": num_records},\n",
    "        )\n",
    "        record_handler.submit_cloud()\n",
    "        job_dict[key]['record_id'] = record_handler.record_id\n",
    "\n",
    "    print(\"Status of synthetics run jobs:\")\n",
    "    track_status_greteljob(\n",
    "        job_dict,\n",
    "        project_name=project_name,\n",
    "        model_id_key=\"model_id\",\n",
    "        record_id_key=\"record_id\"\n",
    "    )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3868b95-3297-4c32-bf12-0333ece26629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching Gretel config to disk.\n",
      "Using endpoint https://api.gretel.cloud\n",
      "Logged in as maarten@gretel.ai âœ…\n"
     ]
    }
   ],
   "source": [
    "# Configure a Gretel session\n",
    "\n",
    "GRETEL_PROJECT_NAME = 'aws-lambda-gretel-project'\n",
    "\n",
    "GRETEL_API_KEY = get_secret()\n",
    "configure_session(api_key=GRETEL_API_KEY, cache=\"yes\", validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8b8455-b19b-46d2-a22b-93f37120e9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of transform training jobs:\n",
      "hospital-records-wk6-2023 64cd39d323411e9b360c4c0c Status.CREATED\n",
      "hospital-records-wk6-2023 64cd39d323411e9b360c4c0c Status.ACTIVE\n",
      "hospital-records-wk6-2023 64cd39d323411e9b360c4c0c Status.ACTIVE\n",
      "hospital-records-wk6-2023 64cd39d323411e9b360c4c0c Status.ACTIVE\n",
      "Processing hospital-records-wk6-2023 with 64cd39d323411e9b360c4c0c is complete.\n",
      "Status of transform run jobs:\n",
      "hospital-records-wk6-2023 64cd3a510d912056eb010f0d Status.PENDING\n",
      "Processing hospital-records-wk6-2023 with 64cd3a510d912056eb010f0d is complete.\n"
     ]
    }
   ],
   "source": [
    "# Use Gretel Transform to de-identify the data\n",
    "\n",
    "gretel_transform_train(\n",
    "    gretel_dict, \n",
    "    data_source_key=\"data_source\",\n",
    "    project_name=GRETEL_PROJECT_NAME\n",
    ")\n",
    "\n",
    "gretel_transform_run(\n",
    "    gretel_dict, \n",
    "    data_source_key=\"data_source\",\n",
    "    project_name=GRETEL_PROJECT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4284e1-de7f-4307-bb3d-a8afc41183a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of synthetics training jobs:\n",
      "hospital-records-wk6-2023 64cd3a7423411e9b360c4c0d Status.PENDING\n",
      "hospital-records-wk6-2023 64cd3a7423411e9b360c4c0d Status.ACTIVE\n",
      "Processing hospital-records-wk6-2023 with 64cd3a7423411e9b360c4c0d is complete.\n",
      "Status of synthetics run jobs:\n",
      "hospital-records-wk6-2023 64cd3ab30d912056eb010f0e Status.CREATED\n",
      "hospital-records-wk6-2023 64cd3ab30d912056eb010f0e Status.ACTIVE\n",
      "Processing hospital-records-wk6-2023 with 64cd3ab30d912056eb010f0e is complete.\n"
     ]
    }
   ],
   "source": [
    "# Load and modify Gretel Actan config\n",
    "config = read_model_config(\"synthetics/tabular-actgan\")\n",
    "config['models'][0]['actgan']['params']['epochs'] = 10\n",
    "\n",
    "gretel_synthetics_train(\n",
    "    gretel_dict, \n",
    "    data_source_key=\"deidentified_data_source\",\n",
    "    project_name=GRETEL_PROJECT_NAME,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "gretel_synthetics_run(\n",
    "    gretel_dict, \n",
    "    data_source_key=\"data_source\",\n",
    "    project_name=GRETEL_PROJECT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f43e38",
   "metadata": {},
   "source": [
    "## 3. Write artifacts to the s3 destination bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e6829c1-37dc-4ecd-aba1-ea48e1af5fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the SQS reports to s3 destination bucket\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "for key in gretel_dict:\n",
    "    model_id = gretel_dict[key]['model_id']\n",
    "    model = project.get_model(model_id)\n",
    "\n",
    "    html_data = open(model.get_artifact_link(\"report\")).read()\n",
    "    s3.put_object(\n",
    "        Body=html_data,\n",
    "        Bucket=dest_bucket,\n",
    "        Key=f'{key}_report.html'\n",
    "    )\n",
    "\n",
    "    # save SQS report summary\n",
    "    s3.put_object(\n",
    "         Body=json.dumps(model.get_report_summary()),\n",
    "         Bucket=dest_bucket,\n",
    "         Key=f'{key}_report_summary.json'\n",
    "      )\n",
    "\n",
    "    record_id = gretel_dict[key]['record_id']\n",
    "    rh = model.get_record_handler(record_id)\n",
    "    synth_df = pd.read_csv(rh.get_artifact_link(\"data\"), compression=\"gzip\")\n",
    "    synth_df.to_csv(f's3://{dest_bucket}/{key}_synth.csv', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
